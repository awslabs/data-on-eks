# Coordinator Node Memory:
# JVM Heap (maxHeapSize): 32G (100%)
# ├── Query Memory (maxMemoryPerNode): 22GB (~70%)
# ├── Heap Headroom: 9.6GB (30%)
# └── Total: 31.6GB < 32GB ✓

# Worker Node Memory
# JVM Heap (maxHeapSize): 89G (100%)
# ├── Query Memory (maxMemoryPerNode): 71GB (~70%)
# ├── Heap Headroom: 9.6GB
# └── Total: 80.6GB < 89GB ✓
---
image:
  tag: "427"
server:
  workers: 3
  exchangeManager:
    baseDir: "s3://${exchange_bucket_id}"
  autoscaling:
    enabled: true
    maxReplicas: 20
    targetCPUUtilizationPercentage: 75
    targetMemoryUtilizationPercentage: 80
    # Add advanced scaling behavior from https://github.com/trinodb/charts/blob/4630167a839e6730c04cecc2af09ff038f522903/charts/trino/values.yaml#L94
  config:
    query:
      maxMemory: "280GB"  # Total memory across cluster for queries
      initialHashPartitions: 100  # Improved parallel processing
      maxStageRetries: 3
      maxExecutionTime: "24h"
      clientTimeout: "2h"
service:
  type: ClusterIP
  port: 8080

coordinator:
  jvm:
    maxHeapSize: "32G"  # ~80% of container memory
    extraArguments:
      - "-XX:+UseG1GC"
      - "-XX:G1HeapRegionSize=32M"
      - "-XX:+UseGCOverheadLimit"
      - "-XX:+ExitOnOutOfMemoryError"
      - "-XX:ReservedCodeCacheSize=256M"
      - "-Djdk.attach.allowAttachSelf=true"
      - "-XX:+UseContainerSupport"
  config:
    query:
      #maxMemoryPerNode + (maxHeapSize * 0.3) < maxHeapSize
      maxMemoryPerNode: "22GB"  # ~70% of maxHeapSize
      minWorkers: 1
      initialHashPartitions: 100
  resources:
    requests:
      cpu: "4000m"     # Reduced CPU request
      memory: 40Gi     # Reduced memory request
    limits:
      cpu: "6000m"     # Higher limit for spikes
      memory: 40Gi
  nodeSelector:
    NodePool: trino-sql-karpenter
    karpenter.sh/capacity-type: on-demand
  topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: kubernetes.io/hostname
      whenUnsatisfiable: DoNotSchedule
      labelSelector:
        matchLabels:
          component: coordinator

worker:
  jvm:
    maxHeapSize: "89G"  # ~80% of container memory (110Gi)
    extraArguments:
      - "-XX:+UseG1GC"
      - "-XX:G1HeapRegionSize=32M"
      - "-XX:+UseGCOverheadLimit"
      - "-XX:+ExitOnOutOfMemoryError"
      - "-XX:ReservedCodeCacheSize=256M"
      - "-Djdk.attach.allowAttachSelf=true"
      - "-XX:+UseContainerSupport"
  config:
    query:
      maxMemoryPerNode: "71GB"  # ~80% of maxHeapSize
  resources:
    requests:
      cpu: "12000m"  # Leave 3000m for system/DaemonSets
      memory: 112Gi  # Leave 16Gi for system/DaemonSets
    limits:
      cpu: "14000m"
      memory: 112Gi
  nodeSelector:
    NodePool: trino-sql-karpenter
    karpenter.sh/capacity-type: on-demand
  topologySpreadConstraints:
    - maxSkew: 1
      topologyKey: kubernetes.io/hostname
      whenUnsatisfiable: DoNotSchedule
      labelSelector:
        matchLabels:
          component: worker

additionalConfigProperties:
  - "retry-policy=TASK"
  - "exchange.compression-enabled=true"
  - "query.remote-task.max-error-duration=1m"
  - "query.max-hash-partition-count=100"   # Updated from query.hash-partition-count
  - "spill-enabled=true"                   # Updated from experimental.spill-enabled
  - "spiller-spill-path=/tmp/spill"        # Chagne this to SSD mount for faster
  - "memory.heap-headroom-per-node=9.6GB"
  - "optimizer.join-reordering-strategy=AUTOMATIC"  # Updated from join-reordering-strategy
  - "query.max-history=100"
  - "query.client.timeout=30m"
  - "sink.max-buffer-size=1GB"

additionalExchangeManagerProperties:
  - "exchange-manager.name=filesystem"
  - "exchange.base-directories=s3://${exchange_bucket_id}"
  - "exchange.s3.region=${region}"
  - "exchange.s3.iam-role=${irsa_arn}"
  - "exchange.s3.max-error-retries=10"
  - "exchange.s3.upload.part-size=64MB"

additionalCatalogs:
  hive: |-
    connector.name=hive
    hive.metastore=glue
    hive.metastore.glue.region=${region}
    hive.metastore.glue.default-warehouse-dir=s3://${bucket_id}/
    hive.metastore.glue.iam-role=${irsa_arn}
    hive.s3.iam-role=${irsa_arn}
    hive.security=allow-all
  iceberg: |-
    connector.name=iceberg
    iceberg.catalog.type=glue
    iceberg.file-format=PARQUET
    iceberg.unique-table-location=true
    iceberg.register-table-procedure.enabled=true
    hive.metastore.glue.region=${region}
    hive.metastore.glue.default-warehouse-dir=s3://${bucket_id}/
    hive.s3.path-style-access=true
    hive.metastore.glue.iam-role=${irsa_arn}
    hive.s3.iam-role=${irsa_arn}
serviceAccount:
  create: true
  name: ${sa}
ingress:
  enabled: false
