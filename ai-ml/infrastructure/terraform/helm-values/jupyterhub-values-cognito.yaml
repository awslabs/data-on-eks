hub:
  db:
    pvc:
      storage: 50Gi
      storageClassName: gp3
  authenticatePrometheus: false
  command: ["sh", "-c", "pip install boto3 && jupyterhub --config /usr/local/etc/jupyterhub/jupyterhub_config.py"]
  config:
    GenericOAuthenticator:
      oauth_callback_url: ${jupyterdomain}
      client_id: ${client_id}
      client_secret: ${client_secret}
      authorize_url: ${authorize_url}
      token_url: ${token_url}
      userdata_url: ${userdata_url}
      scope:
        - openid
        - email
      username_key: "username"
      login_service : "AWS Cognito"
      userdata_method: "POST"
    JupyterHub:
      authenticator_class: generic-oauth
  extraConfig:
    jupyterhub_config.py: |-
      c.KubeSpawner.start_timeout = 1200
      c.Authenticator.enable_auth_state = True

    cognito_config.py: |-
      import boto3
      def auth_state_hook(spawner, auth_state):
        client_idp = boto3.client('cognito-idp', region_name="${region}")
        auth_response = client_idp.initiate_auth(
          AuthFlow="REFRESH_TOKEN_AUTH",
          AuthParameters={
            "REFRESH_TOKEN": auth_state['refresh_token'],
            "SECRET_HASH": "${client_secret}"
          },
          ClientId="${client_id}"
        )
        id_token = auth_response["AuthenticationResult"]["IdToken"]
        client_identity = boto3.client("cognito-identity", region_name="${region}")
        identity_response = client_identity.get_id(
          IdentityPoolId="${identity_pool_id}",
          Logins={
            f"cognito-idp.${region}.amazonaws.com/${user_pool_id}": id_token
          }
        )
        identity_id = identity_response['IdentityId']
        credentials = client_identity.get_credentials_for_identity(
          IdentityId=identity_id,
          Logins={
            f"cognito-idp.${region}.amazonaws.com/${user_pool_id}": id_token
          }
        )
        key = credentials["Credentials"]["AccessKeyId"]
        secret = credentials["Credentials"]["SecretKey"]
        token = credentials["Credentials"]["SessionToken"]
        spawner.environment['AWS_ACCESS_KEY_ID'] = key
        spawner.environment['AWS_SECRET_ACCESS_KEY'] = secret
        spawner.environment['AWS_SESSION_TOKEN'] = token

      c.Spawner.auth_state_hook = auth_state_hook

proxy:
  https:
    enabled: true
    type: offload
  service:
    annotations:
      service.beta.kubernetes.io/aws-load-balancer-ssl-cert: ${ssl_cert_arn}
      service.beta.kubernetes.io/aws-load-balancer-ssl-ports: "https"
      service.beta.kubernetes.io/aws-load-balancer-backend-protocol: "tcp"
      service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "3600"
      service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip
      service.beta.kubernetes.io/aws-load-balancer-scheme: internal
      service.beta.kubernetes.io/aws-load-balancer-type: external
      service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: 'true'
      service.beta.kubernetes.io/aws-load-balancer-ip-address-type: ipv4

singleuser:
  startTimeout: 1200 # 20 mins to spin up a notebook server for GPU including the image pull
  profileList:
    - display_name: Data Engineering (CPU)
      description: "PySpark Notebooks | Karpenter AutoScaling"
      profile_options:
        image:
          display_name: "Image"
          choices:
            pyspark350:
              display_name: "PySpark 3.5.0 + Python 3.11"
              default: true
              kubespawner_override:
                image: jupyter/pyspark-notebook:spark-3.5.0
            pyspark341:
              display_name: "PySpark 3.4.1 + Python 3.11"
              kubespawner_override:
                image: jupyter/pyspark-notebook:spark-3.4.1
        cpu_guarantee: 2
        mem_guarantee: 8G
        cpu_limit: 4
        mem_limit: 8G
      cmd: null
    # NOTE:
    - display_name: Trainium (trn1)
      description: "Trainium | Karpenter AutoScaling"
      profile_options:
        image:
          display_name: "Image"
          choices:
            pytorch1131:
              display_name: "PyTorch 1.13.1 + torch-neuronx"
              default: true
              kubespawner_override:
                image: public.ecr.aws/data-on-eks/pytorch-neuronx:latest
            tflow2101:
              display_name: "Tensorflow 2.10.1 + tensorflow-neuronx"
              kubespawner_override:
                image: public.ecr.aws/data-on-eks/tensorflow-neuronx:latest
      kubespawner_override:
        tolerations:
          - key: aws.amazon.com/neuron
            operator: Exists
            effect: NoSchedule
        cpu_guarantee: 2
        mem_guarantee: 10G
        cpu_limit: 2
        mem_limit: 10G
        extra_resource_limits:
          aws.amazon.com/neuron: "1"
        cmd: "start-singleuser.sh"
    - display_name: Inferentia (inf2)
      description: "Inferentia | Karpenter AutoScaling"
      profile_options:
        image:
          display_name: "Image"
          choices:
            pytorch1131:
              display_name: "PyTorch + torch-neuronx"
              default: true
              kubespawner_override:
                image: public.ecr.aws/data-on-eks/pytorch-neuronx:latest
            tflow2101:
              display_name: "Tensorflow + tensorflow-neuronx"
              kubespawner_override:
                image: public.ecr.aws/data-on-eks/tensorflow-neuronx:latest
      kubespawner_override:
        tolerations:
          - key: aws.amazon.com/neuron
            operator: Exists
            effect: NoSchedule
        cpu_guarantee: 20
        mem_guarantee: 100G
        cpu_limit: 20
        mem_limit: 100G
        extra_resource_limits:
          aws.amazon.com/neuron: "1"
        cmd: null
    - display_name: Data Science (GPU + Time-Slicing - G5)
      default: true
      description: "GPU Time-Slicing with Single GPU VMs (G5 2x, 4x, 8x, 16x) | nvidia.com/gpu: 1 | Karpenter AutoScaling"
      kubespawner_override:
        # namespace: data-team-a
        image: cschranz/gpu-jupyter:v1.5_cuda-11.6_ubuntu-20.04_python-only
        tolerations:
          - key: "nvidia.com/gpu"
            operator: "Exists"
            effect: "NoSchedule"
        extra_resource_limits:
          nvidia.com/gpu: "1" # TIME-SLICING: Use a slice of GPU using time-slicing mode
        cpu_limit: 2
        mem_limit: 4G
        cpu_guarantee: 2
        mem_guarantee: 4G
        cmd: "start-singleuser.sh"
    # Karpenter doesn't support for requesting resources with MIG slices e.g., nvidia.com/mig-1g.5gb: 1,  or nvidia.com/mig-2g.20gb: 1 etc.
    # Hence, this profile relies on Managed node groups with GPU MIG enabled
    - display_name: Data Science (GPU + MIG on P4d.24xlarge)
      description: "GPU MIG with P4d instances | nvidia.com/mig-1g.5gb: 1 | Cluster Autoscaler"
      kubespawner_override:
        image: cschranz/gpu-jupyter:v1.5_cuda-11.6_ubuntu-20.04_python-only
        tolerations:
          - key: "nvidia.com/gpu"
            operator: "Exists"
            effect: "NoSchedule"
        extra_resource_guarantees:
          nvidia.com/mig-1g.5gb: 1 # or nvidia.com/mig-2g.10gb OR nvidia.com/mig-3g.20gb
        # extra_resource_limits:
        #   nvidia.com/gpu: "8" # TIME-SLICING: Use a slice of GPU using time-slicing mode
        cpu_guarantee: 2
        mem_guarantee: 10G
        cpu_limit: 2
        mem_limit: 10G
        cmd: "start-singleuser.sh"
    - display_name: Data Science (GPU - P4d.24xlarge)
      description: "GPU with P4d instances | Karpenter Autoscaler"
      kubespawner_override:
        image: cschranz/gpu-jupyter:v1.5_cuda-11.6_ubuntu-20.04_python-only
        tolerations:
          - key: "nvidia.com/gpu"
            operator: "Exists"
            effect: "NoSchedule"
        extra_resource_limits:
          nvidia.com/gpu: "8"
        cpu_guarantee: 2
        mem_guarantee: 10G
        cpu_limit: 2
        mem_limit: 10G
        cmd: "start-singleuser.sh"
  storage:
    type: "static"
    static:
      pvcName: "efs-persist"
      subPath: "{username}"
    extraVolumes:
    - name: jupyterhub-shared
      persistentVolumeClaim:
        claimName: efs-persist-shared
    extraVolumeMounts:
    - name: jupyterhub-shared
      mountPath: /home/shared
      readOnly: false
  serviceAccountName: ${jupyter_single_user_sa_name}
  allowPrivilegeEscalation: true
  extraPodConfig: # This is needed for Jovyan user running in every single pod, access the Service Account
    securityContext:
        fsGroup: 100
  extraEnv: # Sudo needed to configure the proper permissions to start the notebook instance
    GRANT_SUDO: "yes"
    NOTEBOOK_ARGS: "--allow-root"
    CHOWN_HOME: "yes"
    CHOWN_HOME_OPTS: "-R"
    CHOWN_EXTRA: "/home/shared"
    HUGGING_FACE_HUB_TOKEN:
      valueFrom:
        secretKeyRef:
          name: hf-token
          key: token
  uid: 0
  fsGid: 0
  cmd: null

# Optimizations configured according to this doc https://z2jh.jupyter.org/en/latest/administrator/optimization.html
scheduling:
  userScheduler:
    enabled: true
  podPriority:
    enabled: true
  userPlaceholder:
    enabled: false
    replicas: 1
#  userPods:
#    nodeAffinity:
#      matchNodePurpose: require # This will force single-user pods to use an specific karpenter provisioner

prePuller:
  hook:
    enabled: false
  continuous:
    # NOTE: if used with Karpenter, also add user-placeholders
    enabled: false

global:
  safeToShowValues: false
