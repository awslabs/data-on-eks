hub:
  db:
    pvc:
      storage: 50Gi
      storageClassName: gp3
  authenticatePrometheus: false

proxy:
  https:
    enabled: false
    type: offload
  service:
    type: ClusterIP
    # Disabled LoadBalancer type
#    annotations:
#      service.beta.kubernetes.io/aws-load-balancer-ssl-cert: "ssl_cert_arn"
#      service.beta.kubernetes.io/aws-load-balancer-ssl-ports: "https"
#      service.beta.kubernetes.io/aws-load-balancer-backend-protocol: "tcp"
#      service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "3600"
#      service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip
#      service.beta.kubernetes.io/aws-load-balancer-scheme: internal
#      service.beta.kubernetes.io/aws-load-balancer-type: external
#      service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: 'true'
#      service.beta.kubernetes.io/aws-load-balancer-ip-address-type: ipv4
singleuser:
  startTimeout: 1200 # 20 mins to spin up a notebook server for GPU including the image pull
  profileList:
    - display_name: Elyra (CPU)
      description: "Elyra Notebooks | Karpenter Autoscaling"
      kubespawner_override:
        image: public.ecr.aws/data-on-eks/elyra-jupyter:3.15.0
        node_selector:
          NodePool: default
        cpu_guarantee: 2
        mem_guarantee: 8G
        cpu_limit: 4
        mem_limit: 8G
      cmd: null
    - display_name: Data Engineering (CPU)
      description: "PySpark Notebooks | Karpenter AutoScaling"
      profile_options:
        image:
          display_name: "Image"
          choices:
            pyspark350:
              display_name: "PySpark 3.5.0 + Python 3.11"
              default: true
              kubespawner_override:
                image: jupyter/pyspark-notebook:spark-3.5.0
            pyspark341:
              display_name: "PySpark 3.4.1 + Python 3.11"
              kubespawner_override:
                image: jupyter/pyspark-notebook:spark-3.4.1
      kubespawner_override:
        node_selector:
          NodePool: default
        cpu_guarantee: 2
        mem_guarantee: 8G
        cpu_limit: 4
        mem_limit: 8G
      cmd: null
    # NOTE:
    - display_name: Trainium (trn1)
      description: "Trainium | Karpenter AutoScaling"
      profile_options:
        image:
          display_name: "Image"
          choices:
            pytorch1131:
              display_name: "PyTorch 1.13.1 + torch-neuronx"
              default: true
              kubespawner_override:
                image: public.ecr.aws/data-on-eks/pytorch-neuronx:latest
            tflow2101:
              display_name: "Tensorflow 2.10.1 + tensorflow-neuronx"
              kubespawner_override:
                image: public.ecr.aws/data-on-eks/tensorflow-neuronx:latest
      kubespawner_override:
        node_selector:
          NodePool: trainium
          hub.jupyter.org/node-purpose: user
        tolerations:
          - key: aws.amazon.com/neuroncore
            operator: Exists
            effect: NoSchedule
          - key: aws.amazon.com/neuron
            operator: Exists
            effect: NoSchedule
          - key: "hub.jupyter.org/dedicated" # According to optimization docs https://z2jh.jupyter.org/en/latest/administrator/optimization.html
            operator: "Equal"
            value: "user"
            effect: "NoSchedule"
        cpu_guarantee: 2
        mem_guarantee: 10G
        cpu_limit: 2
        mem_limit: 10G
        extra_resource_limits:
          aws.amazon.com/neuron: "1"
        cmd: "start-singleuser.sh"
    - display_name: Inferentia (inf2)
      description: "Inferentia | Karpenter AutoScaling"
      profile_options:
        image:
          display_name: "Image"
          choices:
            pytorch1131:
              display_name: "PyTorch + torch-neuronx"
              default: true
              kubespawner_override:
                image: public.ecr.aws/data-on-eks/pytorch-neuronx:latest
            tflow2101:
              display_name: "Tensorflow + tensorflow-neuronx"
              kubespawner_override:
                image: public.ecr.aws/data-on-eks/tensorflow-neuronx:latest
      kubespawner_override:
        node_selector:
          NodePool: inferentia
          hub.jupyter.org/node-purpose: user
        tolerations:
          - key: aws.amazon.com/neuroncore
            operator: Exists
            effect: NoSchedule
          - key: aws.amazon.com/neuron
            operator: Exists
            effect: NoSchedule
          - key: "hub.jupyter.org/dedicated" # According to optimization docs https://z2jh.jupyter.org/en/latest/administrator/optimization.html
            operator: "Equal"
            value: "user"
            effect: "NoSchedule"
        cpu_guarantee: 20
        mem_guarantee: 100G
        cpu_limit: 20
        mem_limit: 100G
        extra_resource_limits:
          aws.amazon.com/neuron: "1"
        cmd: null
    - display_name: Data Science (GPU + Time-Slicing - G5)
      default: true
      description: "GPU Time-Slicing with Single GPU VMs (G5 2x, 4x, 8x, 16x) | nvidia.com/gpu: 1 | Karpenter AutoScaling"
      kubespawner_override:
        # namespace: data-team-a
        image: cschranz/gpu-jupyter:v1.6_cuda-11.8_ubuntu-22.04_python-only
        node_selector:
          NodePool: gpu-ts # TIME-SLICING: Use this config with time-slicing mode
          hub.jupyter.org/node-purpose: user
        tolerations:
          - key: "nvidia.com/gpu"
            operator: "Exists"
            effect: "NoSchedule"
          - key: "hub.jupyter.org/dedicated" # According to optimization docs https://z2jh.jupyter.org/en/latest/administrator/optimization.html
            operator: "Equal"
            value: "user"
            effect: "NoSchedule"
        extra_resource_limits:
          nvidia.com/gpu: "1" # TIME-SLICING: Use a slice of GPU using time-slicing mode
        cpu_limit: 2
        mem_limit: 4G
        cpu_guarantee: 2
        mem_guarantee: 4G
        cmd: "start-singleuser.sh"
    # Karpenter doesn't support for requesting resources with MIG slices e.g., nvidia.com/mig-1g.5gb: 1,  or nvidia.com/mig-2g.20gb: 1 etc.
    # Hence, this profile relies on Managed node groups with GPU MIG enabled
    - display_name: Data Science (GPU + MIG on P4d.24xlarge)
      description: "GPU MIG with P4d instances | nvidia.com/mig-1g.5gb: 1 | Cluster Autoscaler"
      kubespawner_override:
        image: cschranz/gpu-jupyter:v1.6_cuda-11.8_ubuntu-22.04_python-only
        node_selector:
          provisioner: cluster-autoscaler
          node.kubernetes.io/instance-type: p4d.24xlarge
          hub.jupyter.org/node-purpose: user
        tolerations:
          - key: "nvidia.com/gpu"
            operator: "Exists"
            effect: "NoSchedule"
          - key: "hub.jupyter.org/dedicated" # According to optimization docs https://z2jh.jupyter.org/en/latest/administrator/optimization.html
            operator: "Equal"
            value: "user"
            effect: "NoSchedule"
        extra_resource_guarantees:
          nvidia.com/mig-1g.5gb: 1 # or nvidia.com/mig-2g.10gb OR nvidia.com/mig-3g.20gb
        # extra_resource_limits:
        #   nvidia.com/gpu: "8" # TIME-SLICING: Use a slice of GPU using time-slicing mode
        cpu_guarantee: 2
        mem_guarantee: 10G
        cpu_limit: 2
        mem_limit: 10G
        cmd: "start-singleuser.sh"
    - display_name: Data Science (GPU - P4d.24xlarge)
      description: "GPU with P4d instances | Karpenter Autoscaler"
      kubespawner_override:
        image: cschranz/gpu-jupyter:v1.6_cuda-11.8_ubuntu-22.04_python-only
        node_selector:
          NodePool: gpu-mig
          hub.jupyter.org/node-purpose: user
        tolerations:
          - key: "nvidia.com/gpu"
            operator: "Exists"
            effect: "NoSchedule"
          - key: "hub.jupyter.org/dedicated" # According to optimization docs https://z2jh.jupyter.org/en/latest/administrator/optimization.html
            operator: "Equal"
            value: "user"
            effect: "NoSchedule"
        extra_resource_limits:
          nvidia.com/gpu: "8"
        cpu_guarantee: 2
        mem_guarantee: 10G
        cpu_limit: 2
        mem_limit: 10G
        cmd: "start-singleuser.sh"
  storage:
    type: "static"
    static:
      pvcName: "efs-persist"
      subPath: "home/{username}"
    extraVolumes:
    - name: jupyterhub-shared
      persistentVolumeClaim:
        claimName: efs-persist-shared
    extraVolumeMounts:
    - name: jupyterhub-shared
      mountPath: /home/shared
      readOnly: false
  serviceAccountName: ${jupyter_single_user_sa_name}
  allowPrivilegeEscalation: true
  extraPodConfig: # This is needed for Jovyan user running in every single pod, access the Service Account
    securityContext:
        fsGroup: 100
  extraEnv: # Sudo needed to configure the proper permissions to start the notebook instance
    GRANT_SUDO: "yes"
    NOTEBOOK_ARGS: "--allow-root"
    CHOWN_HOME: "yes"
    CHOWN_HOME_OPTS: "-R"
    CHOWN_EXTRA: "/home/shared"
  uid: 0
  fsGid: 0
  cmd: null

# Optimizations configured according to this doc https://z2jh.jupyter.org/en/latest/administrator/optimization.html
scheduling:
  userScheduler:
    enabled: true
  podPriority:
    enabled: true
  userPlaceholder:
    enabled: false
    replicas: 1
  userPods:
    nodeAffinity:
      matchNodePurpose: require # This will force single-user pods to use an specific karpenter provisioner

prePuller:
  hook:
    enabled: false
  continuous:
    # NOTE: if used with Karpenter, also add user-placeholders
    enabled: false

global:
  safeToShowValues: false
