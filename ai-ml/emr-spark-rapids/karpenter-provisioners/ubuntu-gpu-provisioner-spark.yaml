# NOTE: Ubuntu 20.04 LTS is not supported by Karpenter yet. So, we are using Ubuntu 18.04 LTS
---
apiVersion: karpenter.sh/v1alpha5
kind: Provisioner
metadata:
  name: spark-ubuntu-gpu-karpenter
  namespace: karpenter
spec:
  kubeletConfiguration:
    containerRuntime: containerd
#    maxPods: 20
  requirements:
    - key: "karpenter.sh/capacity-type"
      operator: In
      values: [ "spot", "on-demand" ]
    - key: "topology.kubernetes.io/zone"
      operator: In
      values: [${azs}b] #Update the correct region and zone
    - key: "karpenter.k8s.aws/instance-family"
      operator: In
      values: ["g5"]
    - key: "karpenter.k8s.aws/instance-size"
      operator: In
      values: [ "xlarge", "2xlarge", "4xlarge", "8xlarge", "16xlarge" ]
    - key: "kubernetes.io/arch"
      operator: In
      values: ["amd64"]
  providerRef:
    name: spark-ubuntu-gpu-karpenter
  labels:
    type: karpenter
    provisioner: spark-ubuntu-gpu-karpenter
    NodeGroupType: spark-ubuntu-gpu-karpenter
  taints:
    - key: spark-ubuntu-gpu-karpenter
      value: 'true'
      effect: NoSchedule
  ttlSecondsAfterEmpty: 120 # optional, but never scales down if not set

---
apiVersion: karpenter.k8s.aws/v1alpha1
kind: AWSNodeTemplate
metadata:
  name: spark-ubuntu-gpu-karpenter
  namespace: karpenter
spec:
  amiFamily: Ubuntu
  blockDeviceMappings:
    - deviceName: /dev/sda1
      ebs:
        volumeSize: 50Gi
        volumeType: gp3
        encrypted: true
        deleteOnTermination: true
  metadataOptions:
    httpEndpoint: enabled
    httpProtocolIPv6: disabled
    httpPutResponseHopLimit: 2
    httpTokens: required
  subnetSelector:
    Name: "${eks_cluster_id}-private*"        # Name of the Subnets to spin up the nodes
  securityGroupSelector:                      # required, when not using launchTemplate
    Name: "${eks_cluster_id}-node*"           # name of the SecurityGroup to be used with Nodes
  #  instanceProfile: ""      # optional, if already set in controller args
  #RAID0 config example
  userData: |
    MIME-Version: 1.0
    Content-Type: multipart/mixed; boundary="BOUNDARY"

    --BOUNDARY
    Content-Type: text/x-shellscript; charset="us-ascii"

    #!/bin/bash
    echo "Running a custom user data script"
    set -ex
    apt-get update
    apt-get install -y nvme-cli mdadm xfsprogs

    # Fetch the list of NVMe devices
    DEVICES=$(lsblk -d -o NAME | grep nvme)

    DISK_ARRAY=()

    for DEV in $DEVICES
    do
      # Exclude the root disk, /dev/nvme0n1, from the list of devices
      if [[ $${DEV} != "nvme0n1" ]]; then
        NVME_INFO=$(nvme id-ctrl --raw-binary "/dev/$${DEV}" | cut -c3073-3104 | tr -s ' ' | sed 's/ $//g')
        # Check if the device is Amazon EC2 NVMe Instance Storage
        if [[ $${NVME_INFO} == *"ephemeral"* ]]; then
          DISK_ARRAY+=("/dev/$${DEV}")
        fi
      fi
    done

    DISK_COUNT=$${#DISK_ARRAY[@]}

    if [ $${DISK_COUNT} -eq 0 ]; then
      echo "No NVMe SSD disks available. No further action needed."
    else
      if [ $${DISK_COUNT} -eq 1 ]; then
        TARGET_DEV=$${DISK_ARRAY[0]}
        mkfs.xfs $${TARGET_DEV}
      else
        mdadm --create --verbose /dev/md0 --level=0 --raid-devices=$${DISK_COUNT} $${DISK_ARRAY[@]}
        mkfs.xfs /dev/md0
        TARGET_DEV=/dev/md0
      fi

      mkdir -p /local1
      echo $${TARGET_DEV} /local1 xfs defaults,noatime 1 2 >> /etc/fstab
      mount -a
      /usr/bin/chown -hR +999:+1000 /local1
    fi

    --BOUNDARY--

  tags:
    InstanceType: "spark-ubuntu-gpu-karpenter"    # optional, add tags for your own use
