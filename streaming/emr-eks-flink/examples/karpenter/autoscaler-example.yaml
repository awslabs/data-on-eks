# NOTE: Make sure you replace <ENTER_S3_BUCKET> with your S3 Bucket before running this job.
# Replace the <JOB_EXECUTION_ROLE_ARN> with the flink_job_execution_role_arn output.
---
apiVersion: flink.apache.org/v1beta1
kind: FlinkDeployment
metadata:
  name: autoscaler-example
  namespace: flink-team-a-ns
spec:
  imagePullPolicy: Always
  emrReleaseLabel: "emr-7.9.0-flink-latest"
  flinkVersion: v1_18
  flinkConfiguration:

    taskmanager.numberOfTaskSlots: "4"
    # Autotuning parameters
    kubernetes.operator.job.autoscaler.enabled: "true"
    kubernetes.operator.job.autoscaler.stabilization.interval: 1m
    kubernetes.operator.job.autoscaler.metrics.window: 1m
    kubernetes.operator.job.autoscaler.target.utilization: "0.5"
    kubernetes.operator.job.autoscaler.target.utilization.boundary: "0.2"
    kubernetes.operator.job.autoscaler.restart.time: 1m
    kubernetes.operator.job.autoscaler.catch-up.duration: 5m
    kubernetes.operator.job.autoscaler.vertex.exclude.ids: ""
    pipeline.max-parallelism: "32"
    pipeline.operator-chaining: "true"

    execution.checkpointing.interval: "3000"
    # ebs local-recovery
    task.local-recovery.ebs.enable: "false"
    state.backend.local-recovery: "true"
    kubernetes.taskmanager.local-recovery.persistentVolumeClaim.sizeLimit: 10Gi
    execution.checkpointing.externalized-checkpoint-retention: RETAIN_ON_CANCELLATION
    # log-based incremental checkpoint
    state.backend.changelog.enabled: "false"
    state.backend.changelog.storage: filesystem
    dstl.dfs.base-path: s3://${S3_BUCKET}/flink/autoscaling/changelog
    state.backend: rocksdb
    state.backend.incremental: "true"
    # Fine-grained recovery
    jobmanager.execution.failover-strategy: region
    restart-strategy: fixed-delay
    restart-strategy.fixed-delay.attempts: "10"
    restart-strategy.fixed-delay.delay: 3 s
    # graceful decommisioning
    cluster.taskmanager.graceful-decommission.enabled: "true"
    jobmanager.adaptive-scheduler.combined-restart.enabled: "true"
    jobmanager.adaptive-scheduler.combined-restart.window-interval : "1m"

    jobmanager.scheduler: adaptive
    # Replace with s3 bucket in your own account
    state.checkpoints.dir: s3://$S3_BUCKET/checkpoints
    state.savepoints.dir: s3://$S3_BUCKET/savepoints

  # Replace this execution role ARN with your own
  executionRoleArn: $FLINK_JOB_ROLE

  podTemplate:
    apiVersion: v1
    kind: Pod
    metadata:
      name: pod-template
    spec:
      nodeSelector:
        NodeGroupType: "FlinkComputeOptimized"

  jobManager:
    highAvailabilityEnabled: true
    # Replace with s3 bucket in your own account
    storageDir: s3://$S3_BUCKET/data/autoscaler-example/jobmanager
    resource:
      memory: "1024m"
      cpu: 1

  taskManager:
    replicas: 2
    resource:
      memory: "1024m"
      cpu: 1

  job:
    # if you have your job jar in S3 bucket you can use that path as well
    jarURI: local:///opt/flink/examples/streaming/AutoscalingExample.jar
    entryClass: org.apache.flink.streaming.examples.autoscaling.LoadSimulationPipeline
    args:
      - "--maxLoadPerTask"
      - "1;2;4;8;16;"
      - "--repeatsAfterMinutes"
      - "60"
    parallelism: 1
    upgradeMode: last-state



  monitoringConfiguration:
    s3MonitoringConfiguration:
      logUri: $S3_BUCKET/logs
    cloudWatchMonitoringConfiguration:
       logGroupName: /aws/emr-flink/flink-team-a
    sideCarResources:
      limits:
        cpuLimit: 500m
        memoryLimit: 250Mi
    containerLogRotationConfiguration:
        rotationSize: 2GB
        maxFilesToKeep: "10"
