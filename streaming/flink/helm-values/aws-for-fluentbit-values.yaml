global:

#hostNetwork and dnsPolicy are critical for enabling large clusters to avoid making calls to API server
# see this link https://docs.fluentbit.io/manual/pipeline/filters/kubernetes#optional-feature-using-kubelet-to-get-metadata
hostNetwork: true
dnsPolicy: ClusterFirstWithHostNet

service:
  parsersFiles:
    - /fluent-bit/parsers/parsers.conf
  extraParsers: |
    [PARSER]
        Name    kubernetes
        Format  regex
        Regex   ^(?<namespace_name>[^_]+)\.(?<container_name>.+)\.(?<pod_name>[a-z0-9](?:[-a-z0-9]*[a-z0-9])?(?:\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*)\.(?<docker_id>[a-z0-9]{64})-$

input:
  name: "tail"
  enabled: true
  tag: "systempods.<namespace_name>.<container_name>.<pod_name>.<docker_id>-"
  path: "/var/log/containers/*.log"
  db: "/var/log/flb_kube.db"
  memBufLimit: 5MB
  skipLongLines: "On"
  refreshInterval: 10
  extraInputs: |
    multiline.parser  docker, cri
    Tag_Regex         (?<pod_name>[a-z0-9](?:[-a-z0-9]*[a-z0-9])?(?:\\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*)_(?<namespace_name>[^_]+)_(?<container_name>.+)-(?<docker_id>[a-z0-9]{64})\.log$


# NOTE: extraFilters config for using Kubelet to get the Metadata instead of talking to API server for large clusters
filter:
  name: "kubernetes"
  match: "systempods.*"
  kubeURL: "https://kubernetes.default.svc.cluster.local:443"
  mergeLog: "On"
  mergeLogKey: "log_processed"
  keepLog: "On"
  k8sLoggingParser: "On"
  k8sLoggingExclude: "Off"
  bufferSize: "0"
  extraFilters: |
    Kube_Tag_Prefix     systempods.
    Regex_Parser        kubernetes
    Labels              On
    Annotations         Off
    Use_Kubelet         true
    Kubelet_Port        10250
    Kube_CA_File        /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    Kube_Token_File     /var/run/secrets/kubernetes.io/serviceaccount/token

# CATION: Do not use `cloudwatch` plugin. This Golang Plugin is not recommended by AWS anymore instead use C plugin(`cloudWatchLogs`) for better performance.
# cloudWatch:
#   enabled: false

#Â This is a new high performance C Plugin for CloudWatchLogs. See docs here https://docs.fluentbit.io/manual/pipeline/outputs/cloudwatch
cloudWatchLogs:
  enabled: true
  match: "systempods.*"
  region: ${region}
  logGroupName: ${cloudwatch_log_group}
  autoCreateGroup: false
  extraOutputs: |
    log_key               log

#----------------------------------------------------------#
# OUTPUT logs to S3
#----------------------------------------------------------#

# This is an example for writing logs to S3 bucket.
# This example writes system pod logs and spark logs into dedicated prefix.
# This second output is using the rewrite_tag filter commented above

additionalOutputs: |
  [OUTPUT]
      Name                            s3
      Match                           systempods.*
      region                          ${region}
      bucket                          ${s3_bucket_name}
      total_file_size                 100M
      s3_key_format                   /${cluster_name}/system-pod-logs/$TAG[1]/$TAG[2]/$TAG[3]/$TAG[3]_%H%M%S_$UUID.log
      s3_key_format_tag_delimiters    ..
      store_dir                       /home/ec2-user/buffer
      upload_timeout                  10m
      log_key                         log


# Resource config for large clusters
resources:
  limits:
    cpu: 1000m
    memory: 1500Mi
  requests:
    cpu: 500m
    memory: 500Mi

## Assign a PriorityClassName to pods if set
priorityClassName: system-node-critical

# This toleration allows Daemonset pod to be scheduled on any node, regardless of their Taints.
tolerations:
  - operator: Exists
