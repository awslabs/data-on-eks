<!doctype html><html lang=en dir=ltr class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-blueprints/data-analytics/spark-operator-beam" data-has-hydrated=false><meta charset=UTF-8><meta name=generator content="Docusaurus v3.8.1"><title data-rh=true>Run Apache Beam pipelines with Spark on EKS | Data on EKS</title><meta data-rh=true name=viewport content="width=device-width, initial-scale=1.0"><meta data-rh=true name=twitter:card content=summary_large_image><meta data-rh=true property=og:url content=https://awslabs.github.io/data-on-eks/docs/blueprints/data-analytics/spark-operator-beam><meta data-rh=true property=og:locale content=en><meta data-rh=true name=docusaurus_locale content=en><meta data-rh=true name=docsearch:language content=en><meta data-rh=true name=docusaurus_version content=current><meta data-rh=true name=docusaurus_tag content=docs-default-current><meta data-rh=true name=docsearch:version content=current><meta data-rh=true name=docsearch:docusaurus_tag content=docs-default-current><meta data-rh=true property=og:title content="Run Apache Beam pipelines with Spark on EKS | Data on EKS"><meta data-rh=true name=description content="Apache Beam (Beam) is a flexible programming model for building batch and streaming data processing pipelines.  With Beam, developers can write code once and run it on various execution engines, such as Apache Spark and Apache Flink. This flexibility allows organizations to leverage the strengths of different execution engines while maintaining a consistent codebase, reducing the complexity of managing multiple codebases and minimizing the risk of vendor lock-in."><meta data-rh=true property=og:description content="Apache Beam (Beam) is a flexible programming model for building batch and streaming data processing pipelines.  With Beam, developers can write code once and run it on various execution engines, such as Apache Spark and Apache Flink. This flexibility allows organizations to leverage the strengths of different execution engines while maintaining a consistent codebase, reducing the complexity of managing multiple codebases and minimizing the risk of vendor lock-in."><link data-rh=true rel=icon href=/data-on-eks/img/header-icon.png><link data-rh=true rel=canonical href=https://awslabs.github.io/data-on-eks/docs/blueprints/data-analytics/spark-operator-beam><link data-rh=true rel=alternate href=https://awslabs.github.io/data-on-eks/docs/blueprints/data-analytics/spark-operator-beam hreflang=en><link data-rh=true rel=alternate href=https://awslabs.github.io/data-on-eks/docs/blueprints/data-analytics/spark-operator-beam hreflang=x-default><script data-rh=true type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://awslabs.github.io/data-on-eks/docs/category/data-analytics-on-eks","name":"Data Analytics on EKS","position":1},{"@type":"ListItem","item":"https://awslabs.github.io/data-on-eks/docs/blueprints/data-analytics/spark-operator-beam","name":"Apache Beam on EKS","position":2}]}</script><link rel=stylesheet href=/data-on-eks/assets/css/styles.03e7d5c7.css><script src=/data-on-eks/assets/js/runtime~main.34aecab1.js defer></script><script src=/data-on-eks/assets/js/main.983e8b43.js defer></script><body class=navigation-with-keyboard><svg xmlns=http://www.w3.org/2000/svg style="display: none;"><defs>
<symbol id=theme-svg-external-link viewBox="0 0 24 24"><path fill=currentColor d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{for(var[t,e]of new URLSearchParams(window.location.search).entries())if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id=__docusaurus><div role=region aria-label="Skip to main content"><a class=skipToContent_fXgn href=#__docusaurus_skipToContent_fallback>Skip to main content</a></div><nav aria-label=Main class="theme-layout-navbar navbar navbar--fixed-top"><div class=navbar__inner><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded=false class="navbar__toggle clean-btn" type=button><svg width=30 height=30 viewBox="0 0 30 30" aria-hidden=true><path stroke=currentColor stroke-linecap=round stroke-miterlimit=10 stroke-width=2 d="M4 7h22M4 15h22M4 23h22"/></svg></button><a class=navbar__brand href=/data-on-eks/><div class=navbar__logo><img src=/data-on-eks/img/header-icon.png alt="DoEKS Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src=/data-on-eks/img/header-icon.png alt="DoEKS Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a aria-current=page class="navbar__item navbar__link navbar__link--active" href=/data-on-eks/docs/blueprints/data-analytics>Blueprints</a><a class="navbar__item navbar__link" href=/data-on-eks/docs/bestpractices/intro>Best Practices</a><a class="navbar__item navbar__link" href=/data-on-eks/docs/benchmarks/emr-on-eks>Benchmarks</a><a class="navbar__item navbar__link" href=/data-on-eks/docs/resources/intro>Resources</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href=https://github.com/awslabs/data-on-eks target=_blank rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width=13.5 height=13.5 aria-hidden=true class=iconExternalLink_nPIU><use href=#theme-svg-external-link /></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type=button disabled title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width=24 height=24 aria-hidden=true class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill=currentColor d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"/></svg><svg viewBox="0 0 24 24" width=24 height=24 aria-hidden=true class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill=currentColor d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"/></svg><svg viewBox="0 0 24 24" width=24 height=24 aria-hidden=true class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill=currentColor d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"/></svg></button></div><div class=navbarSearchContainer_Bca1><div class=navbar__search><span aria-label="expand searchbar" role=button class=search-icon tabindex=0></span><input id=search_input_react type=search placeholder=Loading... aria-label=Search class="navbar__search-input search-bar" disabled></div></div></div></div><div role=presentation class=navbar-sidebar__backdrop></div></nav><div id=__docusaurus_skipToContent_fallback class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class=docsWrapper_hBAB><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type=button></button><div class=docRoot_UBD9><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class=sidebarViewport_aRkj><div class=sidebar_njMd><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist menu__link--active" href=/data-on-eks/docs/category/data-analytics-on-eks>Data Analytics on EKS</a><button aria-label="Collapse sidebar category 'Data Analytics on EKS'" aria-expanded=true type=button class="clean-btn menu__caret"></button></div><ul class=menu__list><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/data-on-eks/docs/blueprints/data-analytics>Introduction</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/data-on-eks/docs/blueprints/data-analytics/spark-operator-yunikorn>Spark Operator with YuniKorn</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/data-on-eks/docs/blueprints/data-analytics/spark-eks-ipv6>Spark Operator on EKS with IPv6</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/data-on-eks/docs/blueprints/data-analytics/spark-operator-s3tables>S3 Tables with EKS</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/data-on-eks/docs/blueprints/data-analytics/observability-spark-on-eks>Spark Observability on EKS</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current=page tabindex=0 href=/data-on-eks/docs/blueprints/data-analytics/spark-operator-beam>Apache Beam on EKS</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/data-on-eks/docs/blueprints/data-analytics/datahub-on-eks>DataHub on EKS</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/data-on-eks/docs/blueprints/data-analytics/ray-data-processing>Ray Data on EKS</a><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class=menu__link tabindex=0 href=/data-on-eks/docs/blueprints/data-analytics/superset-on-eks>Superset on EKS</a></ul><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/data-on-eks/docs/category/amazon-emr-on-eks>Amazon EMR on EKS</a><button aria-label="Expand sidebar category 'Amazon EMR on EKS'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/data-on-eks/docs/category/streaming-platforms-on-eks>Streaming Platforms on EKS</a><button aria-label="Expand sidebar category 'Streaming Platforms on EKS'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/data-on-eks/docs/category/job-schedulers-on-eks>Job Schedulers on EKS</a><button aria-label="Expand sidebar category 'Job Schedulers on EKS'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class=menu__list-item-collapsible><a class="menu__link menu__link--sublist" href=/data-on-eks/docs/category/distributed-databases-on-eks>Distributed Databases on EKS</a><button aria-label="Expand sidebar category 'Distributed Databases on EKS'" aria-expanded=false type=button class="clean-btn menu__caret"></button></div><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class=menu__link href=/data-on-eks/docs/blueprints/troubleshooting>Troubleshooting</a></ul></nav><button type=button title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width=20 height=20 aria-hidden=true class=collapseSidebarButtonIcon_kv0_><g fill=#7a7a7a><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"/><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"/></g></svg></button></div></div></aside><main class=docMainContainer_TBSr><div class="container padding-top--md padding-bottom--lg"><div class=row><div class=col><div class=docItemContainer_Djhp><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label=Breadcrumbs><ul class=breadcrumbs><li class=breadcrumbs__item><a aria-label="Home page" class=breadcrumbs__link href=/data-on-eks/><svg viewBox="0 0 24 24" class=breadcrumbHomeIcon_YNFT><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill=currentColor /></svg></a><li class=breadcrumbs__item><a class=breadcrumbs__link href=/data-on-eks/docs/category/data-analytics-on-eks><span>Data Analytics on EKS</span></a><li class="breadcrumbs__item breadcrumbs__item--active"><span class=breadcrumbs__link>Apache Beam on EKS</span></ul></nav><div class="theme-doc-markdown markdown"><header><h1>Run Apache Beam pipelines with Spark on EKS</h1></header>
<p><a href=https://beam.apache.org/get-started/beam-overview/ target=_blank rel="noopener noreferrer">Apache Beam (Beam)</a> is a flexible programming model for building batch and streaming data processing pipelines.  With Beam, developers can write code once and run it on various execution engines, such as <em>Apache Spark</em> and <em>Apache Flink</em>. This flexibility allows organizations to leverage the strengths of different execution engines while maintaining a consistent codebase, reducing the complexity of managing multiple codebases and minimizing the risk of vendor lock-in.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=beam-on-amazon-eks>Beam on Amazon EKS<a href=#beam-on-amazon-eks class=hash-link aria-label="Direct link to Beam on Amazon EKS" title="Direct link to Beam on Amazon EKS">​</a></h2>
<p>The Spark Operator for Kubernetes simplifies the deployment and management of Apache Spark on Kubernetes. By using the Spark Operator, we can directly submit Apache Beam pipelines as Spark Applications and deploy and manage them on EKS cluster, taking advantage of features such as automatic scaling and self-healing capabilities on the robust and managed infrastructure of EKS.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=solution-overview>Solution overview<a href=#solution-overview class=hash-link aria-label="Direct link to Solution overview" title="Direct link to Solution overview">​</a></h2>
<p>In this solution, we will show how to deploy your Beam pipeline, written in Python, on an EKS cluster with Spark Operator.  It uses the example pipeline from Apache Beam <a href=https://github.com/apache/beam/tree/master/sdks/python target=_blank rel="noopener noreferrer">github repo</a>.</p>
<p><img decoding=async loading=lazy alt=BeamOnEKS src=/data-on-eks/assets/images/spark-operator-beam-6218f0e0622e80533e34df948ddac309.png width=1094 height=461 class=img_ev3q></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id=deploy-beam-pipeline>Deploy Beam pipeline<a href=#deploy-beam-pipeline class=hash-link aria-label="Direct link to Deploy Beam pipeline" title="Direct link to Deploy Beam pipeline">​</a></h2>
<div class=collapsibleContent_q3kw><div class=header_QCEw><h2><span>Deploying the Spark-Operator-on-EKS solution</span></h2><span class=icon_PckA>👈</span></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=step-1-build-custom-docker-image-with-spark-and-beam-sdk>Step 1: Build custom Docker Image with Spark and Beam SDK<a href=#step-1-build-custom-docker-image-with-spark-and-beam-sdk class=hash-link aria-label="Direct link to Step 1: Build custom Docker Image with Spark and Beam SDK" title="Direct link to Step 1: Build custom Docker Image with Spark and Beam SDK">​</a></h3>
<p>Create a custom spark runtime image from the office spark base image, with a Python virtual environment and Apache Beam SDK pre-installed.</p>
<ul>
<li>Review the sample <a href=https://github.com/awslabs/data-on-eks/blob/main/analytics/terraform/spark-k8s-operator/examples/beam/Dockerfile target=_blank rel="noopener noreferrer">Dockerfile</a></li>
<li>Customize the Dockerfile as needed for your environment</li>
<li>Build the Docker image and push the image to ECR</li>
</ul>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token builtin class-name">cd</span><span class="token plain"> examples/beam</span><br></span><span class=token-line style=color:#393A34><span class="token plain">aws ecr create-repository --repository-name beam-spark-repo </span><span class="token parameter variable" style=color:#36acaa>--region</span><span class="token plain"> us-east-1</span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token function" style=color:#d73a49>docker</span><span class="token plain"> build </span><span class="token builtin class-name">.</span><span class="token plain"> </span><span class="token parameter variable" style=color:#36acaa>--tag</span><span class="token plain"> </span><span class="token variable" style=color:#36acaa>${ACCOUNT_ID}</span><span class="token plain">.dkr.ecr.us-east-1.amazonaws.com/beam-spark-repo:eks-beam-image </span><span class="token parameter variable" style=color:#36acaa>--platform</span><span class="token plain"> linux/amd64,linux/arm64</span><br></span><span class=token-line style=color:#393A34><span class="token plain">aws ecr get-login-password </span><span class="token parameter variable" style=color:#36acaa>--region</span><span class="token plain"> us-east-1 </span><span class="token operator" style=color:#393A34>|</span><span class="token plain"> </span><span class="token function" style=color:#d73a49>docker</span><span class="token plain"> login </span><span class="token parameter variable" style=color:#36acaa>--username</span><span class="token plain"> AWS --password-stdin </span><span class="token variable" style=color:#36acaa>${ACCOUNT_ID}</span><span class="token plain">.dkr.ecr.us-east-1.amazonaws.com</span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token function" style=color:#d73a49>docker</span><span class="token plain"> push </span><span class="token variable" style=color:#36acaa>${ACCOUNT_ID}</span><span class="token plain">.dkr.ecr.us-east-1.amazonaws.com/beam-spark-repo:eks-beam-image</span><br></span></code></pre></div></div>
<p>We have created a docker image and published in ECR.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=step-2-build-and-package-the-beam-pipeline-with-dependencies>Step 2: Build and package the Beam pipeline with dependencies<a href=#step-2-build-and-package-the-beam-pipeline-with-dependencies class=hash-link aria-label="Direct link to Step 2: Build and package the Beam pipeline with dependencies" title="Direct link to Step 2: Build and package the Beam pipeline with dependencies">​</a></h3>
<p>With python 3.11 installed, create a Python virtual environment and install dependencies required for building the Beam pipeline:</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">python3 </span><span class="token parameter variable" style=color:#36acaa>-m</span><span class="token plain"> venv build-environment </span><span class="token operator" style=color:#393A34>&&</span><span class="token plain"> </span><span class="token punctuation" style=color:#393A34>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token builtin class-name">source</span><span class="token plain"> build-environment/bin/activate </span><span class="token operator" style=color:#393A34>&&</span><span class="token plain"> </span><span class="token punctuation" style=color:#393A34>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">python3 </span><span class="token parameter variable" style=color:#36acaa>-m</span><span class="token plain"> pip </span><span class="token function" style=color:#d73a49>install</span><span class="token plain"> </span><span class="token parameter variable" style=color:#36acaa>--upgrade</span><span class="token plain"> pip </span><span class="token operator" style=color:#393A34>&&</span><span class="token plain"> </span><span class="token punctuation" style=color:#393A34>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">python3 </span><span class="token parameter variable" style=color:#36acaa>-m</span><span class="token plain"> pip </span><span class="token function" style=color:#d73a49>install</span><span class="token plain"> </span><span class="token assign-left variable" style=color:#36acaa>apache_beam</span><span class="token operator" style=color:#393A34>==</span><span class="token number" style=color:#36acaa>2.58</span><span class="token plain">.0 </span><span class="token punctuation" style=color:#393A34>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    s3fs </span><span class="token punctuation" style=color:#393A34>\</span><span class="token plain"></span><br></span><span class=token-line style=color:#393A34><span class="token plain">    boto3</span><br></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br></span></code></pre></div></div>
<p>Download the <a href=https://raw.githubusercontent.com/apache/beam/master/sdks/python/apache_beam/examples/wordcount.py target=_blank rel="noopener noreferrer">wordcount.py</a> example pipeline and the sample input file. The wordcount Python example demonstrates an Apache Beam pipeline with the following stages: read files, split words, map, group, and sum word counts, and write output to files.</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token function" style=color:#d73a49>curl</span><span class="token plain"> </span><span class="token parameter variable" style=color:#36acaa>-O</span><span class="token plain"> https://raw.githubusercontent.com/apache/beam/master/sdks/python/apache_beam/examples/wordcount.py</span><br></span><span class=token-line style=color:#393A34><span class="token plain" style=display:inline-block></span><br></span><span class=token-line style=color:#393A34><span class="token plain"></span><span class="token function" style=color:#d73a49>curl</span><span class="token plain"> </span><span class="token parameter variable" style=color:#36acaa>-O</span><span class="token plain"> https://raw.githubusercontent.com/cs109/2015/master/Lectures/Lecture15b/sparklect/shakes/kinglear.txt</span><br></span></code></pre></div></div>
<p>Upload the input text file to the S3 bucket.</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">aws s3 </span><span class="token function" style=color:#d73a49>cp</span><span class="token plain"> kinglear.txt s3://</span><span class="token variable" style=color:#36acaa>${S3_BUCKET}</span><span class="token plain">/</span><br></span></code></pre></div></div>
<p>To run an Apache Beam Python pipeline on Spark, you may package the pipeline and all its dependencies into a single jar file.  Use the below command to create the "fat" jar for the wordcount pipeline with all parameters, without actually executing the pipeline:</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">python3 wordcount.py </span><span class="token parameter variable" style=color:#36acaa>--output_executable_path</span><span class="token operator" style=color:#393A34>=</span><span class="token plain">./wordcountApp.jar </span><span class="token punctuation" style=color:#393A34>\</span><span class="token plain"> </span><span class="token parameter variable" style=color:#36acaa>--runner</span><span class="token operator" style=color:#393A34>=</span><span class="token plain">SparkRunner </span><span class="token punctuation" style=color:#393A34>\</span><span class="token plain"> </span><span class="token parameter variable" style=color:#36acaa>--environment_type</span><span class="token operator" style=color:#393A34>=</span><span class="token plain">PROCESS </span><span class="token punctuation" style=color:#393A34>\</span><span class="token plain"> </span><span class="token parameter variable" style=color:#36acaa>--environment_config</span><span class="token operator" style=color:#393A34>=</span><span class="token string" style=color:#e3116c>'{"command":"/opt/apache/beam/boot"}'</span><span class="token plain"> </span><span class="token punctuation" style=color:#393A34>\</span><span class="token plain"> </span><span class="token parameter variable" style=color:#36acaa>--input</span><span class="token operator" style=color:#393A34>=</span><span class="token plain">s3://</span><span class="token variable" style=color:#36acaa>${S3_BUCKET}</span><span class="token plain">/kinglear.txt </span><span class="token punctuation" style=color:#393A34>\</span><span class="token plain"> </span><span class="token parameter variable" style=color:#36acaa>--output</span><span class="token operator" style=color:#393A34>=</span><span class="token plain">s3://</span><span class="token variable" style=color:#36acaa>${S3_BUCKET}</span><span class="token plain">/output.txt</span><br></span></code></pre></div></div>
<p>Upload the jar file to the S3 bucket to be used by the spark application.</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">aws s3 </span><span class="token function" style=color:#d73a49>cp</span><span class="token plain"> wordcountApp.jar s3://</span><span class="token variable" style=color:#36acaa>${S3_BUCKET}</span><span class="token plain">/app/</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=step-3-create-and-run-the-pipeline-as-sparkapplication>Step 3: Create and run the pipeline as SparkApplication<a href=#step-3-create-and-run-the-pipeline-as-sparkapplication class=hash-link aria-label="Direct link to Step 3: Create and run the pipeline as SparkApplication" title="Direct link to Step 3: Create and run the pipeline as SparkApplication">​</a></h3>
<p>In this step, we create the manifest file for the SparkApplication object to submit the Apache Beam pipeline as a Spark application. Run the below commands to create a BeamApp.yaml file substituting the ACCOUNT_ID and S3_BUCKET values from the build environment.</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">envsubst </span><span class="token operator" style=color:#393A34>&lt;</span><span class="token plain"> beamapp.yaml </span><span class="token operator" style=color:#393A34>></span><span class="token plain"> beamapp.yaml</span><br></span></code></pre></div></div>
<p>This command will replace the env variables in file beamapp.yaml.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=step-4-execute-spark-job>Step 4: Execute Spark Job<a href=#step-4-execute-spark-job class=hash-link aria-label="Direct link to Step 4: Execute Spark Job" title="Direct link to Step 4: Execute Spark Job">​</a></h3>
<p>Apply the YAML configuration file to create the SparkApplication on your EKS cluster to execute the Beam pipeline:</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">kubectl apply </span><span class="token parameter variable" style=color:#36acaa>-f</span><span class="token plain"> beamapp.yaml</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id=step-5-monitor-and-review-the-pipeline-job>Step 5: Monitor and review the pipeline job<a href=#step-5-monitor-and-review-the-pipeline-job class=hash-link aria-label="Direct link to Step 5: Monitor and review the pipeline job" title="Direct link to Step 5: Monitor and review the pipeline job">​</a></h3>
<p>Monitor and review the pipeline job
The word count Beam pipeline may take a couple of minutes to execute.  There are a few ways to monitor its status and review job details.</p>
<ol>
<li>We can use the Spark history server to check the running job</li>
</ol>
<p>We used the spark-k8s-operator pattern to create the EKS cluster, which had already installed and configured a spark-history-server.  Run the command below to start port-forwarding, then click the Preview menu and select Preview Running Application:</p>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">kubectl port-forward svc/spark-history-server </span><span class="token number" style=color:#36acaa>8080</span><span class="token plain">:80 </span><span class="token parameter variable" style=color:#36acaa>-n</span><span class="token plain"> spark-history-server</span><br></span></code></pre></div></div>
<p>Open a new browser window and go to this address: <a href=http://127.0.0.1:8080/ target=_blank rel="noopener noreferrer">http://127.0.0.1:8080/</a>.</p>
<ol start=2>
<li>Once the job completes successfully, in about 2 minutes, the output files (output.txt-*) containing words found in the input text and the count of each occurrence can be downloaded from the S3 bucket by running the below commands to copy the outputs to your build environment.</li>
</ol>
<div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-sh codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token function" style=color:#d73a49>mkdir</span><span class="token plain"> job_output </span><span class="token operator" style=color:#393A34>&&</span><span class="token plain">  </span><span class="token builtin class-name">cd</span><span class="token plain"> job_output</span><br></span><span class=token-line style=color:#393A34><span class="token plain">aws s3 </span><span class="token function" style=color:#d73a49>sync</span><span class="token plain"> s3://</span><span class="token variable" style=color:#36acaa>$S3_BUCKET</span><span class="token plain">/ </span><span class="token builtin class-name">.</span><span class="token plain"> </span><span class="token parameter variable" style=color:#36acaa>--include</span><span class="token plain"> </span><span class="token string" style=color:#e3116c>"output.txt-*"</span><span class="token plain"> </span><span class="token parameter variable" style=color:#36acaa>--exclude</span><span class="token plain"> </span><span class="token string" style=color:#e3116c>"kinglear*"</span><span class="token plain"> </span><span class="token parameter variable" style=color:#36acaa>--exclude</span><span class="token plain"> app/*</span><br></span></code></pre></div></div>
<p>Output looks like below:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style=--prism-color:#393A34;--prism-background-color:#f6f8fa><div class=codeBlockContent_QJqH><pre tabindex=0 class="prism-code language-text codeBlock_bY9V thin-scrollbar" style=color:#393A34;background-color:#f6f8fa><code class=codeBlockLines_e6Vv><span class=token-line style=color:#393A34><span class="token plain">...</span><br></span><span class=token-line style=color:#393A34><span class="token plain">particular: 3</span><br></span><span class=token-line style=color:#393A34><span class="token plain">wish: 2</span><br></span><span class=token-line style=color:#393A34><span class="token plain">Either: 3</span><br></span><span class=token-line style=color:#393A34><span class="token plain">benison: 2</span><br></span><span class=token-line style=color:#393A34><span class="token plain">Duke: 30</span><br></span><span class=token-line style=color:#393A34><span class="token plain">Contending: 1</span><br></span><span class=token-line style=color:#393A34><span class="token plain">say'st: 4</span><br></span><span class=token-line style=color:#393A34><span class="token plain">attendance: 1</span><br></span><span class=token-line style=color:#393A34><span class="token plain">...</span><br></span></code></pre></div></div>
<div class=collapsibleContent_q3kw><div class=header_QCEw><h2><span>Cleanup</span></h2><span class=icon_PckA>👈</span></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class=col><a href=https://github.com/awslabs/data-on-eks/blob/main/website/docs/blueprints/data-analytics/spark-operator-beam.md target=_blank rel="noopener noreferrer" class=theme-edit-this-page><svg fill=currentColor height=20 width=20 viewBox="0 0 40 40" class=iconEdit_Z9Sw aria-hidden=true><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"/></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href=/data-on-eks/docs/blueprints/data-analytics/observability-spark-on-eks><div class=pagination-nav__sublabel>Previous</div><div class=pagination-nav__label>Spark Observability on EKS</div></a><a class="pagination-nav__link pagination-nav__link--next" href=/data-on-eks/docs/blueprints/data-analytics/datahub-on-eks><div class=pagination-nav__sublabel>Next</div><div class=pagination-nav__label>DataHub on EKS</div></a></nav></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class=footer__title>Get Started</div><ul class="footer__items clean-list"><li class=footer__item><a class=footer__link-item href=/data-on-eks/docs/introduction/intro>Docs</a></ul></div><div class="theme-layout-footer-column col footer__col"><div class=footer__title>Get Involved</div><ul class="footer__items clean-list"><li class=footer__item><a href=https://github.com/awslabs/data-on-eks target=_blank rel="noopener noreferrer" class=footer__link-item>Github<svg width=13.5 height=13.5 aria-hidden=true class=iconExternalLink_nPIU><use href=#theme-svg-external-link /></svg></a></ul></div></div><div class="footer__bottom text--center"><div class=footer__copyright>Built with ❤️ at AWS  <br> © 2025 Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer><script defer src=https://static.cloudflareinsights.com/beacon.min.js data-cf-beacon='{"token": "7fbc7ab02fae4767b1af2588eba0cdf2"}'></script></div>