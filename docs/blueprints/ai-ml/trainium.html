<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-blueprints/ai-ml/trainium" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">trainium | Data on EKS</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://awslabs.github.io/data-on-eks/docs/blueprints/ai-ml/trainium"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="trainium | Data on EKS"><meta data-rh="true" name="description" content="Deployment of ML models on EKS requires access to GPUs or Neuron instances. If your deployment isn&#x27;t working, it’s often due to missing access to these resources. Also, some deployment patterns rely on Karpenter autoscaling and static node groups; if nodes aren&#x27;t initializing, check the logs for Karpenter or Node groups to resolve the issue."><meta data-rh="true" property="og:description" content="Deployment of ML models on EKS requires access to GPUs or Neuron instances. If your deployment isn&#x27;t working, it’s often due to missing access to these resources. Also, some deployment patterns rely on Karpenter autoscaling and static node groups; if nodes aren&#x27;t initializing, check the logs for Karpenter or Node groups to resolve the issue."><link data-rh="true" rel="icon" href="/data-on-eks/img/header-icon.png"><link data-rh="true" rel="canonical" href="https://awslabs.github.io/data-on-eks/docs/blueprints/ai-ml/trainium"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/data-on-eks/docs/blueprints/ai-ml/trainium" hreflang="en"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/data-on-eks/docs/blueprints/ai-ml/trainium" hreflang="x-default"><link rel="stylesheet" href="/data-on-eks/assets/css/styles.1b422cd7.css">
<script src="/data-on-eks/assets/js/runtime~main.d052eb71.js" defer="defer"></script>
<script src="/data-on-eks/assets/js/main.102b9bdc.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/data-on-eks/"><div class="navbar__logo"><img src="/data-on-eks/img/header-icon.png" alt="DoEKS Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/data-on-eks/img/header-icon.png" alt="DoEKS Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/data-on-eks/docs/introduction/intro">Introduction</a><a class="navbar__item navbar__link" href="/data-on-eks/docs/gen-ai">Gen AI</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/data-on-eks/docs/blueprints/amazon-emr-on-eks">Blueprints</a><a class="navbar__item navbar__link" href="/data-on-eks/docs/bestpractices/intro">Best Practices</a><a class="navbar__item navbar__link" href="/data-on-eks/docs/benchmarks/emr-on-eks">Benchmarks</a><a class="navbar__item navbar__link" href="/data-on-eks/docs/resources/intro">Resources</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/awslabs/data-on-eks" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/data-on-eks/docs/category/aiml-on-eks">AI/ML on EKS</a><button aria-label="Collapse sidebar category &#x27;AI/ML on EKS&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/data-on-eks/docs/blueprints/ai-ml">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/data-on-eks/docs/blueprints/ai-ml/trainium">Trainium on EKS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/data-on-eks/docs/blueprints/ai-ml/jark">JARK on EKS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/data-on-eks/docs/blueprints/ai-ml/jupyterhub">JupyterHub on EKS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/data-on-eks/docs/blueprints/ai-ml/emr-spark-rapids">EMR NVIDIA Spark-RAPIDS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/data-on-eks/docs/blueprints/ai-ml/ray">Ray on EKS</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/data-on-eks/docs/category/data-analytics-on-eks">Data Analytics on EKS</a><button aria-label="Expand sidebar category &#x27;Data Analytics on EKS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/data-on-eks/docs/category/amazon-emr-on-eks">Amazon EMR on EKS</a><button aria-label="Expand sidebar category &#x27;Amazon EMR on EKS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/data-on-eks/docs/category/streaming-platforms-on-eks">Streaming Platforms on EKS</a><button aria-label="Expand sidebar category &#x27;Streaming Platforms on EKS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/data-on-eks/docs/category/job-schedulers-on-eks">Job Schedulers on EKS</a><button aria-label="Expand sidebar category &#x27;Job Schedulers on EKS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/data-on-eks/docs/category/distributed-databases-on-eks">Distributed Databases on EKS</a><button aria-label="Expand sidebar category &#x27;Distributed Databases on EKS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/data-on-eks/docs/blueprints/troubleshooting">Troubleshooting</a></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/data-on-eks/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/data-on-eks/docs/category/aiml-on-eks"><span itemprop="name">AI/ML on EKS</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Trainium on EKS</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_BuS1"><p>Deployment of ML models on EKS requires access to GPUs or Neuron instances. If your deployment isn&#x27;t working, it’s often due to missing access to these resources. Also, some deployment patterns rely on Karpenter autoscaling and static node groups; if nodes aren&#x27;t initializing, check the logs for Karpenter or Node groups to resolve the issue.</p></div></div>
<header><h1>AWS Trainium on EKS</h1></header>
<p><a href="https://aws.amazon.com/machine-learning/trainium/" target="_blank" rel="noopener noreferrer">AWS Trainium</a> is an advanced ML accelerator that transforms high-performance deep learning(DL) training. <code>Trn1</code> instances, powered by AWS Trainium chips, are purpose-built for high-performance DL training of <strong>100B+ parameter</strong> models. Meticulously designed for exceptional performance, Trn1 instances cater specifically to training popular Natual Language Processing(NLP) models on AWS, offering up to  **50% cost savings ** compared to GPU-based EC2 instances. This cost efficiency makes them an attractive option for data scientists and ML practitioners seeking optimized training costs without compromising performance.</p>
<p>At the core of Trn1 instance&#x27;s capabilities lies the <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/" target="_blank" rel="noopener noreferrer">AWS Neuron SDK</a>, a software development kit seamlessly integrated with leading ML frameworks and libraries, such as <a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">PyTorch</a>, <a href="https://tensorflow.org/" target="_blank" rel="noopener noreferrer">TensorFlow</a>, <a href="https://huggingface.co/docs/accelerate/usage_guides/megatron_lm" target="_blank" rel="noopener noreferrer">Megatron-LM</a>, and <a href="https://huggingface.co/" target="_blank" rel="noopener noreferrer">Hugging Face</a>. The Neuron SDK empowers developers to train NLP, computer vision, and recommender models on Trainium with ease, requiring only a few lines of code changes.</p>
<p>In this blueprint, we will learn how to securely deploy an <a href="https://docs.aws.amazon.com/eks/latest/userguide/clusters.html" target="_blank" rel="noopener noreferrer">Amazon EKS Cluster</a> with Trainium Node groups (<code>Trn1.32xlarge</code> and <code>Trn1n.32xlarge</code>) and all the required plugins(EFA Package for EC2, Neuron Device K8s Plugin and EFA K8s plugin). Once the deployment is complete, we will learn how to train a BERT-large(Bidirectional Encoder Representations from Transformers) model  with Distributed PyTorch pre-training using the WikiCorpus dataset. For scheduling the distributed training job, we will utilize <a href="https://pytorch.org/torchx/latest/" target="_blank" rel="noopener noreferrer">TorchX</a> with the <a href="https://volcano.sh/en/" target="_blank" rel="noopener noreferrer">Volcano Scheduler</a>. Additionally, we can monitor the neuron activity during training using <code>neuron-top</code>.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="trianium-device-architecture">Trianium Device Architecture<a href="#trianium-device-architecture" class="hash-link" aria-label="Direct link to Trianium Device Architecture" title="Direct link to Trianium Device Architecture">​</a></h4>
<p>Each Trainium device (chip) comprises two neuron cores. In the case of <code>Trn1.32xlarge</code> instances, <code>16 Trainium devices</code> are combined, resulting in a total of <code>32 Neuron cores</code>. The diagram below provides a visual representation of the Neuron device&#x27;s architecture:</p>
<p><img decoding="async" loading="lazy" alt="Trainium Device" src="/data-on-eks/assets/images/neuron-device-b6418f956d103a5da9e7087ba07cf949.png" width="625" height="556" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="aws-neuron-drivers">AWS Neuron Drivers<a href="#aws-neuron-drivers" class="hash-link" aria-label="Direct link to AWS Neuron Drivers" title="Direct link to AWS Neuron Drivers">​</a></h4>
<p>Neuron Drivers are a set of essential software components installed on the host operating system of AWS Inferentia-based accelerators, such as Trainium/Inferentia instances. Their primary function is to optimize the interaction between the accelerator hardware and the underlying operating system, ensuring seamless communication and efficient utilization of the accelerator&#x27;s computational capabilities.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="aws-neuron-runtime">AWS Neuron Runtime<a href="#aws-neuron-runtime" class="hash-link" aria-label="Direct link to AWS Neuron Runtime" title="Direct link to AWS Neuron Runtime">​</a></h4>
<p>Neuron runtime consists of kernel driver and C/C++ libraries which provides APIs to access Inferentia and Trainium Neuron devices. The Neuron ML frameworks plugins for TensorFlow, PyTorch and Apache MXNet use the Neuron runtime to load and run models on the NeuronCores.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="aws-neuron-device-plugin-for-kubernetes">AWS Neuron Device Plugin for Kubernetes<a href="#aws-neuron-device-plugin-for-kubernetes" class="hash-link" aria-label="Direct link to AWS Neuron Device Plugin for Kubernetes" title="Direct link to AWS Neuron Device Plugin for Kubernetes">​</a></h4>
<p>The AWS Neuron Device Plugin for Kubernetes is a component that promotes Trainium/Inferentia devices as system hardware resources within the EKS cluster. It is deployed as a <a href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/" target="_blank" rel="noopener noreferrer">DaemonSet</a>, ensuring proper permissions for the device plugin to update the Node and Pod annotations, thereby seamlessly integrating Inferentia devices with Kubernetes pods.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="fsx-for-lustre">FSx for Lustre<a href="#fsx-for-lustre" class="hash-link" aria-label="Direct link to FSx for Lustre" title="Direct link to FSx for Lustre">​</a></h4>
<p>In this blueprint, we utilize TorchX to initiate a DataParallel BERT phase1 pretraining task, employing 64 workers distributed across 2 trn1.32xlarge (or trn1n.32xlarge) instances, with 32 workers per instance. The BERT phase1 pretraining process involves a substantial 50+ GB WikiCorpus dataset as the training data. To handle large datasets efficiently, including the dataset inside the training container image or downloading it at the start of each job is not practical. Instead, we leverage shared file system storage to ensure multiple compute instances can process the training datasets concurrently.</p>
<p>For this purpose, FSx for Lustre emerges as an ideal solution for machine learning workloads. It provides shared file system storage that can process massive data sets at up to hundreds of gigabytes per second of throughput, millions of IOPS, and sub-millisecond latencies. We can dynamically create FSx for Lustre and attach the file system to the Pods using the FSx CSI controller through Persistent Volume Claims(PVC), enabling seamless integration of shared file storage with the distributed training process.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="torchx">TorchX<a href="#torchx" class="hash-link" aria-label="Direct link to TorchX" title="Direct link to TorchX">​</a></h4>
<p><a href="https://pytorch.org/torchx/main/quickstart.html" target="_blank" rel="noopener noreferrer">TorchX</a> SDK or CLI provides the functionality to effortlessly submit PyTorch jobs to Kubernetes. It offers the capability to connect predefined components like hyperparameter optimization, model serving, and distributed data-parallel into sophisticated pipelines, while leveraging popular job schedulers like Slurm, Ray, AWS Batch, Kubeflow Pipelines, and Airflow.</p>
<p>The TorchX Kubernetes scheduler relies on the <a href="https://volcano.sh/en/docs/" target="_blank" rel="noopener noreferrer">Volcano Scheduler</a>, which must be installed on the Kubernetes cluster. Gang scheduling is essential for multi-replica/multi-role execution, and currently, Volcano is the only supported scheduler within Kubernetes that meets this requirement.</p>
<p>TorchX can seamlessly integrate with Airflow and Kubeflow Pipelines. In this blueprint, we will install the TorchX CLI on a local machine/cloud9 ide and use it to trigger job submission on the EKS cluster, which, in turn, submits jobs to the Volcano scheduler queue running on the EKS Cluster.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="volcano-scheduler">Volcano Scheduler<a href="#volcano-scheduler" class="hash-link" aria-label="Direct link to Volcano Scheduler" title="Direct link to Volcano Scheduler">​</a></h4>
<p><a href="https://volcano.sh/en/docs/" target="_blank" rel="noopener noreferrer">Volcano Scheduler</a> is a custom Kubernetes batch scheduler designed to efficiently manage diverse workloads, making it particularly well-suited for resource-intensive tasks like machine learning. Volcano Queue serves as a collection of PodGroups, adopting a FIFO (First-In-First-Out) approach and forming the basis for resource allocation. VolcanoJob, also known as <code>vcjob</code>, is a Custom Resource Definition (CRD) object specifically tailored for Volcano. It stands out from a regular Kubernetes job by offering advanced features, including a specified scheduler, minimum member requirements, task definitions, lifecycle management, specific queue assignment, and priority settings. VolcanoJob is ideally suited for high-performance computing scenarios, such as machine learning, big data applications, and scientific computing.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="solution-architecture">Solution Architecture<a href="#solution-architecture" class="hash-link" aria-label="Direct link to Solution Architecture" title="Direct link to Solution Architecture">​</a></h3>
<p><img decoding="async" loading="lazy" alt="Alt text" src="/data-on-eks/assets/images/trainium-on-eks-arch-7d551d7182d87be5c787267ec74ff22d.png" width="12492" height="7950" class="img_ev3q"></p>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h2><span>Deploying the Solution</span></h2><span class="icon_PckA">👈</span></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="observability-with-aws-cloudwatch-and-neuron-monitor">Observability with AWS CloudWatch and Neuron Monitor<a href="#observability-with-aws-cloudwatch-and-neuron-monitor" class="hash-link" aria-label="Direct link to Observability with AWS CloudWatch and Neuron Monitor" title="Direct link to Observability with AWS CloudWatch and Neuron Monitor">​</a></h3>
<p>This blueprint deploys the CloudWatch Observability Agent as a managed add-on, providing comprehensive monitoring for containerized workloads. It includes container insights for tracking key performance metrics such as CPU and memory utilization. Additionally, the blueprint integrates GPU metrics using NVIDIA&#x27;s DCGM plugin, which is essential for monitoring high-performance GPU workloads. For machine learning models running on AWS Inferentia or Trainium, the <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/tools/neuron-sys-tools/neuron-monitor-user-guide.html#neuron-monitor-user-guide" target="_blank" rel="noopener noreferrer">Neuron Monitor plugin</a> is added to capture and report Neuron-specific metrics.</p>
<p>All metrics, including container insights, GPU performance, and Neuron metrics, are sent to Amazon CloudWatch, where you can monitor and analyze them in real-time. After the deployment is complete, you should be able to access these metrics directly from the CloudWatch console, allowing you to manage and optimize your workloads effectively.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="distributed-pytorch-training-on-trainium-with-torchx-and-eks">Distributed PyTorch Training on Trainium with TorchX and EKS<a href="#distributed-pytorch-training-on-trainium-with-torchx-and-eks" class="hash-link" aria-label="Direct link to Distributed PyTorch Training on Trainium with TorchX and EKS" title="Direct link to Distributed PyTorch Training on Trainium with TorchX and EKS">​</a></h3>
<p>In this example, we will perform DataParallel-based phase1 pretraining on the BERT-large model using the WikiCorpus dataset. To execute the task, we will use TorchX to initiate the job on two <code>trn1.32xlarge</code> instances, with 32 workers per instance. You can also run the same job on <code>trn1n.32xlarge</code> node group.</p>
<p>We have created three Shell scripts to automate the job execution as much as possible.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="step1-create-a-docker-image--for-pytorch-neuron-container-for-bert-large-model-pre-training">Step1: Create a Docker image  for PyTorch Neuron container for BERT-large model pre-training<a href="#step1-create-a-docker-image--for-pytorch-neuron-container-for-bert-large-model-pre-training" class="hash-link" aria-label="Direct link to Step1: Create a Docker image  for PyTorch Neuron container for BERT-large model pre-training" title="Direct link to Step1: Create a Docker image  for PyTorch Neuron container for BERT-large model pre-training">​</a></h4>
<p>This step creates a new Docker image and push this image to ECR repo. The Dockerfile handles the installation of necessary software packages, such as AWS Neuron repos, Python dependencies, and other essential tools for PyTorch and BERT pre-training. It configures various environment variables to ensure smooth execution and optimal performance. The image contains crucial components like a BERT pretraining script and requirements.txt file sourced from GitHub, both vital for the BERT pretraining process. Furthermore, it includes a basic environment test script for validation purposes. Together, this Docker image provides a comprehensive environment for efficient BERT pre-training with PyTorch while incorporating AWS Neuron optimizations.</p>
<div class="theme-admonition theme-admonition-caution admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</div><div class="admonitionContent_BuS1"><p>This step generates an AMD64 (x86-64) Docker image with a size of 7GB or more. Therefore, it is strongly advised to utilize an AWS Cloud9/EC2 AMD64 (x86-64) instance with Docker client installed, ensuring sufficient storage capacity for this process.</p></div></div>
<div class="theme-admonition theme-admonition-caution admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</div><div class="admonitionContent_BuS1"><p>If you are executing this script on a Cloud9 IDE/EC2 instance different from the one where the EKS Cluster is deployed, it is essential to ensure that the same IAM role is used or attached to the Cloud9 IDE/EC2 instance. Should you prefer a distinct IAM role for Cloud9 IDE/EC2, it must be added to the EKS Cluster&#x27;s aws-auth config map to grant the role authorization for authenticating with the EKS Cluster. Taking these precautions will enable smooth communication between the instances and the EKS Cluster, ensuring the script functions as intended.</p></div></div>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd ai-ml/trainium-inferentia/examples/dp-bert-large-pretrain</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chmod +x 1-bert-pretrain-build-image.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./1-bert-pretrain-build-image.sh</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Admin:~/environment/data-on-eks/ai-ml/trainium-inferentia/examples/dp-bert-large-pretrain (trainium-part2) $ ./1-bert-pretrain-build-image.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Did you install docker on AMD64(x86-64) machine (y/n): y</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Enter the ECR region: us-west-2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ECR repository &#x27;eks_torchx_test&#x27; already exists.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Repository URL: &lt;YOUR_ACCOUNT_ID&gt;.dkr.ecr.us-west-2.amazonaws.com/eks_torchx_test</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Building and Tagging Docker image... &lt;YOUR_ACCOUNT_ID&gt;.dkr.ecr.us-west-2.amazonaws.com/eks_torchx_test:bert_pretrain</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[+] Building 2.4s (26/26) FINISHED</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> =&gt; [internal] load build definition from Dockerfile.bert_pretrain                                                                                                                   0.0s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> =&gt; =&gt; transferring dockerfile: 5.15kB                                                                                                                                               0.0s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> =&gt; [internal] load .dockerignore                                                                                                                                                    0.0s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> =&gt; =&gt; transferring context: 2B                                                                                                                                                      0.0s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> =&gt; [internal] load metadata for docker.io/library/ubuntu:20.04                                                                                                                      0.7s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> =&gt; [ 1/22] FROM docker.io/library/ubuntu:20.04@sha256:c9820a44b950956a790c354700c1166a7ec648bc0d215fa438d3a339812f1d01                                                              0.0s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"> ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">bert_pretrain: digest: sha256:1bacd5233d1a87ca1d88273c5a7cb131073c6f390f03198a91dc563158485941 size: 4729</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Login to AWS Console and verify the ECR repo(<code>&lt;YOUR_ACCOUNT_ID&gt;.dkr.ecr.&lt;REGION&gt;.amazonaws.com/eks_torchx_test</code>) and the image tag(<code>bert_pretrain</code>) in ECR.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="step2-copy-wikicorpus-pre-training-dataset-for-bert-model-to-fsx-for-lustre-filesystem">Step2: Copy WikiCorpus pre-training dataset for BERT model to FSx for Lustre filesystem<a href="#step2-copy-wikicorpus-pre-training-dataset-for-bert-model-to-fsx-for-lustre-filesystem" class="hash-link" aria-label="Direct link to Step2: Copy WikiCorpus pre-training dataset for BERT model to FSx for Lustre filesystem" title="Direct link to Step2: Copy WikiCorpus pre-training dataset for BERT model to FSx for Lustre filesystem">​</a></h4>
<p>In this step, we make it easy to transfer the WikiCorpus pre-training dataset, which is crucial for training the BERT model in distributed mode by multiple Trainium instances, to the FSx for Lustre filesystem. To achieve this, we will login to <code>cmd-shell</code> pod which includes an AWS CLI container, providing access to the filesystem.</p>
<p>Once you&#x27;re inside the container, Copy the WikiCorpus dataset from S3 bucket (<code>s3://neuron-s3/training_datasets/bert_pretrain_wikicorpus_tokenized_hdf5/bert_pretrain_wikicorpus_tokenized_hdf5_seqlen128.tar</code>). The dataset is then unpacked, giving you access to its contents, ready for use in the subsequent BERT model pre-training process.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl exec -i -t -n default cmd-shell -c app -- sh -c &quot;clear; (bash || ash || sh)&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Once logged into the container</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">yum install tar</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">cd /data</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">aws s3 cp s3://neuron-s3/training_datasets/bert_pretrain_wikicorpus_tokenized_hdf5/bert_pretrain_wikicorpus_tokenized_hdf5_seqlen128.tar . --no-sign-request</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chmod 744 bert_pretrain_wikicorpus_tokenized_hdf5_seqlen128.tar</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tar xvf bert_pretrain_wikicorpus_tokenized_hdf5_seqlen128.tar</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="step3-precompile-the-bert-graphs-using-neuron_parallel_compile">Step3: Precompile the BERT graphs using neuron_parallel_compile<a href="#step3-precompile-the-bert-graphs-using-neuron_parallel_compile" class="hash-link" aria-label="Direct link to Step3: Precompile the BERT graphs using neuron_parallel_compile" title="Direct link to Step3: Precompile the BERT graphs using neuron_parallel_compile">​</a></h4>
<p>PyTorch Neuron introduces a valuable tool known as <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/api-reference-guide/training/pytorch-neuron-parallel-compile.html" target="_blank" rel="noopener noreferrer">neuron_parallel_compile</a>, which significantly reduces graph compilation time by extracting model graphs and compiling them in parallel. This optimization technique expedites the process and results in faster model compilation. The compiled graphs are then stored on the Fsx for Lustre shared storage volume, accessible by worker nodes during model training. This efficient approach streamlines the training process and improves overall performance, making the most of PyTorch Neuron&#x27;s capabilities.</p>
<p>Execute the following commands.This script prompts the user to configure their kubeconfig and verifies the presence of the <code>lib</code> folder with <code>trn1_dist_ddp.py</code>. It sets up Docker credentials, installs the <strong>TorchX</strong> client for Kubernetes. Using TorchX, the script runs a Kubernetes job to compile BERT graphs with optimized performance. Additionally, TorchX creates another Docker image and pushes it to the ECR repository within the same repo. This image is utilized in the subsequent pre-compiling pods, optimizing the overall BERT model training process.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd ai-ml/trainium-inferentia/examples/dp-bert-large-pretrain</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chmod +x 2-bert-pretrain-precompile.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./2-bert-pretrain-precompile.sh</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>You can verify the pods status by running <code>kubectl get pods</code> or <code>kubectl get vcjob</code>. Successful output looks like below.</p>
<p><img decoding="async" loading="lazy" alt="Alt text" src="/data-on-eks/assets/images/pre-compile-pod-status-a957a723dd43219aacf123b09c9337ec.png" width="2152" height="1360" class="img_ev3q"></p>
<p>You can also verify the logs for the Pod once they are <code>Succeeded</code>. The precompilation job will run for <code>~15 minutes</code>. Once complete, you will see the following in the output:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">2023-07-29 09:42:42.000310: INFO ||PARALLEL_COMPILE||: Starting parallel compilations of the extracted graphs2023-07-29 09:42:42.000312: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.406_16969875447143373016.hlo.pb using following command: neuronx-cc compile —target=trn1 —framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.406_16969875447143373016.hlo.pb —model-type=transformer —verbose=35 —output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.406_16969875447143373016.neff</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023-07-29 09:42:42.000313: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.22250_9219523464496887986.hlo.pb using following command: neuronx-cc compile —target=trn1 —framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.22250_9219523464496887986.hlo.pb —model-type=transformer —verbose=35 —output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.22250_9219523464496887986.neff</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023-07-29 09:42:42.000314: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25434_3000743782456078279.hlo.pb using following command: neuronx-cc compile —target=trn1 —framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25434_3000743782456078279.hlo.pb —model-type=transformer —verbose=35 —output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25434_3000743782456078279.neff</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023-07-29 09:42:42.000315: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25637_13822314547392343350.hlo.pb using following command: neuronx-cc compile —target=trn1 —framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25637_13822314547392343350.hlo.pb —model-type=transformer —verbose=35 —output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25637_13822314547392343350.neff</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">2023-07-29 09:42:42.000316: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21907_15179678551789598088.hlo.pb using following command: neuronx-cc compile —target=trn1 —framework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21907_15179678551789598088.hlo.pb —model-type=transformer —verbose=35 —output /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21907_15179678551789598088.neff</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">.....</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Compiler status PASS</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>New pre-training cache files are stored under FSx for Lustre.</p>
<p><img decoding="async" loading="lazy" alt="Alt text" src="/data-on-eks/assets/images/cache-c20ffd2f2f08427c018edbd418f745af.png" width="1448" height="286" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="step4-launch-bert-pretraining-job-using-64-neuron-cores-with-two-trn132xlarge-instances">Step4: Launch BERT pretraining job using 64 Neuron cores with two trn1.32xlarge instances<a href="#step4-launch-bert-pretraining-job-using-64-neuron-cores-with-two-trn132xlarge-instances" class="hash-link" aria-label="Direct link to Step4: Launch BERT pretraining job using 64 Neuron cores with two trn1.32xlarge instances" title="Direct link to Step4: Launch BERT pretraining job using 64 Neuron cores with two trn1.32xlarge instances">​</a></h4>
<p>We are now in the final step of training the BERT-large model with WikiCorpus data.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd ai-ml/trainium-inferentia/examples/dp-bert-large-pretrain</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chmod +x 3-bert-pretrain.sh</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./3-bert-pretrain.sh</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Monitor the job with the following commands. This job may take several hours as its training 30GB+ worth of the data.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get vcjob</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods # Two pods will be running in default namespace</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>To monitor Neuron usage, you can log in to one of the Trainium EC2 instances using SSM (Systems Manager) from the EC2 console. Once logged in, run the command neuron-ls, and you will receive an output similar to the following.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[root@ip-100-64-229-201 aws-efa-installer]# neuron-ls</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">instance-type: trn1.32xlarge</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">instance-id: i-04b476a6a0e686980</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+--------+--------+--------+---------------+---------+--------+------------------------------------------+---------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| NEURON | NEURON | NEURON | CONNECTED | PCI | PID | COMMAND | RUNTIME |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| DEVICE | CORES | MEMORY | DEVICES | BDF | | | VERSION |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+--------+--------+--------+---------------+---------+--------+------------------------------------------+---------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 0 | 2 | 32 GB | 12, 3, 4, 1 | 10:1c.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 1 | 2 | 32 GB | 13, 0, 5, 2 | 10:1d.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 2 | 2 | 32 GB | 14, 1, 6, 3 | a0:1c.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 3 | 2 | 32 GB | 15, 2, 7, 0 | a0:1d.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 4 | 2 | 32 GB | 0, 7, 8, 5 | 20:1b.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 5 | 2 | 32 GB | 1, 4, 9, 6 | 20:1c.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 6 | 2 | 32 GB | 2, 5, 10, 7 | 90:1b.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 7 | 2 | 32 GB | 3, 6, 11, 4 | 90:1c.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 8 | 2 | 32 GB | 4, 11, 12, 9 | 20:1d.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 9 | 2 | 32 GB | 5, 8, 13, 10 | 20:1e.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 10 | 2 | 32 GB | 6, 9, 14, 11 | 90:1d.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 11 | 2 | 32 GB | 7, 10, 15, 8 | 90:1e.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 12 | 2 | 32 GB | 8, 15, 0, 13 | 10:1e.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 13 | 2 | 32 GB | 9, 12, 1, 14 | 10:1b.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 14 | 2 | 32 GB | 10, 13, 2, 15 | a0:1e.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| 15 | 2 | 32 GB | 11, 14, 3, 12 | a0:1b.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+--------+--------+--------+---------------+---------+--------+------------------------------------------+---------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>You can also run <code>neuron-top</code> which provides the live usage of neuron cores. The below shows the usage of all 32 neuron cores.</p>
<p><img decoding="async" loading="lazy" alt="Alt text" src="/data-on-eks/assets/images/neuron-top-15b215db91829995ded8d938dc8b3ef8.png" width="2116" height="1204" class="img_ev3q"></p>
<p>If you wish to terminate the job, you can execute the following commands:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get vcjob # Get a job name</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl delete &lt;ENTER_JOB_NAME&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h2><span>Cleanup</span></h2><span class="icon_PckA">👈</span></div></div>
<div class="theme-admonition theme-admonition-caution admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</div><div class="admonitionContent_BuS1"><p>To avoid unwanted charges to your AWS account, delete all the AWS resources created during this deployment</p></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/awslabs/data-on-eks/blob/main/website/docs/blueprints/ai-ml/trainium.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/data-on-eks/docs/blueprints/ai-ml"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Introduction</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/data-on-eks/docs/blueprints/ai-ml/jark"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">JARK on EKS</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#solution-architecture" class="table-of-contents__link toc-highlight">Solution Architecture</a></li><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a></li><li><a href="#deploy" class="table-of-contents__link toc-highlight">Deploy</a></li><li><a href="#verify-the-resources" class="table-of-contents__link toc-highlight">Verify the resources</a></li><li><a href="#observability-with-aws-cloudwatch-and-neuron-monitor" class="table-of-contents__link toc-highlight">Observability with AWS CloudWatch and Neuron Monitor</a></li><li><a href="#distributed-pytorch-training-on-trainium-with-torchx-and-eks" class="table-of-contents__link toc-highlight">Distributed PyTorch Training on Trainium with TorchX and EKS</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Get Started</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/data-on-eks/docs/introduction/intro">Docs</a></li></ul></div><div class="col footer__col"><div class="footer__title">Get Involved</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/awslabs/data-on-eks" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with ❤️ at AWS  <br> © 2024 Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer></div>
</body>
</html>