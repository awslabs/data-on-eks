<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-gen-ai/inference/Neuron/stablediffusion-inf2" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">Stable Diffusion on Inferentia2 | Data on EKS</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://awslabs.github.io/data-on-eks/docs/gen-ai/inference/Neuron/stablediffusion-inf2"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Stable Diffusion on Inferentia2 | Data on EKS"><meta data-rh="true" name="description" content="The AI on EKS content is being migrated to a new repository."><meta data-rh="true" property="og:description" content="The AI on EKS content is being migrated to a new repository."><link data-rh="true" rel="icon" href="/data-on-eks/img/header-icon.png"><link data-rh="true" rel="canonical" href="https://awslabs.github.io/data-on-eks/docs/gen-ai/inference/Neuron/stablediffusion-inf2"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/data-on-eks/docs/gen-ai/inference/Neuron/stablediffusion-inf2" hreflang="en"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/data-on-eks/docs/gen-ai/inference/Neuron/stablediffusion-inf2" hreflang="x-default"><link rel="stylesheet" href="/data-on-eks/assets/css/styles.264cfa7d.css">
<script src="/data-on-eks/assets/js/runtime~main.04c8927c.js" defer="defer"></script>
<script src="/data-on-eks/assets/js/main.c8b44f72.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/data-on-eks/"><div class="navbar__logo"><img src="/data-on-eks/img/header-icon.png" alt="DoEKS Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/data-on-eks/img/header-icon.png" alt="DoEKS Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link navbar-highlight-link" href="/data-on-eks/docs/migration/migration-announcement">🚨 Repo Split Update</a><a class="navbar__item navbar__link" href="/data-on-eks/docs/introduction/intro">Introduction</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/data-on-eks/docs/gen-ai">AI on EKS (🚨 Moving)</a><a class="navbar__item navbar__link" href="/data-on-eks/docs/blueprints/amazon-emr-on-eks">Blueprints</a><a class="navbar__item navbar__link" href="/data-on-eks/docs/bestpractices/intro">Best Practices</a><a class="navbar__item navbar__link" href="/data-on-eks/docs/benchmarks/emr-on-eks">Benchmarks</a><a class="navbar__item navbar__link" href="/data-on-eks/docs/resources/intro">Resources</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/awslabs/data-on-eks" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/data-on-eks/docs/gen-ai">Overview</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/data-on-eks/docs/category/inference-on-eks">Inference on EKS</a><button aria-label="Collapse sidebar category &#x27;Inference on EKS&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/data-on-eks/docs/gen-ai/inference/GPUs/ray-vllm-deepseek">GPUs</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/data-on-eks/docs/gen-ai/inference/Neuron/vllm-ray-inf2">Neuron</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/data-on-eks/docs/gen-ai/inference/Neuron/vllm-ray-inf2">Llama-3-8B with vLLM on Inferentia2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/data-on-eks/docs/gen-ai/inference/Neuron/Mistral-7b-inf2">Mistral-7B on Inferentia2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/data-on-eks/docs/gen-ai/inference/Neuron/llama3-inf2">Llama-3-8B on Inferentia2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/data-on-eks/docs/gen-ai/inference/Neuron/llama2-inf2">Llama-2 on Inferentia2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/data-on-eks/docs/gen-ai/inference/Neuron/stablediffusion-inf2">Stable Diffusion on Inferentia2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/data-on-eks/docs/gen-ai/inference/Neuron/rayserve-ha">Ray Serve High Availability</a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/data-on-eks/docs/category/training-on-eks">Training on EKS</a><button aria-label="Expand sidebar category &#x27;Training on EKS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/data-on-eks/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/data-on-eks/docs/category/inference-on-eks"><span itemprop="name">Inference on EKS</span></a><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Neuron</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Stable Diffusion on Inferentia2</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><div class="theme-admonition theme-admonition-caution admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</div><div class="admonitionContent_BuS1"><p>The <strong>AI on EKS</strong> content <strong>is being migrated</strong> to a new repository.
🔗 👉 <a href="https://awslabs.github.io/data-on-eks/docs/migration/migration-announcement" target="_blank" rel="noopener noreferrer">Read the full migration announcement »</a></p></div></div>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_BuS1"><p>Deployment of ML models on EKS requires access to GPUs or Neuron instances. If your deployment isn&#x27;t working, it’s often due to missing access to these resources. Also, some deployment patterns rely on Karpenter autoscaling and static node groups; if nodes aren&#x27;t initializing, check the logs for Karpenter or Node groups to resolve the issue.</p></div></div>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>This example blueprint deploys a <code>stable-diffusion-xl-base-1-0</code> model on Inferentia2 instance running as a worker node in an EKS cluster. The model is served using <code>RayServe</code>.</p></div></div>
<header><h1>Serving Stable Diffusion XL Base  Model with Inferentia, Ray Serve and Gradio</h1></header>
<p>Welcome to the comprehensive guide on deploying the <a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0" target="_blank" rel="noopener noreferrer">Stable Diffusion XL Base</a> model on Amazon Elastic Kubernetes Service (EKS) using <a href="https://docs.ray.io/en/latest/serve/index.html" target="_blank" rel="noopener noreferrer">Ray Serve</a>.
In this tutorial, you will not only learn how to harness the power of Stable Diffusion models, but also gain insights into the intricacies of deploying large language models (LLMs) efficiently, particularly on <a href="https://aws.amazon.com/machine-learning/neuron/" target="_blank" rel="noopener noreferrer">trn1/inf2</a> (powered by AWS Trainium and Inferentia) instances, such as <code>inf2.24xlarge</code> and <code>inf2.48xlarge</code>,
which are optimized for deploying and scaling large language models.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-stable-diffusion">What is Stable Diffusion?<a href="#what-is-stable-diffusion" class="hash-link" aria-label="Direct link to What is Stable Diffusion?" title="Direct link to What is Stable Diffusion?">​</a></h3>
<p>Stable Diffusion is a text-to-image model for creating stunning art within seconds. It is one of the largest and most powerful LLMs available today. It is primarily used to generate detailed images conditioned on text descriptions, though it can also be applied to other tasks such as inpainting, outpainting, and generating image-to-image translations guided by a text prompt.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="stable-diffusion-xlsdxl">Stable Diffusion XL(SDXL)<a href="#stable-diffusion-xlsdxl" class="hash-link" aria-label="Direct link to Stable Diffusion XL(SDXL)" title="Direct link to Stable Diffusion XL(SDXL)">​</a></h4>
<p>SDXL is a latent diffusion model for text-to-image synthesis. Compared to previous versions of Stable Diffusion, SDXL  uses pipelines for latent diffusion and noise reduction. SDXL also improves the quality of generated images compared to prior Stable Diffusion models by using a times larger UNet. The increase of model parameters is mainly due to more attention blocks and a larger cross-attention context as SDXL uses a second text encoder.</p>
<p>SDXL has been designed with multiple novel conditioning schemes and trained on multiple aspect ratios. It also uses a refinement model which is used to improve the visual fidelity of samples generated by SDXL using a post-hoc image-to-image technique.</p>
<p>This process results in a highly capable and fine-tuned language model that we will guide you to deploy and utilize effectively on <strong>Amazon EKS</strong> with <strong>Ray Serve</strong>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="inference-on-trn1inf2-instances-unlocking-the-full-potential-of-stable-diffusion-llms">Inference on Trn1/Inf2 Instances: Unlocking the Full Potential of Stable Diffusion LLMs<a href="#inference-on-trn1inf2-instances-unlocking-the-full-potential-of-stable-diffusion-llms" class="hash-link" aria-label="Direct link to Inference on Trn1/Inf2 Instances: Unlocking the Full Potential of Stable Diffusion LLMs" title="Direct link to Inference on Trn1/Inf2 Instances: Unlocking the Full Potential of Stable Diffusion LLMs">​</a></h2>
<p><strong>Stable Diffusion XL</strong> can be deployed on a variety of hardware platforms, each with its own set of advantages. However, when it comes to maximizing the efficiency, scalability, and cost-effectiveness of Stable Diffusion models, <a href="https://aws.amazon.com/ec2/instance-types/inf2/" target="_blank" rel="noopener noreferrer">AWS Trn1/Inf2 instances</a> shine as the optimal choice.</p>
<p><strong>Scalability and Availability</strong>
One of the key challenges in deploying large language models (<code>LLMs</code>) like StableDiffusion XL is the scalability and availability of suitable hardware. Traditional <code>GPU</code> instances often face scarcity due to high demand, making it challenging to provision and scale resources effectively.
In contrast, <code>Trn1/Inf2</code> instances, such as <code>trn1.32xlarge</code>, <code>trn1n.32xlarge</code>, <code>inf2.24xlarge</code> and <code>inf2.48xlarge</code>, are purpose built for high-performance deep learning (DL) training and inference of generative AI models, including LLMs. They offer both scalability and availability, ensuring that you can deploy and scale your <code>Stable-diffusion-xl</code> models as needed, without resource bottlenecks or delays.</p>
<p><strong>Cost Optimization:</strong>
Running LLMs on traditional GPU instances can be cost-prohibitive, especially given the scarcity of GPUs and their competitive pricing.
<strong>Trn1/Inf2</strong> instances provide a cost-effective alternative. By offering dedicated hardware optimized for AI and machine learning tasks, Trn1/Inf2 instances allow you to achieve top-notch performance at a fraction of the cost.
This cost optimization enables you to allocate your budget efficiently, making LLM deployment accessible and sustainable.</p>
<p><strong>Performance Boost</strong>
While Stable-Diffusion-xl can achieve high-performance inference on GPUs, Neuron accelerators take performance to the next level. Neuron accelerators are purpose-built for machine learning workloads, providing hardware acceleration that significantly enhances Stable-diffusion&#x27;s inference speeds. This translates to faster response times and improved user experiences when deploying Stable-Diffusion-xl on Trn1/Inf2 instances.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="example-usecase">Example usecase<a href="#example-usecase" class="hash-link" aria-label="Direct link to Example usecase" title="Direct link to Example usecase">​</a></h3>
<p>A digital art company wants to deploy Stable-diffusion-xl powered image generator to help generate possible art based on prompts. Using a selection of textual prompts, users can create artwork, graphics and logos in a wide variety of styles. The image generator can be used to predict or fine-tune the art and can result in significant time saving in product iteration cycle. Company has a large customer base and wants the model to be scalable at high load. The company needs to design an infrastructure that can handle the high volume of requests and provide a fast response time.</p>
<p>The company can use Inferentia2 instances to scale its Stable diffusion image generator efficiently. Inferentia2 instances are specialized hardware accelerators for machine learning tasks. They can provide up to 20x better performance and up to 7x lower cost than GPUs for machine learning workloads.</p>
<p>The company can also use Ray Serve to horizontally scale its Stable diffusion image generator. Ray Serve is a distributed framework for serving machine learning models. It can automatically scale your models up or down based on demand.</p>
<p>To scale its Stable diffusion image generator, the company can deploy multiple Inferentia2 instances and use Ray Serve to distribute the traffic across the instances. This will allow the company to handle a high volume of requests and provide a fast response time.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="solution-architecture">Solution Architecture<a href="#solution-architecture" class="hash-link" aria-label="Direct link to Solution Architecture" title="Direct link to Solution Architecture">​</a></h2>
<p>In this section, we will delve into the architecture of our solution, which combines Stable diffusion xl model, <a href="https://docs.ray.io/en/latest/serve/index.html" target="_blank" rel="noopener noreferrer">Ray Serve</a> and <a href="https://aws.amazon.com/ec2/instance-types/inf2/" target="_blank" rel="noopener noreferrer">Inferentia2</a> on Amazon EKS.</p>
<p><img decoding="async" loading="lazy" alt="Sdxl-inf2" src="/data-on-eks/assets/images/excali-draw-sdxl-inf2-41ed1999a8a1b88197923df83d0c1af7.png" width="2018" height="1060" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploying-the-solution">Deploying the Solution<a href="#deploying-the-solution" class="hash-link" aria-label="Direct link to Deploying the Solution" title="Direct link to Deploying the Solution">​</a></h2>
<p>To get started with deploying <code>stable-diffusion-xl-base-1-0</code> on <a href="https://aws.amazon.com/eks/" target="_blank" rel="noopener noreferrer">Amazon EKS</a>, we will cover the necessary prerequisites and guide you through the deployment process step by step.
This includes setting up the infrastructure, deploying the <strong>Ray cluster</strong>, and creating the <a href="https://www.gradio.app/" target="_blank" rel="noopener noreferrer">Gradio</a> WebUI app.</p>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h2><span>Prerequisites</span></h2><span class="icon_PckA">👈</span></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploying-the-ray-cluster-with-stable-diffusion-xl-model">Deploying the Ray Cluster with Stable Diffusion XL Model<a href="#deploying-the-ray-cluster-with-stable-diffusion-xl-model" class="hash-link" aria-label="Direct link to Deploying the Ray Cluster with Stable Diffusion XL Model" title="Direct link to Deploying the Ray Cluster with Stable Diffusion XL Model">​</a></h2>
<p>Once the <code>Trainium on EKS</code> Cluster is deployed, you can proceed to use <code>kubectl</code> to deploy the <code>ray-service-stablediffusion.yaml</code>.</p>
<p>In this step, we will deploy the Ray Serve cluster, which comprises one <code>Head Pod</code> on <code>x86 CPU</code> instances using Karpenter autoscaling, as well as <code>Ray workers</code> on <code>Inf2.48xlarge</code> instances, autoscaled by <a href="https://karpenter.sh/" target="_blank" rel="noopener noreferrer">Karpenter</a>.</p>
<p>Let&#x27;s take a closer look at the key files used in this deployment and understand their functionalities before proceeding with the deployment:</p>
<ul>
<li><strong>ray_serve_stablediffusion.py:</strong>
This script uses FastAPI, Ray Serve, and <a href="https://github.com/huggingface/optimum-neuron" target="_blank" rel="noopener noreferrer">Hugging Face Optimum Neuron</a> library of tools to create an efficient text to image generator using the <a href="https://huggingface.co/aws-neuron/stable-diffusion-xl-base-1-0-1024x1024" target="_blank" rel="noopener noreferrer">Neuronx model for stable-diffusion-xl-base-1.0</a> language model.</li>
</ul>
<p>For this example blueprint, we are using a precompiled model that&#x27;s been compiled to run on AWS Neuron. You can use any stable diffusion model of your choice and compile it to run on AWS Neuron before driving inference on it.</p>
<ul>
<li><strong>ray-service-stablediffusion.yaml:</strong>
This Ray Serve YAML file serves as a Kubernetes configuration for deploying the Ray Serve service, facilitating efficient text generation using the <code>stable-diffusion-xl-base-1.0</code> model.
It defines a Kubernetes namespace named <code>stablediffusion</code> to isolate resources. Within the configuration, the <code>RayService</code> specification, named <code>stablediffusion-service</code>, is created and hosted within the <code>stablediffusion</code> namespace. The <code>RayService</code> specification leverages the Python script <code>ray_serve_stablediffusion.py</code> (copied into the Dockerfile located within the same folder) to create the Ray Serve service.
The Docker image used in this example is publicly available on Amazon Elastic Container Registry (ECR) for ease of deployment.
Users can also modify the Dockerfile to suit their specific requirements and push it to their own ECR repository, referencing it in the YAML file.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-the-stable-diffusion-xl-base-1-0-model">Deploy the Stable-Diffusion-xl-base-1-0 Model<a href="#deploy-the-stable-diffusion-xl-base-1-0-model" class="hash-link" aria-label="Direct link to Deploy the Stable-Diffusion-xl-base-1-0 Model" title="Direct link to Deploy the Stable-Diffusion-xl-base-1-0 Model">​</a></h3>
<p><strong>Ensure the cluster is configured locally</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">aws eks --region us-west-2 update-kubeconfig --name trainium-inferentia</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Deploy RayServe Cluster</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd data-on-eks/gen-ai/inference/stable-diffusion-xl-base-rayserve-inf2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply -f ray-service-stablediffusion.yaml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Verify the deployment by running the following commands</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>The deployment process may take up to 10 minutes. The Head Pod is expected to be ready within 2 to 3 minutes, while the Ray Serve worker pod may take up to 10 minutes for image retrieval and Model deployment from Huggingface.</p></div></div>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">$ kubectl get po -n stablediffusion -w</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                                      READY   STATUS     RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">service-raycluster-gc7gb-worker-inf2-worker-group-k2kf2   0/1     Init:0/1   0          7s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">stablediffusion-service-raycluster-gc7gb-head-6fqvv       1/1     Running    0          7s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">service-raycluster-gc7gb-worker-inf2-worker-group-k2kf2   0/1     PodInitializing   0          9s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">service-raycluster-gc7gb-worker-inf2-worker-group-k2kf2   1/1     Running           0          10s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">stablediffusion-service-raycluster-gc7gb-head-6fqvv       1/1     Running           0          53s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">service-raycluster-gc7gb-worker-inf2-worker-group-k2kf2   1/1     Running           0          53s</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Also check the service and ingress resources that got created</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get svc -n stablediffusion</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                                TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                                                       AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">stablediffusion-service             NodePort   172.20.175.61    &lt;none&gt;        6379:32190/TCP,8265:32375/TCP,10001:32117/TCP,8000:30770/TCP,52365:30334/TCP,8080:30094/TCP   16h</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">stablediffusion-service-head-svc    NodePort   172.20.193.225   &lt;none&gt;        6379:32228/TCP,8265:30215/TCP,10001:30767/TCP,8000:31482/TCP,52365:30170/TCP,8080:31584/TCP   16h</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">stablediffusion-service-serve-svc   NodePort   172.20.15.224    &lt;none&gt;        8000:30982/TCP                                                                                16h</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">$ kubectl get ingress -n stablediffusion</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NAME                      CLASS   HOSTS   ADDRESS                                                                         PORTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">stablediffusion-ingress   nginx   *       k8s-ingressn-ingressn-7f3f4b475b-1b8966c0b8f4d3da.elb.us-west-2.amazonaws.com   80      16h</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Now, you can access the Ray Dashboard from the Load balancer URL below.</p>
<p>http://&lt;NLB_DNS_NAME&gt;/dashboard/#/serve</p>
<p>If you don&#x27;t have access to a public Load Balancer, you can use port-forwarding and browse the Ray Dashboard using localhost with the following command:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl port-forward svc/stablediffusion-service 8265:8265 -n stablediffusion</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Open the link in the browser</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">http://localhost:8265/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>From this webpage, you will be able to monitor the progress of Model deployment, as shown in the image below:</p>
<p><img decoding="async" loading="lazy" alt="Ray Dashboard" src="/data-on-eks/assets/images/ray-dashboard-sdxl-51432dea23c6c3c166120668cc16ae9d.png" width="1730" height="893" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="to-test-the-stable-diffusion-xl-model">To Test the Stable Diffusion XL Model<a href="#to-test-the-stable-diffusion-xl-model" class="hash-link" aria-label="Direct link to To Test the Stable Diffusion XL Model" title="Direct link to To Test the Stable Diffusion XL Model">​</a></h3>
<p>Once you&#x27;ve verified that the Stable Diffusion model deployment status has switched to a <code>running</code> state in Ray Dashboard , you&#x27;re all set to start leveraging the model. This change in status signifies that the Stable Diffusion model is now fully functional and prepared to handle your image generation requests based on textual descriptions.&quot;</p>
<p>You can use the following URL with a query added at the end of the URL.</p>
<p>http://&lt;NLB_DNS_NAME&gt;/serve/imagine?prompt=an astronaut is dancing on green grass, sunlit</p>
<p>You will see an output like this in your browser:</p>
<p><img decoding="async" loading="lazy" alt="Prompt Output" src="/data-on-eks/assets/images/stable-diffusion-xl-prompt_3-b8210e7d3458390ad4d840ad2f1532fe.png" width="1164" height="742" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploying-the-gradio-webui-app">Deploying the Gradio WebUI App<a href="#deploying-the-gradio-webui-app" class="hash-link" aria-label="Direct link to Deploying the Gradio WebUI App" title="Direct link to Deploying the Gradio WebUI App">​</a></h2>
<p>Discover how to create a user-friendly chat interface using <a href="https://www.gradio.app/" target="_blank" rel="noopener noreferrer">Gradio</a> that integrates seamlessly with deployed models.</p>
<p>Let&#x27;s move forward with setting up the Gradio app as a Docker container running on localhost. This setup will enable interaction with the Stable Diffusion XL model, which is deployed using RayServe.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="build-the-gradio-app-docker-container">Build the Gradio app docker container<a href="#build-the-gradio-app-docker-container" class="hash-link" aria-label="Direct link to Build the Gradio app docker container" title="Direct link to Build the Gradio app docker container">​</a></h3>
<p>First, lets build the docker container for the client app.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd data-on-eks/gen-ai/inference/gradio-ui</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">docker build --platform=linux/amd64 \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    -t gradio-app:sd \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    --build-arg GRADIO_APP=&quot;gradio-app-stable-diffusion.py&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    .</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-the-gradio-container">Deploy the Gradio container<a href="#deploy-the-gradio-container" class="hash-link" aria-label="Direct link to Deploy the Gradio container" title="Direct link to Deploy the Gradio container">​</a></h3>
<p>Deploy the Gradio app as a container on localhost using docker:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run --rm -it -p 7860:7860 -p 8000:8000 gradio-app:sd</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>If you are not running Docker Desktop on your machine and using something like <a href="https://runfinch.com/" target="_blank" rel="noopener noreferrer">finch</a> instead then you will need to additional flags for a custom host-to-IP mapping inside the container.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run --rm -it \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    --add-host ray-service:&lt;workstation-ip&gt; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    -e &quot;SERVICE_NAME=http://ray-service:8000&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    -p 7860:7860 gradio-app:sd</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="invoke-the-webui">Invoke the WebUI<a href="#invoke-the-webui" class="hash-link" aria-label="Direct link to Invoke the WebUI" title="Direct link to Invoke the WebUI">​</a></h4>
<p>Open your web browser and access the Gradio WebUI by navigating to the following URL:</p>
<p>Running on local URL:  <a href="http://localhost:7860" target="_blank" rel="noopener noreferrer">http://localhost:7860</a></p>
<p>You should now be able to interact with the Gradio application from your local machine.</p>
<p><img decoding="async" loading="lazy" alt="Gradio Output" src="/data-on-eks/assets/images/stable-diffusion-xl-gradio-85bc04fb75c2c78e2a2ab1a3eadbd078.png" width="979" height="488" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>In conclusion, you will have successfully deployed the <strong>Stable-diffusion-xl-base</strong> model on EKS with Ray Serve and created a prompt based web UI using Gradio.
This opens up exciting possibilities for natural language processing and prompt based image generator and image predictor development.</p>
<p>In summary, when it comes to deploying and scaling Stable diffusion models, AWS Trn1/Inf2 instances offer a compelling advantage.
They provide the scalability, cost optimization, and performance boost needed to make running large language models efficient and accessible, all while overcoming the challenges associated with the scarcity of GPUs.
Whether you&#x27;re building text-to-image generators, image-to-image generators or any other LLM-driven solution, Trn1/Inf2 instances empower you to harness the full potential of Stable Diffusion LLMs on the AWS cloud.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="cleanup">Cleanup<a href="#cleanup" class="hash-link" aria-label="Direct link to Cleanup" title="Direct link to Cleanup">​</a></h2>
<p>Finally, we&#x27;ll provide instructions for cleaning up and deprovisioning the resources when they are no longer needed.</p>
<p><strong>Step1:</strong> Delete Gradio Container</p>
<p><code>Ctrl-c</code> on the localhost terminal window where <code>docker run</code> is running to kill the container running the Gradio app. Optionally clean up the docker image</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker rmi gradio-app:sd</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Step2:</strong> Delete Ray Cluster</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd data-on-eks/gen-ai/inference/stable-diffusion-xl-base-rayserve-inf2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl delete -f ray-service-stablediffusion.yaml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Step3:</strong> Cleanup the EKS Cluster
This script will cleanup the environment using <code>-target</code> option to ensure all the resources are deleted in correct order.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd data-on-eks/ai-ml/trainium-inferentia/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./cleanup.sh</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/awslabs/data-on-eks/blob/main/website/docs/gen-ai/inference/Neuron/stablediffusion-inf2.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/data-on-eks/docs/gen-ai/inference/Neuron/llama2-inf2"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Llama-2 on Inferentia2</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/data-on-eks/docs/gen-ai/inference/Neuron/rayserve-ha"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Ray Serve High Availability</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#what-is-stable-diffusion" class="table-of-contents__link toc-highlight">What is Stable Diffusion?</a></li><li><a href="#inference-on-trn1inf2-instances-unlocking-the-full-potential-of-stable-diffusion-llms" class="table-of-contents__link toc-highlight">Inference on Trn1/Inf2 Instances: Unlocking the Full Potential of Stable Diffusion LLMs</a><ul><li><a href="#example-usecase" class="table-of-contents__link toc-highlight">Example usecase</a></li></ul></li><li><a href="#solution-architecture" class="table-of-contents__link toc-highlight">Solution Architecture</a></li><li><a href="#deploying-the-solution" class="table-of-contents__link toc-highlight">Deploying the Solution</a><ul><li><a href="#deploy" class="table-of-contents__link toc-highlight">Deploy</a></li><li><a href="#verify-the-resources" class="table-of-contents__link toc-highlight">Verify the resources</a></li></ul></li><li><a href="#deploying-the-ray-cluster-with-stable-diffusion-xl-model" class="table-of-contents__link toc-highlight">Deploying the Ray Cluster with Stable Diffusion XL Model</a><ul><li><a href="#deploy-the-stable-diffusion-xl-base-1-0-model" class="table-of-contents__link toc-highlight">Deploy the Stable-Diffusion-xl-base-1-0 Model</a></li><li><a href="#to-test-the-stable-diffusion-xl-model" class="table-of-contents__link toc-highlight">To Test the Stable Diffusion XL Model</a></li></ul></li><li><a href="#deploying-the-gradio-webui-app" class="table-of-contents__link toc-highlight">Deploying the Gradio WebUI App</a><ul><li><a href="#build-the-gradio-app-docker-container" class="table-of-contents__link toc-highlight">Build the Gradio app docker container</a></li><li><a href="#deploy-the-gradio-container" class="table-of-contents__link toc-highlight">Deploy the Gradio container</a></li></ul></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li><li><a href="#cleanup" class="table-of-contents__link toc-highlight">Cleanup</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Get Started</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/data-on-eks/docs/introduction/intro">Docs</a></li></ul></div><div class="col footer__col"><div class="footer__title">Get Involved</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/awslabs/data-on-eks" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with ❤️ at AWS  <br> © 2025 Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;7fbc7ab02fae4767b1af2588eba0cdf2&quot;}"></script></div>
</body>
</html>