<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-gen-ai/training/GPUs/bionemo" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">bionemo | Data on EKS</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://awslabs.github.io/data-on-eks/docs/gen-ai/training/GPUs/bionemo"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="bionemo | Data on EKS"><meta data-rh="true" name="description" content="The AI on EKS content is being migrated to a new repository."><meta data-rh="true" property="og:description" content="The AI on EKS content is being migrated to a new repository."><link data-rh="true" rel="icon" href="/data-on-eks/img/header-icon.png"><link data-rh="true" rel="canonical" href="https://awslabs.github.io/data-on-eks/docs/gen-ai/training/GPUs/bionemo"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/data-on-eks/docs/gen-ai/training/GPUs/bionemo" hreflang="en"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/data-on-eks/docs/gen-ai/training/GPUs/bionemo" hreflang="x-default"><link rel="stylesheet" href="/data-on-eks/assets/css/styles.264cfa7d.css">
<script src="/data-on-eks/assets/js/runtime~main.c7d0aa17.js" defer="defer"></script>
<script src="/data-on-eks/assets/js/main.d35c188a.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/data-on-eks/"><div class="navbar__logo"><img src="/data-on-eks/img/header-icon.png" alt="DoEKS Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/data-on-eks/img/header-icon.png" alt="DoEKS Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link navbar-highlight-link" href="/data-on-eks/docs/migration/migration-announcement">ðŸš¨ Repo Split Update</a><a class="navbar__item navbar__link" href="/data-on-eks/docs/introduction/intro">Introduction</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/data-on-eks/docs/gen-ai">AI on EKS (ðŸš¨ Moving)</a><a class="navbar__item navbar__link" href="/data-on-eks/docs/blueprints/amazon-emr-on-eks">Blueprints</a><a class="navbar__item navbar__link" href="/data-on-eks/docs/bestpractices/intro">Best Practices</a><a class="navbar__item navbar__link" href="/data-on-eks/docs/benchmarks/emr-on-eks">Benchmarks</a><a class="navbar__item navbar__link" href="/data-on-eks/docs/resources/intro">Resources</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/awslabs/data-on-eks" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/data-on-eks/docs/gen-ai">Overview</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/data-on-eks/docs/category/inference-on-eks">Inference on EKS</a><button aria-label="Expand sidebar category &#x27;Inference on EKS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/data-on-eks/docs/category/training-on-eks">Training on EKS</a><button aria-label="Collapse sidebar category &#x27;Training on EKS&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/data-on-eks/docs/gen-ai/training/GPUs/bionemo">GPUs</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/data-on-eks/docs/gen-ai/training/GPUs/bionemo">BioNeMo on EKS</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/data-on-eks/docs/gen-ai/training/Neuron/Llama-LoRA-Finetuning">Neuron</a></div></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/data-on-eks/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/data-on-eks/docs/category/training-on-eks"><span itemprop="name">Training on EKS</span></a><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">GPUs</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">BioNeMo on EKS</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><div class="theme-admonition theme-admonition-caution admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</div><div class="admonitionContent_BuS1"><p>The <strong>AI on EKS</strong> content <strong>is being migrated</strong> to a new repository.
ðŸ”— ðŸ‘‰ <a href="https://awslabs.github.io/data-on-eks/docs/migration/migration-announcement" target="_blank" rel="noopener noreferrer">Read the full migration announcement Â»</a></p></div></div>
<header><h1>BioNeMo on EKS</h1></header>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_BuS1"><p>Deployment of ML models on EKS requires access to GPUs or Neuron instances. If your deployment isn&#x27;t working, itâ€™s often due to missing access to these resources. Also, some deployment patterns rely on Karpenter autoscaling and static node groups; if nodes aren&#x27;t initializing, check the logs for Karpenter or Node groups to resolve the issue.</p></div></div>
<div class="theme-admonition theme-admonition-caution admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</div><div class="admonitionContent_BuS1"><p>This blueprint should be considered as experimental and should only be used for proof of concept.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">â€‹</a></h2>
<p><a href="https://www.nvidia.com/en-us/clara/bionemo/" target="_blank" rel="noopener noreferrer">NVIDIA BioNeMo</a> is a generative AI platform for drug discovery that simplifies and accelerates the training of models using your own data and scaling the deployment of models for drug discovery applications. BioNeMo offers the quickest path to both AI model development and deployment, accelerating the journey to AI-powered drug discovery. It has a growing community of users and contributors, and is actively maintained and developed by the NVIDIA.</p>
<p>Given its containerized nature, BioNeMo finds versatility in deployment across various environments such as Amazon Sagemaker, AWS ParallelCluster, Amazon ECS, and Amazon EKS. This solution, however, zeroes in on the specific deployment of BioNeMo on Amazon EKS.</p>
<p><em>Source: <a href="https://blogs.nvidia.com/blog/bionemo-on-aws-generative-ai-drug-discovery/" target="_blank" rel="noopener noreferrer">https://blogs.nvidia.com/blog/bionemo-on-aws-generative-ai-drug-discovery/</a></em></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploying-bionemo-on-kubernetes">Deploying BioNeMo on Kubernetes<a href="#deploying-bionemo-on-kubernetes" class="hash-link" aria-label="Direct link to Deploying BioNeMo on Kubernetes" title="Direct link to Deploying BioNeMo on Kubernetes">â€‹</a></h2>
<p>This blueprint leverages three major components for its functionality. The NVIDIA Device Plugin facilitates GPU usage, FSx stores training data, and the Kubeflow Training Operator manages the actual training process.</p>
<ol>
<li><a href="https://www.kubeflow.org/docs/components/training/" target="_blank" rel="noopener noreferrer"><strong>Kubeflow Training Operator</strong></a></li>
<li><a href="https://github.com/NVIDIA/k8s-device-plugin" target="_blank" rel="noopener noreferrer"><strong>NVIDIA Device Plugin</strong></a></li>
<li><a href="https://docs.aws.amazon.com/eks/latest/userguide/fsx-csi.html" target="_blank" rel="noopener noreferrer"><strong>FSx for Lustre CSI Driver</strong></a></li>
</ol>
<p>In this blueprint, we will deploy an Amazon EKS cluster and execute both a data preparation job and a distributed model training job.</p>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h3><span>Pre-requisites</span></h3><span class="icon_PckA">ðŸ‘ˆ</span></div></div>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h3><span>Deploy the blueprint</span></h3><span class="icon_PckA">ðŸ‘ˆ</span></div></div>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h3><span>Verify Deployment</span></h3><span class="icon_PckA">ðŸ‘ˆ</span></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="run-bionemo-training-jobs">Run BioNeMo Training jobs<a href="#run-bionemo-training-jobs" class="hash-link" aria-label="Direct link to Run BioNeMo Training jobs" title="Direct link to Run BioNeMo Training jobs">â€‹</a></h3>
<p>Once you&#x27;ve ensured that all components are functioning properly, you can proceed to submit jobs to your clusters.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="step1-initiate-the-uniref50-data-preparation-task">Step1: Initiate the Uniref50 Data Preparation Task<a href="#step1-initiate-the-uniref50-data-preparation-task" class="hash-link" aria-label="Direct link to Step1: Initiate the Uniref50 Data Preparation Task" title="Direct link to Step1: Initiate the Uniref50 Data Preparation Task">â€‹</a></h4>
<p>The first task, named the <code>uniref50-job.yaml</code>, involves downloading and partitioning the data to enhance processing efficiency. This task specifically retrieves the <code>uniref50 dataset</code> and organizes it within the FSx for Lustre Filesystem. This structured layout is designed for training, testing, and validation purposes. You can learn more about the uniref dataset <a href="https://www.uniprot.org/help/uniref" target="_blank" rel="noopener noreferrer">here</a>.</p>
<p>To execute this job, navigate to the <code>examples\training</code> directory and deploy the <code>uniref50-job.yaml</code> manifest using the following commands:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd examples/training</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply -f uniref50-job.yaml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>It&#x27;s important to note that this task requires a significant amount of time, typically ranging from 50 to 60 hours.</p></div></div>
<p>Run the below command to look for the pod <code>uniref50-download-*</code></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>To verify its progress, examine the logs generated by the corresponding pod:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs uniref50-download-xnz42</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[NeMo I 2024-02-26 23:02:20 preprocess:289] Download and preprocess of UniRef50 data does not currently use GPU. Workstation or CPU-only instance recommended.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[NeMo I 2024-02-26 23:02:20 preprocess:115] Data processing can take an hour or more depending on system resources.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[NeMo I 2024-02-26 23:02:20 preprocess:117] Downloading file from https://ftp.uniprot.org/pub/databases/uniprot/uniref/uniref50/uniref50.fasta.gz...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[NeMo I 2024-02-26 23:02:20 preprocess:75] Downloading file to /fsx/raw/uniref50.fasta.gz...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[NeMo I 2024-02-26 23:08:33 preprocess:89] Extracting file to /fsx/raw/uniref50.fasta...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[NeMo I 2024-02-26 23:12:46 preprocess:311] UniRef50 data processing complete.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[NeMo I 2024-02-26 23:12:46 preprocess:313] Indexing UniRef50 dataset.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[NeMo I 2024-02-26 23:16:21 preprocess:319] Writing processed dataset files to /fsx/processed...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">[NeMo I 2024-02-26 23:16:21 preprocess:255] Creating train split...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>After finishing this task, the processed dataset will be saved in the <code>/fsx/processed</code> directory. Once this is done, we can move forward and start the <code>pre-training</code> job by running the following command:</p>
<p>Following this, we can proceed to execute the pre-training job by running:</p>
<p>In this PyTorchJob YAML, the command <code>python3 -m torch.distributed.run</code> plays a crucial role in orchestrating <strong>distributed training</strong> across multiple worker pods in your Kubernetes cluster.</p>
<p>It handles the following tasks:</p>
<ol>
<li>Initializes a distributed backend (e.g., c10d, NCCL) for communication between worker processes.In our example it&#x27;s using c10d. This is a commonly used distributed backend in PyTorch that can leverage different communication mechanisms like TCP or Infiniband depending on your environment.</li>
<li>Sets up environment variables to enable distributed training within your training script.</li>
<li>Launches your training script on all worker pods, ensuring each process participates in the distributed training.</li>
</ol>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cd examples/training</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl apply -f esm1nv_pretrain-job.yaml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Run the below command to look for the pods <code>esm1nv-pretraining-worker-*</code></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">NAME                           READY   STATUS    RESTARTS   AGE</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">esm1nv-pretraining-worker-0    1/1     Running   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">esm1nv-pretraining-worker-1    1/1     Running   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">esm1nv-pretraining-worker-10   1/1     Running   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">esm1nv-pretraining-worker-11   1/1     Running   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">esm1nv-pretraining-worker-12   1/1     Running   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">esm1nv-pretraining-worker-13   1/1     Running   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">esm1nv-pretraining-worker-14   1/1     Running   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">esm1nv-pretraining-worker-15   1/1     Running   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">esm1nv-pretraining-worker-2    1/1     Running   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">esm1nv-pretraining-worker-3    1/1     Running   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">esm1nv-pretraining-worker-4    1/1     Running   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">esm1nv-pretraining-worker-5    1/1     Running   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">esm1nv-pretraining-worker-6    1/1     Running   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">esm1nv-pretraining-worker-7    1/1     Running   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">esm1nv-pretraining-worker-8    1/1     Running   0          13m</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">esm1nv-pretraining-worker-9    1/1     Running   0          13m</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>We should see 16 pods running. We chose p3.16xlarge instances and each instance has 8 GPUs. In the pod definition we specified each job will leverage 1 gpu.
Since we set up &quot;nprocPerNode&quot; to &quot;8&quot;, each node will be responsible for 8 jobs. Since we have 2 nodes, total of 16 pods will start. For more details around distributed pytorch training see <a href="https://pytorch.org/docs/stable/distributed.html" target="_blank" rel="noopener noreferrer">pytorch docs</a>.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>This training job can run for at least 3-4 days with 2 p3.16xlarge nodes.</p></div></div>
<p>This configuration utilizes Kubeflow&#x27;s PyTorch training Custom Resource Definition (CRD). Within this manifest, various parameters are available for customization. For detailed insights into each parameter and guidance on fine-tuning, you can refer to <a href="https://docs.nvidia.com/bionemo-framework/latest/notebooks/model_training_esm1nv.html" target="_blank" rel="noopener noreferrer">BioNeMo&#x27;s documentation</a>.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>Based on the Kubeflow training operator documentation, if you do not specify the master replica pod explicitly, the first worker replica pod(worker-0) will be treated as the master pod.</p></div></div>
<p>To track the progress of this process, follow these steps:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs esm1nv-pretraining-worker-0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Epoch 0:   7%|â–‹         | 73017/1017679 [00:38&lt;08:12, 1918.0%</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Additionally, to monitor the usage of the GPUs, you have the option to connect to your nodes through the EC2 console using Session Manager and run <code>nvidia-smi</code> command. If you want to have a more robust observability, you can refer to the <a href="https://docs.nvidia.com/datacenter/cloud-native/gpu-telemetry/latest/dcgm-exporter.html" target="_blank" rel="noopener noreferrer">DCGM Exporter</a>.</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">sh-4.2$ nvidia-smi</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Thu Mar  7 16:31:01 2024</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+---------------------------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|-----------------------------------------+----------------------+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                         |                      |               MIG M. |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|=========================================+======================+======================|</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   0  Tesla V100-SXM2-16GB           On  | 00000000:00:17.0 Off |                    0 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| N/A   51C    P0              80W / 300W |   3087MiB / 16384MiB |    100%      Default |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                         |                      |                  N/A |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------------------------+----------------------+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   1  Tesla V100-SXM2-16GB           On  | 00000000:00:18.0 Off |                    0 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| N/A   44C    P0              76W / 300W |   3085MiB / 16384MiB |    100%      Default |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                         |                      |                  N/A |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------------------------+----------------------+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   2  Tesla V100-SXM2-16GB           On  | 00000000:00:19.0 Off |                    0 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| N/A   43C    P0              77W / 300W |   3085MiB / 16384MiB |    100%      Default |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                         |                      |                  N/A |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------------------------+----------------------+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   3  Tesla V100-SXM2-16GB           On  | 00000000:00:1A.0 Off |                    0 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| N/A   52C    P0              77W / 300W |   3085MiB / 16384MiB |    100%      Default |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                         |                      |                  N/A |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------------------------+----------------------+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   4  Tesla V100-SXM2-16GB           On  | 00000000:00:1B.0 Off |                    0 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| N/A   49C    P0              79W / 300W |   3085MiB / 16384MiB |    100%      Default |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                         |                      |                  N/A |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------------------------+----------------------+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   5  Tesla V100-SXM2-16GB           On  | 00000000:00:1C.0 Off |                    0 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| N/A   44C    P0              74W / 300W |   3085MiB / 16384MiB |    100%      Default |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                         |                      |                  N/A |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------------------------+----------------------+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   6  Tesla V100-SXM2-16GB           On  | 00000000:00:1D.0 Off |                    0 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| N/A   44C    P0              78W / 300W |   3085MiB / 16384MiB |    100%      Default |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                         |                      |                  N/A |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------------------------+----------------------+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|   7  Tesla V100-SXM2-16GB           On  | 00000000:00:1E.0 Off |                    0 |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| N/A   50C    P0              79W / 300W |   3085MiB / 16384MiB |    100%      Default |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|                                         |                      |                  N/A |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+-----------------------------------------+----------------------+----------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+---------------------------------------------------------------------------------------+</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">| Processes:                                                                            |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|        ID   ID                                                             Usage      |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|=======================================================================================|</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|    0   N/A  N/A   1552275      C   /usr/bin/python3                           3084MiB |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|    1   N/A  N/A   1552277      C   /usr/bin/python3                           3082MiB |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|    2   N/A  N/A   1552278      C   /usr/bin/python3                           3082MiB |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|    3   N/A  N/A   1552280      C   /usr/bin/python3                           3082MiB |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|    4   N/A  N/A   1552279      C   /usr/bin/python3                           3082MiB |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|    5   N/A  N/A   1552274      C   /usr/bin/python3                           3082MiB |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|    6   N/A  N/A   1552273      C   /usr/bin/python3                           3082MiB |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">|    7   N/A  N/A   1552276      C   /usr/bin/python3                           3082MiB |</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">+---------------------------------------------------------------------------------------+</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="benefits-of-distributed-training">Benefits of Distributed Training:<a href="#benefits-of-distributed-training" class="hash-link" aria-label="Direct link to Benefits of Distributed Training:" title="Direct link to Benefits of Distributed Training:">â€‹</a></h4>
<p>By distributing the training workload across multiple GPUs in your worker pods, you can train large models faster by leveraging the combined computational power of all GPUs. Handle larger datasets that might not fit on a single GPU&#x27;s memory.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">â€‹</a></h4>
<p>BioNeMo stands as a formidable generative AI tool tailored for the realm of drug discovery. In this illustrative example, we took the initiative to pretrain a custom model entirely from scratch, utilizing the extensive uniref50 dataset. However, it&#x27;s worth noting that BioNeMo offers the flexibility to expedite the process by employing pretrained models directly <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/containers/bionemo-framework" target="_blank" rel="noopener noreferrer">provided by NVidia</a>. This alternative approach can significantly streamline your workflow while maintaining the robust capabilities of the BioNeMo framework.</p>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h3><span>Cleanup</span></h3><span class="icon_PckA">ðŸ‘ˆ</span></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/awslabs/data-on-eks/blob/main/website/docs/gen-ai/training/GPUs/bionemo.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/data-on-eks/docs/category/training-on-eks"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Training on EKS</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/data-on-eks/docs/gen-ai/training/Neuron/Llama-LoRA-Finetuning"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Llama-3 with RayTrain on Trn1</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#deploying-bionemo-on-kubernetes" class="table-of-contents__link toc-highlight">Deploying BioNeMo on Kubernetes</a><ul><li><a href="#run-bionemo-training-jobs" class="table-of-contents__link toc-highlight">Run BioNeMo Training jobs</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Get Started</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/data-on-eks/docs/introduction/intro">Docs</a></li></ul></div><div class="col footer__col"><div class="footer__title">Get Involved</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/awslabs/data-on-eks" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with â¤ï¸ at AWS  <br> Â© 2025 Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;7fbc7ab02fae4767b1af2588eba0cdf2&quot;}"></script></div>
</body>
</html>