---
title: EMR Spark Operator
sidebar_label: EMR Spark Operator
sidebar_position: 5
---

# EMR Spark Operator

ì´ ì˜ˆì œëŠ” ì„ ì–¸ì  ì‘ì—… ê´€ë¦¬ë¥¼ ìœ„í•´ AWS EMR Spark Operatorë¥¼ ì‚¬ìš©í•˜ì—¬ EMR on EKSì—ì„œ Spark ì‘ì—…ì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. OperatorëŠ” ì‚¬ìš©ì ì •ì˜ ë¦¬ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ Spark ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì œì¶œí•˜ê³  ê´€ë¦¬í•˜ëŠ” Kubernetes ë„¤ì´í‹°ë¸Œ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.

## í•™ìŠµ ë‚´ìš©

- EMR Spark Operator v7.12.0 í™œì„±í™” ë° ë°°í¬ ë°©ë²•
- SparkApplication CRDë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ ì–¸ì ìœ¼ë¡œ Spark ì‘ì—…ì„ ì œì¶œí•˜ëŠ” ë°©ë²•
- Kubernetesë¥¼ í†µí•´ Spark ì‘ì—…ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ê´€ë¦¬í•˜ëŠ” ë°©ë²•
- EMR Spark Operatorì™€ EMR Virtual Cluster ì‚¬ìš© ì‹œê¸°

## ì´ ì˜ˆì œ ì‚¬ìš© ì‹œê¸°

**ì í•©í•œ ê²½ìš°:**
- âœ… ì„ ì–¸ì  ì‘ì—… ì •ì˜ê°€ í¬í•¨ëœ GitOps ì›Œí¬í”Œë¡œ
- âœ… Kubernetes ë„¤ì´í‹°ë¸Œ Spark ì‘ì—… ê´€ë¦¬
- âœ… Kubernetes Operatorì— ìµìˆ™í•œ íŒ€
- âœ… YAML ë§¤ë‹ˆí˜ìŠ¤íŠ¸ë¡œ Spark ì‘ì—…ì„ ë°°í¬í•˜ëŠ” CI/CD íŒŒì´í”„ë¼ì¸

**ê¶Œì¥í•˜ì§€ ì•ŠëŠ” ê²½ìš°:**
- âŒ ë‹¨ìˆœ ì¼íšŒì„± ì‘ì—… ì œì¶œ (ëŒ€ì‹  `start-job-run` ì‚¬ìš©)
- âŒ Kubernetes ê°œë…ì— ìµìˆ™í•˜ì§€ ì•Šì€ íŒ€
- âŒ EMR Studio í†µí•©ì´ í•„ìš”í•œ ì›Œí¬í”Œë¡œ

## ì•„í‚¤í…ì²˜: EMR Spark Operator

```mermaid
graph TB
    subgraph "EKS í´ëŸ¬ìŠ¤í„°"
        subgraph "emr-spark-operator-ns"
            OP[EMR Spark Operator<br/>v7.12.0]
            WH[Webhook]
        end

        subgraph "emr-data-team-a"
            SA[SparkApplication CRD]
            D[Driver Pod]
            E1[Executor Pod 1]
            E2[Executor Pod 2]
            E3[Executor Pod 3]
        end

        subgraph "ArgoCD"
            APP[emr-spark-operator<br/>Application]
        end
    end

    subgraph "Public ECR"
        IMG[public.ecr.aws/emr-on-eks/<br/>spark-operator:7.12.0]
    end

    APP -->|ë°°í¬| OP
    IMG -->|Pull| OP
    SA -->|ê°ì‹œ| OP
    OP -->|ìƒì„±| D
    D -->|ìƒì„±| E1
    D -->|ìƒì„±| E2
    D -->|ìƒì„±| E3

    style OP fill:#ff9999
    style SA fill:#99ff99
    style APP fill:#9999ff
```

**ì£¼ìš” ì´ì :**
- ğŸ¯ **ì„ ì–¸ì **: Spark ì‘ì—…ì„ Kubernetes ë¦¬ì†ŒìŠ¤ë¡œ ì •ì˜
- ğŸ”„ **GitOps ì§€ì›**: Spark ì‘ì—… ì •ì˜ë¥¼ ë²„ì „ ê´€ë¦¬
- ğŸ“Š **ë„¤ì´í‹°ë¸Œ ëª¨ë‹ˆí„°ë§**: kubectlì„ ì‚¬ìš©í•˜ì—¬ ì‘ì—… ìƒíƒœ ëª¨ë‹ˆí„°ë§
- ğŸš€ **EMR ìµœì í™”**: EMRFS ë° ìµœì í™”ê°€ í¬í•¨ëœ EMR ëŸ°íƒ€ì„ ì‚¬ìš©

**íŠ¸ë ˆì´ë“œì˜¤í”„:**
- âš ï¸ **í•™ìŠµ ê³¡ì„ **: Kubernetes ì§€ì‹ í•„ìš”
- ğŸ”§ **ë” ë³µì¡í•¨**: ê´€ë¦¬í•  ì¶”ê°€ Operator
- ğŸ“ **YAML ì¤‘ì‹¬**: ë‹¨ìˆœ ì‘ì—… ì œì¶œë³´ë‹¤ ì¥í™©í•¨

## ì „ì œ ì¡°ê±´

### 1. EMR on EKS ì¸í”„ë¼ ë°°í¬

ë¨¼ì € EMR on EKS ì¸í”„ë¼ê°€ ë°°í¬ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [ì¸í”„ë¼ ì„¤ì •](./infra.md)ì„ ì°¸ì¡°í•˜ì„¸ìš”.

### 2. EMR Spark Operator í™œì„±í™”

`data-stack.tfvars` íŒŒì¼ì„ í¸ì§‘í•©ë‹ˆë‹¤:

```hcl
# EMR Spark Operator í™œì„±í™”
enable_emr_spark_operator = true
```

### 3. ìŠ¤íƒ ë°°í¬

```bash
cd data-stacks/emr-on-eks
./deploy.sh
```

ì´ ëª…ë ¹ì€ ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
1. ArgoCDë¥¼ í†µí•´ EMR Spark Operator v7.12.0 ë°°í¬
2. `public.ecr.aws/emr-on-eks/spark-operator:7.12.0`ì—ì„œ ê³µê°œ ì´ë¯¸ì§€ ì‚¬ìš©
3. Operator ë„¤ì„ìŠ¤í˜ì´ìŠ¤ `emr-spark-operator-ns` ìƒì„±
4. SparkApplication ê²€ì¦ì„ ìœ„í•œ Webhook êµ¬ì„±

ì˜ˆìƒ ë°°í¬ ì‹œê°„: ì•½ 2-3ë¶„

### 4. Operator ë°°í¬ í™•ì¸

```bash
# kubeconfig ì„¤ì •
export KUBECONFIG=$(pwd)/kubeconfig.yaml

# ArgoCD ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ í™•ì¸
kubectl get application emr-spark-operator -n argocd

# ì˜ˆìƒ ì¶œë ¥:
# NAME                 SYNC STATUS   HEALTH STATUS
# emr-spark-operator   Synced        Healthy

# Operator Pod í™•ì¸
kubectl get pods -n emr-spark-operator-ns

# ì˜ˆìƒ ì¶œë ¥:
# NAME                                    READY   STATUS      RESTARTS   AGE
# emr-spark-operator-c9ff4d9c7-xxxxx      1/1     Running     0          2m
# emr-spark-operator-webhook-init-xxxxx   0/1     Completed   0          2m
```

## EMR Spark Operator vs. Virtual Cluster

| ê¸°ëŠ¥ | EMR Spark Operator | EMR Virtual Cluster |
|------|-------------------|---------------------|
| **ì‘ì—… ì œì¶œ** | Kubernetes CRD | AWS CLI/SDK |
| **ê´€ë¦¬** | kubectl | AWS ì½˜ì†”/CLI |
| **GitOps** | âœ… ë„¤ì´í‹°ë¸Œ | âš ï¸ ë˜í¼ í•„ìš” |
| **ëª¨ë‹ˆí„°ë§** | kubectl/K8s ë„êµ¬ | CloudWatch/EMR ì½˜ì†” |
| **í•™ìŠµ ê³¡ì„ ** | Kubernetes | AWS EMR |
| **EMR Studio** | âŒ ë¯¸ì§€ì› | âœ… ì§€ì› |

## SparkApplication ì‚¬ìš©ì ì •ì˜ ë¦¬ì†ŒìŠ¤

EMR Spark OperatorëŠ” `SparkApplication` CRDë¥¼ ì‚¬ìš©í•˜ì—¬ Spark ì‘ì—…ì„ ì •ì˜í•©ë‹ˆë‹¤:

```yaml
apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: spark-pi-operator
  namespace: emr-data-team-a
spec:
  type: Scala
  mode: cluster

  # EMR ìµœì í™” ëŸ°íƒ€ì„ ì´ë¯¸ì§€
  image: "895885662937.dkr.ecr.us-west-2.amazonaws.com/spark/emr-7.12.0:latest"
  imagePullPolicy: Always

  # ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
  mainClass: org.apache.spark.examples.SparkPi
  mainApplicationFile: local:///usr/lib/spark/examples/jars/spark-examples.jar

  arguments:
    - "1000"

  # Spark êµ¬ì„±
  sparkConf:
    spark.kubernetes.driver.pod.name: driver-spark-pi-operator

  sparkVersion: "3.3.1"

  restartPolicy:
    type: Never

  # Driver êµ¬ì„±
  driver:
    cores: 2
    memory: "8g"
    # EMR ê°€ìƒ í´ëŸ¬ìŠ¤í„° ëª¨ë“ˆì—ì„œ ìƒì„±í•œ ì„œë¹„ìŠ¤ ê³„ì •
    # ì‹¤ì œ ì´ë¦„ í™•ì¸: kubectl get sa -n emr-data-team-a | grep driver
    serviceAccount: emr-containers-sa-spark-driver-<deployment-id>

    nodeSelector:
      NodeGroupType: "SparkGravitonComputeOptimized"

    labels:
      app: spark-pi-operator
      role: driver

  # Executor êµ¬ì„±
  executor:
    cores: 4
    instances: 3
    memory: "16g"
    # EMR ê°€ìƒ í´ëŸ¬ìŠ¤í„° ëª¨ë“ˆì—ì„œ ìƒì„±í•œ ì„œë¹„ìŠ¤ ê³„ì •
    # ì‹¤ì œ ì´ë¦„ í™•ì¸: kubectl get sa -n emr-data-team-a | grep executor
    serviceAccount: emr-containers-sa-spark-executor-<deployment-id>

    nodeSelector:
      NodeGroupType: "SparkGravitonComputeOptimized"

    labels:
      app: spark-pi-operator
      role: executor
```

## ì˜ˆì œ ì‹¤í–‰

### 1. kubectl ì ‘ê·¼ êµ¬ì„±

```bash
# terraform ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd data-stacks/emr-on-eks/terraform/_local

# kubectl êµ¬ì„± ëª…ë ¹ì–´ ê°€ì ¸ì˜¤ê¸°
terraform output configure_kubectl

# ì¶œë ¥ ëª…ë ¹ì–´ ì‹¤í–‰ (ì˜ˆì‹œ):
aws eks --region us-west-2 update-kubeconfig --name emr-on-eks

# ì ‘ê·¼ í™•ì¸
kubectl get nodes
```

### 2. ì˜ˆì œ ë””ë ‰í† ë¦¬ë¡œ ì´ë™

```bash
cd ../../examples/emr-spark-operator
```

### 3. ì„œë¹„ìŠ¤ ê³„ì • ì´ë¦„ ê°€ì ¸ì˜¤ê¸°

EMR ê°€ìƒ í´ëŸ¬ìŠ¤í„° ëª¨ë“ˆì€ AWS ê³„ì • IDì™€ ë°°í¬ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì  ì´ë¦„ìœ¼ë¡œ ì„œë¹„ìŠ¤ ê³„ì •ì„ ìƒì„±í•©ë‹ˆë‹¤. ì‹¤ì œ ì´ë¦„ì„ ê°€ì ¸ì™€ì•¼ í•©ë‹ˆë‹¤:

```bash
# kubeconfig ì„¤ì •
export KUBECONFIG=../../kubeconfig.yaml

# Driver ì„œë¹„ìŠ¤ ê³„ì • ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
DRIVER_SA=$(kubectl get sa -n emr-data-team-a | grep driver | awk '{print $1}')
echo "Driver SA: $DRIVER_SA"

# Executor ì„œë¹„ìŠ¤ ê³„ì • ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
EXECUTOR_SA=$(kubectl get sa -n emr-data-team-a | grep executor | awk '{print $1}')
echo "Executor SA: $EXECUTOR_SA"

# ì˜ˆìƒ ì¶œë ¥:
# Driver SA: emr-containers-sa-spark-driver-123456789012-abcdefghijklmnopqrstuvwxyz1234567890abcd
# Executor SA: emr-containers-sa-spark-executor-123456789012-abcdefghijklmnopqrstuvwxyz1234567890abcd
```

### 4. SparkApplication YAML ì—…ë°ì´íŠ¸

YAML íŒŒì¼ì—ì„œ ì„œë¹„ìŠ¤ ê³„ì • ì´ë¦„ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤:

```bash
# ìë™ìœ¼ë¡œ ì„œë¹„ìŠ¤ ê³„ì • ì´ë¦„ ì—…ë°ì´íŠ¸
sed -i.bak "s/serviceAccount: emr-containers-sa-spark-driver-.*/serviceAccount: $DRIVER_SA/" taxi-trip-spark-operator.yaml
sed -i.bak "s/serviceAccount: emr-containers-sa-spark-executor-.*/serviceAccount: $EXECUTOR_SA/" taxi-trip-spark-operator.yaml
```

ë˜ëŠ” `taxi-trip-spark-operator.yaml`ì„ ìˆ˜ë™ìœ¼ë¡œ í¸ì§‘í•˜ì—¬ ì„œë¹„ìŠ¤ ê³„ì • ì´ë¦„ì„ êµì²´í•©ë‹ˆë‹¤.

### 5. SparkApplication ê²€í† 

ì˜ˆì œì— í¬í•¨ëœ í•­ëª©:
- `taxi-trip-spark-operator.yaml` - Spark Pi ê³„ì‚°ì„ ìœ„í•œ SparkApplication ë§¤ë‹ˆí˜ìŠ¤íŠ¸
- `README.md` - ë¹ ë¥¸ ì°¸ì¡° ê°€ì´ë“œ

ì£¼ìš” êµ¬ì„±:
- EMR 7.12.0 ëŸ°íƒ€ì„ ì´ë¯¸ì§€ ì‚¬ìš©
- Spark Pi ì˜ˆì œ ì‹¤í–‰ (ëª¬í…Œì¹´ë¥¼ë¡œ ë°©ë²•ìœ¼ë¡œ Ï€ ê³„ì‚°)
- Graviton ì»´í“¨íŒ… ìµœì í™” ë…¸ë“œìš©ìœ¼ë¡œ êµ¬ì„±ë¨
- S3 ì ‘ê·¼ì´ ê°€ëŠ¥í•œ EMR ì„œë¹„ìŠ¤ ê³„ì • ì‚¬ìš©

### 6. Spark ì‘ì—… ì œì¶œ

```bash
# SparkApplication ì ìš©
kubectl apply -f taxi-trip-spark-operator.yaml

# ì˜ˆìƒ ì¶œë ¥:
# sparkapplication.sparkoperator.k8s.io/spark-pi-operator created
```

### 7. ì‘ì—… ëª¨ë‹ˆí„°ë§

```bash
# SparkApplication ìƒíƒœ í™•ì¸
kubectl get sparkapplication spark-pi-operator -n emr-data-team-a -w

# ì˜ˆìƒ ì§„í–‰ ìƒí™©:
# NAME                STATUS      ATTEMPTS   START                  FINISH
# spark-pi-operator   SUBMITTED   1          2026-01-18T01:49:09Z   <no value>
# spark-pi-operator   RUNNING     1          2026-01-18T01:49:09Z   <no value>
# spark-pi-operator   COMPLETED   1          2026-01-18T01:49:09Z   2026-01-18T01:51:40Z

# ì‹¤ì‹œê°„ìœ¼ë¡œ Pod í™•ì¸
kubectl get pods -n emr-data-team-a -l app=spark-pi-operator -w

# ì˜ˆìƒ ì¶œë ¥:
# NAME                               READY   STATUS    RESTARTS   AGE
# driver-spark-pi-operator           1/1     Running   0          30s
# spark-pi-c992669bcecb9646-exec-1   1/1     Running   0          20s
# spark-pi-c992669bcecb9646-exec-2   1/1     Running   0          20s
# spark-pi-c992669bcecb9646-exec-3   1/1     Running   0          20s
```

### 8. ì‘ì—… ë¡œê·¸ ë³´ê¸°

```bash
# Driver ë¡œê·¸ ë³´ê¸°
kubectl logs driver-spark-pi-operator -n emr-data-team-a

# Executor ë¡œê·¸ ë³´ê¸°
kubectl logs spark-pi-c992669bcecb9646-exec-1 -n emr-data-team-a
```

### 9. ê²°ê³¼ í™•ì¸

```bash
# ê³„ì‚°ëœ Pi ê°’ í™•ì¸
kubectl logs driver-spark-pi-operator -n emr-data-team-a | grep "Pi is roughly"

# ì˜ˆìƒ ì¶œë ¥:
# Pi is roughly 3.141532511415325
```

### 10. ì‘ì—… ì„¸ë¶€ ì •ë³´ í™•ì¸

```bash
# ìƒì„¸í•œ SparkApplication ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
kubectl describe sparkapplication spark-pi-operator -n emr-data-team-a

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ë²¤íŠ¸ ë³´ê¸°
kubectl get events -n emr-data-team-a --sort-by='.lastTimestamp' | grep spark-pi
```

## ì‘ì—… ë¼ì´í”„ì‚¬ì´í´

### ìƒíƒœ ì§„í–‰

1. **SUBMITTED** - Operatorê°€ ì‘ì—…ì„ ìˆ˜ë½, Driver Pod ìƒì„± ì¤‘
2. **RUNNING** - Driver Pod ì‹¤í–‰ ì¤‘, Executor ìƒì„± ì¤‘
3. **COMPLETED** - ì‘ì—… ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ
4. **FAILED** - ì‘ì—… ì‹¤íŒ¨ (ì˜¤ë¥˜ ë¡œê·¸ í™•ì¸)

### ìë™ ì •ë¦¬

OperatorëŠ” `restartPolicy`ì— ë”°ë¼ ì™„ë£Œëœ ì‘ì—…ì„ ìë™ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤:

```yaml
restartPolicy:
  type: Never  # ì™„ë£Œ ì‹œ ì¬ì‹œì‘í•˜ì§€ ì•ŠìŒ
```

ì™„ë£Œ í›„ ìë™ ì •ë¦¬:

```yaml
spec:
  timeToLiveSeconds: 3600  # 1ì‹œê°„ í›„ ì‚­ì œ
```

## ê³ ê¸‰ êµ¬ì„±

### 1. ë™ì  í• ë‹¹

Spark ë™ì  í• ë‹¹ í™œì„±í™”:

```yaml
sparkConf:
  spark.dynamicAllocation.enabled: "true"
  spark.dynamicAllocation.shuffleTracking.enabled: "true"
  spark.dynamicAllocation.minExecutors: "2"
  spark.dynamicAllocation.maxExecutors: "10"
  spark.dynamicAllocation.initialExecutors: "3"
```

### 2. S3ì— ì´ë²¤íŠ¸ ë¡œê¹…

Spark History Server í†µí•© í™œì„±í™”:

```yaml
sparkConf:
  spark.eventLog.enabled: "true"
  spark.eventLog.dir: "s3://your-bucket/spark-event-logs/"
```

### 3. ì‚¬ìš©ì ì •ì˜ EMR êµ¬ì„±

EMRFS ë° EMR ìµœì í™” ì‚¬ìš©:

```yaml
hadoopConf:
  fs.s3.customAWSCredentialsProvider: com.amazonaws.auth.WebIdentityTokenCredentialsProvider
  fs.s3.impl: com.amazon.ws.emr.hadoop.fs.EmrFileSystem
  fs.AbstractFileSystem.s3.impl: org.apache.hadoop.fs.s3.EMRFSDelegate

sparkConf:
  spark.sql.parquet.output.committer.class: com.amazon.emr.committer.EmrOptimizedSparkSqlParquetOutputCommitter
  spark.sql.parquet.fs.optimized.committer.optimization-enabled: "true"
  spark.sql.emr.internal.extensions: com.amazonaws.emr.spark.EmrSparkSessionExtensions
```

### 4. ëª¨ë‹ˆí„°ë§ ë° ê´€ì¸¡ì„±

Prometheus ë©”íŠ¸ë¦­ ì¶”ê°€:

```yaml
sparkConf:
  spark.ui.prometheus.enabled: "true"
  spark.executor.processTreeMetrics.enabled: "true"
  spark.metrics.conf.*.sink.prometheusServlet.class: org.apache.spark.metrics.sink.PrometheusServlet
  spark.metrics.conf.*.sink.prometheusServlet.path: /metrics/prometheus
```

## ë¬¸ì œ í•´ê²°

### ì‘ì—…ì´ SUBMITTEDì—ì„œ ë©ˆì¶¤

Operator ë¡œê·¸ í™•ì¸:

```bash
kubectl logs -n emr-spark-operator-ns -l app.kubernetes.io/name=spark-operator
```

ì¼ë°˜ì ì¸ ë¬¸ì œ:
- ì„œë¹„ìŠ¤ ê³„ì •ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ
- ì´ë¯¸ì§€ Pull ì˜¤ë¥˜
- ë¦¬ì†ŒìŠ¤ ë¶€ì¡±

### Driver Podê°€ Pending

Pod ì´ë²¤íŠ¸ í™•ì¸:

```bash
kubectl describe pod driver-spark-pi-operator -n emr-data-team-a
```

ì¼ë°˜ì ì¸ ë¬¸ì œ:
- nodeSelectorì™€ ì¼ì¹˜í•˜ëŠ” ë…¸ë“œ ì—†ìŒ
- CPU/ë©”ëª¨ë¦¬ ë¶€ì¡±
- ì´ë¯¸ì§€ Pull ì‹¤íŒ¨

### ê¶Œí•œ ì˜¤ë¥˜

ì„œë¹„ìŠ¤ ê³„ì •ì— ì˜¬ë°”ë¥¸ IAM ì—­í• ì´ ìˆëŠ”ì§€ í™•ì¸:

```bash
# Driver ì„œë¹„ìŠ¤ ê³„ì • í™•ì¸
kubectl get sa emr-containers-sa-spark-driver-* -n emr-data-team-a -o yaml

# IAM ì—­í•  ì–´ë…¸í…Œì´ì…˜ í™•ì¸
kubectl get sa emr-containers-sa-spark-driver-* -n emr-data-team-a \
  -o jsonpath='{.metadata.annotations.eks\.amazonaws\.com/role-arn}'
```

### ì‘ì—… ì‹¤íŒ¨

ì˜¤ë¥˜ì— ëŒ€í•œ Driver ë¡œê·¸ í™•ì¸:

```bash
kubectl logs driver-spark-pi-operator -n emr-data-team-a --tail=100
```

ì¼ë°˜ì ì¸ ë¬¸ì œ:
- S3 ì ‘ê·¼ ê±°ë¶€
- ì˜ëª»ëœ Spark êµ¬ì„±
- ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ì˜¤ë¥˜

## ëª¨ë²” ì‚¬ë¡€

### 1. ë²„ì „ ê´€ë¦¬ ì‚¬ìš©

SparkApplication ë§¤ë‹ˆí˜ìŠ¤íŠ¸ë¥¼ Gitì— ì €ì¥:

```bash
git add taxi-trip-spark-operator.yaml
git commit -m "Add Spark Pi job"
git push
```

### 2. ConfigMapìœ¼ë¡œ ë§¤ê°œë³€ìˆ˜í™”

í™˜ê²½ë³„ ê°’ì— ConfigMap ì‚¬ìš©:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-config
  namespace: emr-data-team-a
data:
  s3_bucket: "my-spark-bucket"
  log_level: "INFO"
---
apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
spec:
  sparkConf:
    spark.eventLog.dir: "s3://$(S3_BUCKET)/logs/"
  driver:
    envFrom:
      - configMapRef:
          name: spark-config
```

### 3. ë¦¬ì†ŒìŠ¤ ì œí•œ ì„¤ì •

ë¦¬ì†ŒìŠ¤ ê³ ê°ˆ ë°©ì§€:

```yaml
driver:
  cores: 2
  coreLimit: "2000m"
  memory: "8g"
  memoryOverhead: "1g"

executor:
  cores: 4
  coreLimit: "4000m"
  memory: "16g"
  memoryOverhead: "2g"
```

### 4. ëª¨ë‹ˆí„°ë§ í™œì„±í™”

ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ë ˆì´ë¸” ì¶”ê°€:

```yaml
metadata:
  labels:
    app: spark-jobs
    team: data-engineering
    environment: production
```

### 5. ì™„ë£Œëœ ì‘ì—… ì •ë¦¬

ìë™ ì •ë¦¬ë¥¼ ìœ„í•œ TTL ì„¤ì •:

```yaml
spec:
  timeToLiveSeconds: 86400  # 24ì‹œê°„ í›„ ì‚­ì œ
```

## ë‹¤ë¥¸ ì œì¶œ ë°©ë²•ê³¼ ë¹„êµ

### vs. EMR Virtual Cluster (start-job-run)

| ê¸°ëŠ¥ | Spark Operator | start-job-run |
|------|---------------|---------------|
| **ì œì¶œ** | kubectl apply | AWS CLI |
| **ëª¨ë‹ˆí„°ë§** | kubectl get | AWS ì½˜ì†” |
| **GitOps** | âœ… ë„¤ì´í‹°ë¸Œ | âš ï¸ ë˜í¼ í•„ìš” |
| **ë³µì¡ë„** | ë†’ìŒ | ë‚®ìŒ |
| **EMR Studio** | âŒ | âœ… |

### vs. Spark Operator (Kubeflow)

| ê¸°ëŠ¥ | EMR Spark Operator | Kubeflow Spark Operator |
|------|-------------------|------------------------|
| **ëŸ°íƒ€ì„** | EMR ìµœì í™” | ì˜¤í”ˆì†ŒìŠ¤ Spark |
| **EMRFS** | âœ… ê¸°ë³¸ ì œê³µ | âŒ ë¯¸í¬í•¨ |
| **ì§€ì›** | AWS ì§€ì› | ì»¤ë®¤ë‹ˆí‹° |
| **ê¸°ëŠ¥** | EMR í™•ì¥ | í‘œì¤€ Spark |

## ë‹¤ìŒ ë‹¨ê³„

- [NVMe SSD ìŠ¤í† ë¦¬ì§€](./nvme-ssd.md) - ê³ ì„±ëŠ¥ ì…”í”Œ ìŠ¤í† ë¦¬ì§€
- [EBS Hostpath ìŠ¤í† ë¦¬ì§€](./ebs-hostpath.md) - ë¹„ìš© íš¨ìœ¨ì ì¸ ê³µìœ  ìŠ¤í† ë¦¬ì§€
- [ì¸í”„ë¼ ê°€ì´ë“œ](./infra.md) - ë°°í¬ ì»¤ìŠ¤í„°ë§ˆì´ì§•

## ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- [EMR Spark Operator ë¬¸ì„œ](https://docs.aws.amazon.com/emr/latest/EMR-on-EKS-DevelopmentGuide/spark-operator-gs.html)
- [SparkApplication API ì°¸ì¡°](https://github.com/kubeflow/spark-operator/blob/master/docs/api-docs.md)
- [EMR on EKS ëª¨ë²” ì‚¬ë¡€](https://aws.github.io/aws-emr-containers-best-practices/)
