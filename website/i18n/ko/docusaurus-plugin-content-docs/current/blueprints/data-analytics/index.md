---
sidebar_position: 1
sidebar_label: 소개
---

# EKS 기반 데이터 분석

Kubernetes에서 데이터 분석 도구를 실행하면 대규모의 복잡한 데이터 세트에서 인사이트를 추출하려는 조직에 많은 이점을 제공할 수 있습니다. **Apache Spark** 및 **DASK**와 같은 도구는 머신 클러스터에서 실행되도록 설계되어 Kubernetes 배포에 적합합니다.

Kubernetes용 **Spark Operator**는 Kubernetes에서 Apache Spark의 배포 및 관리를 단순화하는 인기 있는 Kubernetes 오퍼레이터입니다. Spark Operator를 사용하면 조직은 자동 스케일링, 롤링 업데이트, 자가 복구 기능과 같은 기능을 활용하여 데이터 분석 파이프라인의 고가용성과 안정성을 보장할 수 있습니다. 이를 통해 복잡한 애플리케이션의 배포, 스케일링 및 관리를 크게 단순화하고 자동화하여 데이터 과학자와 엔지니어가 데이터 분석 및 해석에 집중할 수 있습니다.

도구 에코시스템이 성장하고 다양한 사용 사례를 지원함에 따라 Kubernetes는 프로덕션 환경에서 데이터 분석 플랫폼을 실행하기 위한 점점 더 인기 있는 선택이 되고 있습니다.
- [Spark Operator](https://github.com/GoogleCloudPlatform/spark-on-k8s-operator)
- [Spark Submit](https://spark.apache.org/docs/latest/running-on-kubernetes.html)
- [Karpenter](https://karpenter.sh/)
- [Apache YuniKorn](https://yunikorn.apache.org/)
- [Volcano](https://volcano.sh/en/)
