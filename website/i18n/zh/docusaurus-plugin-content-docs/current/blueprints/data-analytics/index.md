---
sidebar_position: 1
sidebar_label: 介绍
---

# EKS 上的数据分析

在 Kubernetes 上运行数据分析工具可以为希望从大型复杂数据集中提取洞察的组织提供多种优势。像 **Apache Spark** 和 **DASK** 这样的工具设计用于在机器集群上运行，使它们非常适合部署在 Kubernetes 上。

Kubernetes 的 **Spark Operator** 是一个流行的 Kubernetes 操作符，它简化了 Apache Spark 在 Kubernetes 上的部署和管理。通过使用 Spark Operator，组织可以利用自动扩展、滚动更新和自我修复等功能，确保数据分析管道的高可用性和可靠性。这可以极大地简化和自动化这些复杂应用程序的部署、扩展和管理，使数据科学家和工程师能够专注于数据的分析和解释。

随着其不断增长的工具生态系统和对广泛用例的支持，Kubernetes 正成为在生产环境中运行数据分析平台的越来越受欢迎的选择。
- [Spark Operator](https://github.com/GoogleCloudPlatform/spark-on-k8s-operator)
- [Spark Submit](https://spark.apache.org/docs/latest/running-on-kubernetes.html)
- [Karpenter](https://karpenter.sh/)
- [Apache YuniKorn](https://yunikorn.apache.org/)
- [Volcano](https://volcano.sh/en/)
