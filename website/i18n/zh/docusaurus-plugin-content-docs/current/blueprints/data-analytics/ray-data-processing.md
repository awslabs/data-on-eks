---
sidebar_position: 7
sidebar_label: Ray Data on EKS
mermaid: true
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CollapsibleContent from '../../../../../../src/components/CollapsibleContent';

# ä½¿ç”¨ Ray Data è¿›è¡Œåˆ†å¸ƒå¼æ•°æ®å¤„ç†

## ä»€ä¹ˆæ˜¯ Ray Dataï¼Ÿ

[Ray Data](https://docs.ray.io/en/latest/data/data.html) æ˜¯ä¸€ä¸ªå¯æ‰©å±•çš„ã€æ¡†æ¶æ— å…³çš„æ•°æ®å¤„ç†åº“ï¼Œæ„å»ºåœ¨ Ray ä¹‹ä¸Šï¼Œä¸“ä¸ºåˆ†å¸ƒå¼æ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ å·¥ä½œè´Ÿè½½è€Œè®¾è®¡ã€‚å®ƒæä¾›ï¼š

- **åˆ†å¸ƒå¼å¤„ç†**ï¼šè·¨å¤šä¸ª Ray å·¥ä½œèŠ‚ç‚¹çš„å¹¶è¡Œæ•°æ®å¤„ç†
- **æƒ°æ€§æ±‚å€¼**ï¼šæ“ä½œè¢«ä¼˜åŒ–å¹¶ä»…åœ¨éœ€è¦ç»“æœæ—¶æ‰§è¡Œ
- **ä¸°å¯Œçš„æ•°æ®è¿æ¥å™¨**ï¼šå¯¹å„ç§æ•°æ®æºçš„åŸç”Ÿæ”¯æŒï¼ŒåŒ…æ‹¬ S3ã€æ•°æ®åº“å’Œæ–‡ä»¶ç³»ç»Ÿ
- **å†…å­˜ç®¡ç†**ï¼šé«˜æ•ˆå¤„ç†ä¸é€‚åˆå†…å­˜çš„å¤§å‹æ•°æ®é›†
- **ä¸æœºå™¨å­¦ä¹ åº“é›†æˆ**ï¼šä¸ pandasã€NumPy å’Œ PyArrow æ— ç¼é›†æˆ

## ä¸ºä»€ä¹ˆé€‰æ‹© Ray Dataï¼Ÿè¿™æ˜¯ Spark çš„æ›¿ä»£å·¥å…·å—ï¼Ÿ

Ray Data æ˜¯ **Spark çš„è¡¥å……**ï¼Œè€Œä¸æ˜¯ç›´æ¥æ›¿ä»£å“ã€‚è™½ç„¶ä¸¤è€…éƒ½æ˜¯åˆ†å¸ƒå¼æ•°æ®å¤„ç†æ¡†æ¶ï¼Œä½†å®ƒä»¬æœåŠ¡äºä¸åŒçš„ç”¨ä¾‹ï¼š

```mermaid
graph LR
    subgraph AS["<b>Apache Spark</b>"]
        A[å¤§è§„æ¨¡æ•°æ®åˆ†æ]
        B[åˆ†å¸ƒå¼ SQL åˆ†æ]
        C[æ‰¹å¤„ç†/æµå¤„ç†]
    end

    subgraph RD["<b>Ray Data</b>"]
        D[æœºå™¨å­¦ä¹ æ•°æ®é¢„å¤„ç†]
        E[å®æ—¶æ¨ç†]
        F[è¿­ä»£å·¥ä½œè´Ÿè½½]
        G[Python åŸç”Ÿå¤„ç†]
    end

    subgraph CU["<b>å¸¸è§ç”¨ä¾‹</b>"]
        H[æ•°æ®è½¬æ¢]
        I[åˆ†å¸ƒå¼è®¡ç®—]
    end

    style A fill:#37474f,color:#fff
    style B fill:#37474f,color:#fff
    style C fill:#37474f,color:#fff
    style D fill:#FF6B6B,stroke:#FF4444,stroke-width:3px,color:#fff
    style E fill:#4ECDC4,stroke:#45B7AA,stroke-width:3px,color:#fff
    style F fill:#FFE66D,stroke:#FFD93D,stroke-width:3px,color:#333
    style G fill:#A8E6CF,stroke:#7FD4A0,stroke-width:3px,color:#333
    style H fill:#455a64,color:#fff
    style I fill:#455a64,color:#fff
```

**Ray Data åœ¨ä»¥ä¸‹æƒ…å†µä¸‹è¡¨ç°å‡ºè‰²ï¼š**
- ä½¿ç”¨ç†Ÿæ‚‰çš„ pandas/NumPy API è¿›è¡Œ Python åŸç”Ÿæ•°æ®å¤„ç†
- ä¸æœºå™¨å­¦ä¹ ç®¡é“ç´§å¯†é›†æˆ
- å®æ—¶æˆ–æµæ•°æ®å¤„ç†
- å¤æ‚çš„è¿­ä»£ç®—æ³•

**Spark ä»ç„¶æ˜¯ä»¥ä¸‹åœºæ™¯çš„ç†æƒ³é€‰æ‹©ï¼š**
- å¤§è§„æ¨¡ ETL æ“ä½œ
- å¤æ‚çš„åŸºäº SQL çš„åˆ†æ
- ä¼ä¸šæ•°æ®ä»“åº“å·¥ä½œè´Ÿè½½
- è·¨è¯­è¨€æ”¯æŒï¼ˆScalaã€Javaã€Pythonã€Rï¼‰

### é—®é¢˜é™ˆè¿°

å½“ Apache Spark åº”ç”¨ç¨‹åºåœ¨ Kubernetes ä¸Šè¿è¡Œæ—¶ï¼Œå®ƒä»¬ä¼šç”Ÿæˆå¤§é‡æ—¥å¿—ï¼Œè¿™äº›æ—¥å¿—ç”± Fluent Bit æ•è·å¹¶å†™å…¥ S3ã€‚ç„¶è€Œï¼Œè¿™äº›æ—¥å¿—ç»™æ•°æ®å·¥ç¨‹å¸ˆå¸¦æ¥äº†å‡ ä¸ªæŒ‘æˆ˜ï¼š

1. **éç»“æ„åŒ–æ ¼å¼**ï¼šSpark æ—¥å¿—ä»¥åŸå§‹æ–‡æœ¬æ–‡ä»¶å½¢å¼å†™å…¥ï¼Œæ²¡æœ‰ä¸€è‡´çš„æ¨¡å¼
2. **æ— æŸ¥è¯¢èƒ½åŠ›**ï¼šå·¥ç¨‹å¸ˆæ— æ³•ä½¿ç”¨åŸºäº SQL çš„å·¥å…·ï¼ˆå¦‚ Amazon Athenaï¼‰è½»æ¾æŸ¥è¯¢æ—¥å¿—
3. **å…ƒæ•°æ®ä¸°å¯Œ**ï¼šFluent Bit å°† Kubernetes å…ƒæ•°æ®æ·»åŠ ä¸º JSONï¼Œåˆ›å»ºæ··åˆæ ¼å¼
4. **æ€§èƒ½é—®é¢˜**ï¼šæ‰«æåŸå§‹æ—¥å¿—æ–‡ä»¶è¿›è¡Œæ•…éšœæ’é™¤æ—¢è€—æ—¶åˆæ˜‚è´µ

```mermaid
graph TB
    subgraph UL["<b>éç»“æ„åŒ–æ—¥å¿—</b>"]
        Spark[Spark åº”ç”¨ç¨‹åº] -->|åŸå§‹æ—¥å¿—| FB[Fluent Bit]
        FB -->|ä¸°å¯Œçš„ JSON| S3Raw[S3 åŸå§‹æ—¥å¿—]
        S3Raw -->|âŒ æ— æ¨¡å¼| Query[æ— æ³•é«˜æ•ˆæŸ¥è¯¢]
    end

    style Spark fill:#ff9800,color:#fff
    style FB fill:#2196F3,color:#fff
    style S3Raw fill:#f44336,color:#fff
    style Query fill:#9e9e9e,color:#fff
```

**è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨ Ray Data å®šæœŸå¤„ç†è¿™äº›éç»“æ„åŒ–æ—¥å¿—ï¼Œåº”ç”¨ä¸€è‡´çš„æ¨¡å¼ï¼Œå¹¶å°†å®ƒä»¬å†™å…¥ Apache Iceberg è¡¨ã€‚è¿™ä½¿å¾—ï¼š
- âœ… é€šè¿‡ Amazon Athena è¿›è¡Œ SQL æŸ¥è¯¢
- âœ… å…·æœ‰å®šä¹‰æ¨¡å¼çš„ç»“æ„åŒ–æ•°æ®
- âœ… é«˜æ•ˆçš„åˆ—å¼å­˜å‚¨æ ¼å¼
- âœ… æ—¶é—´æ—…è¡Œå’Œç‰ˆæœ¬æ§åˆ¶åŠŸèƒ½

### å¤„ç†å‰ S3 ä¸­çš„æ—¥å¿—ç‰‡æ®µ

ä»¥ä¸‹æ˜¯ Fluent Bit å†™å…¥ S3 æ—¶ Spark æ—¥å¿—çš„æ ·å­ï¼š

```json
{
  "log": "2024-01-15 14:23:45 INFO SparkContext: Running Spark version 3.5.0\n",
  "stream": "stdout",
  "time": "2024-01-15T14:23:45.123456Z",
  "kubernetes": {
    "pod_name": "spark-driver-abc123",
    "namespace_name": "spark-team-a",
    "pod_id": "12345678-1234-1234-1234-123456789012",
    "labels": {
      "spark-role": "driver",
      "spark-app-id": "spark-application-12345"
    },
    "container_name": "spark-driver",
    "container_image": "spark:3.5.0"
  }
}
{
  "log": "2024-01-15 14:23:46 INFO ResourceUtils: Using Spark's default log4j profile\n",
  "stream": "stdout",
  "time": "2024-01-15T14:23:46.234567Z",
  "kubernetes": {
    "pod_name": "spark-driver-abc123",
    "namespace_name": "spark-team-a",
    "pod_id": "12345678-1234-1234-1234-123456789012",
    "labels": {
      "spark-role": "driver",
      "spark-app-id": "spark-application-12345"
    },
    "container_name": "spark-driver",
    "container_image": "spark:3.5.0"
  }
}
```

**ä¸»è¦æŒ‘æˆ˜ï¼š**

- æ¯ä¸ªæ—¥å¿—è¡Œéƒ½åŒ…è£…åœ¨å¸¦æœ‰ Kubernetes å…ƒæ•°æ®çš„ JSON ä¸­
- å®é™…çš„æ—¥å¿—æ¶ˆæ¯åµŒå…¥åœ¨ `log` å­—æ®µä¸­
- æ²¡æœ‰ç”¨äºæŸ¥è¯¢ç‰¹å®šæ—¥å¿—çº§åˆ«æˆ–ç»„ä»¶çš„ç»“æ„åŒ–æ¨¡å¼
- æ¯ä¸ªæ—¥å¿—è¡Œé‡å¤å†—ä½™å…ƒæ•°æ®

:::info Fluent Bit ä¸°å¯Œ
Fluent Bit è‡ªåŠ¨ä½¿ç”¨ Kubernetes å…ƒæ•°æ®ä¸°å¯Œæ¯ä¸ªæ—¥å¿—è¡Œï¼ŒåŒ…æ‹¬ pod åç§°ã€å‘½åç©ºé—´ã€æ ‡ç­¾å’Œå®¹å™¨ä¿¡æ¯ã€‚æ­¤ä¸°å¯Œåœ¨ [aws-for-fluentbit-values.yaml](https://github.com/awslabs/data-on-eks/blob/main/analytics/terraform/spark-k8s-operator/helm-values/aws-for-fluentbit-values.yaml) æ–‡ä»¶ä¸­é…ç½®ã€‚è™½ç„¶æ­¤å…ƒæ•°æ®å¯¹è°ƒè¯•å¾ˆæœ‰ä»·å€¼ï¼Œä½†å®ƒåˆ›å»ºäº†éš¾ä»¥é«˜æ•ˆæŸ¥è¯¢çš„æ··åˆæ ¼å¼ã€‚
:::

## ğŸ“‹ æ¶æ„æ¦‚è¿°

### Ray Data å¦‚ä½•è½¬æ¢æ—¥å¿—å¤„ç†

Ray Data å®šæœŸä» S3 è·å–æ–°æ—¥å¿—ï¼Œå¹¶è¡Œå¤„ç†å®ƒä»¬ï¼Œå¹¶å°†ç»“æ„åŒ–æ•°æ®å†™å…¥ Apache Iceberg è¡¨ã€‚è§£å†³æ–¹æ¡ˆåŒ…æ‹¬ï¼š

```mermaid
graph TB
    S3[S3 Spark æ—¥å¿—] --> RayData[âš¡ Ray Data å¤„ç†]
    RayData --> Iceberg[S3 ä¸­çš„ Apache Iceberg è¡¨]
    Glue[AWS Glue ç›®å½•] --> Iceberg
    Meta[å…ƒæ•°æ®è·Ÿè¸ª] --> RayData

    subgraph EKS["<b>EKS é›†ç¾¤</b>"]
        RayData
        subgraph RC["<b>Ray é›†ç¾¤</b>"]
            Head[Ray å¤´èŠ‚ç‚¹]
            Workers[Ray å·¥ä½œèŠ‚ç‚¹]
        end
    end

    subgraph SC["<b>â˜ï¸ å­˜å‚¨</b>"]
        S3
        Iceberg
    end

    style S3 fill:#FF9900,stroke:#232F3E,stroke-width:2px,color:#fff
    style Glue fill:#FF9900,stroke:#232F3E,stroke-width:2px,color:#fff
    style RayData fill:#028CF0,stroke:#232F3E,stroke-width:2px,color:#fff
    style Iceberg fill:#3FCBFF,stroke:#232F3E,stroke-width:2px,color:#fff
```

### Ray Data å¤„ç†çš„å…³é”®åŠŸèƒ½

#### ğŸ“Š **æ¨¡å¼æå–å’Œè§£æ**

Ray Data æ™ºèƒ½åœ°ä»éç»“æ„åŒ–æ—¥å¿—ä¸­æå–ç»“æ„åŒ–å­—æ®µï¼š

- ğŸ• **`timestamp`** - ä»æ—¥å¿—æ¶ˆæ¯ä¸­è§£æ
- ğŸ·ï¸ **`log_level`** - æå–çº§åˆ«ï¼ˆINFOã€WARNã€ERRORã€DEBUGï¼‰
- ğŸ”§ **`component`** - Spark ç»„ä»¶ï¼ˆSparkContextã€ResourceUtils ç­‰ï¼‰
- ğŸ“ **`message`** - å®é™…æ—¥å¿—å†…å®¹
- ğŸ  **`pod_name`** & **`namespace`** - æ¥è‡ª Kubernetes å…ƒæ•°æ®
- ğŸ‘· **`spark_role`** - é©±åŠ¨ç¨‹åºæˆ–æ‰§è¡Œå™¨æ ‡è¯†
- ğŸ†” **`application_id`** - å”¯ä¸€çš„ Spark åº”ç”¨ç¨‹åºæ ‡è¯†ç¬¦

#### ğŸ” **æ™ºèƒ½è¿‡æ»¤å’ŒæŸ¥è¯¢**

å¤„ç†åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ SQL è½»æ¾æŸ¥è¯¢æ—¥å¿—ï¼š

```sql
-- æŸ¥æ‰¾ç‰¹å®šåº”ç”¨ç¨‹åºçš„æ‰€æœ‰ ERROR æ—¥å¿—
SELECT timestamp, component, message
FROM spark_logs
WHERE log_level = 'ERROR'
  AND application_id = 'spark-application-12345'
  AND timestamp > '2024-01-15 00:00:00'
ORDER BY timestamp DESC;

-- æŒ‰ç»„ä»¶åˆ†ææ—¥å¿—æ¨¡å¼
SELECT component, log_level, COUNT(*) as count
FROM spark_logs
WHERE namespace = 'spark-team-a'
GROUP BY component, log_level
ORDER BY count DESC;

-- è·Ÿè¸ªåº”ç”¨ç¨‹åºç”Ÿå‘½å‘¨æœŸäº‹ä»¶
SELECT timestamp, message
FROM spark_logs
WHERE component = 'SparkContext'
  AND (message LIKE '%Starting%' OR message LIKE '%Stopping%')
ORDER BY timestamp;
```

#### ğŸ¯ **å…ƒæ•°æ®ç®¡ç†**

- âœ… **å¹‚ç­‰å¤„ç†** - è·Ÿè¸ªå·²å¤„ç†çš„æ–‡ä»¶å¤¹ä»¥é¿å…é‡å¤å¤„ç†
- ğŸ“‹ **å…ƒæ•°æ®è¡¨** - ç»´æŠ¤å¤„ç†å†å²å’ŒçŠ¶æ€
- ğŸ”„ **è‡ªåŠ¨å‘ç°** - è‡ªåŠ¨æŸ¥æ‰¾ S3 ä¸­çš„æ–°æ—¥å¿—æ–‡ä»¶å¤¹
- âš¡ **å¢é‡æ›´æ–°** - ä»…å¤„ç†æ–°æ•°æ®ä»¥æé«˜æ•ˆç‡

## ğŸš€ å…¥é—¨æŒ‡å—

### å…ˆå†³æ¡ä»¶

åœ¨éƒ¨ç½²æ­¤è“å›¾ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å…·æœ‰ï¼š

- âœ… **åŒ…å« Spark åº”ç”¨ç¨‹åºæ—¥å¿—çš„ S3 å­˜å‚¨æ¡¶**ï¼šæŒ‰ç…§ [Spark Operator è“å›¾](https://awslabs.github.io/data-on-eks/docs/blueprints/data-analytics/spark-operator-yunikorn) ç”Ÿæˆ Spark æ—¥å¿—ã€‚
  **æ³¨æ„ï¼š** æ‰§è¡Œ **ä½¿ç”¨ Karpenter æ‰§è¡Œç¤ºä¾‹ Spark ä½œä¸š** æ­¥éª¤ä¸­çš„ **å°†ç¤ºä¾‹æ•°æ®æ”¾å…¥ S3** éƒ¨åˆ†çš„æ­¥éª¤ï¼Œä»¥ä½¿ç”¨ Spark åº”ç”¨ç¨‹åºæ—¥å¿—å¡«å…… S3 å­˜å‚¨æ¡¶ã€‚
- âœ… **é…ç½®äº†é€‚å½“æƒé™çš„ AWS CLI**
- âœ… kubectl
- âœ… **å·²å®‰è£… Terraform**ï¼ˆ>= 1.0ï¼‰

:::tip é¦–å…ˆç”Ÿæˆ Spark æ—¥å¿—
Ray Data ç®¡é“å¤„ç† Spark åº”ç”¨ç¨‹åºæ—¥å¿—ã€‚ç¡®ä¿æ‚¨å·²ä» [Spark Operator è“å›¾](https://awslabs.github.io/data-on-eks/docs/blueprints/data-analytics/spark-operator-yunikorn#put-sample-data-in-s3) è¿è¡Œå‡ºç§Ÿè½¦è¡Œç¨‹ç¤ºä¾‹ï¼Œä»¥ä½¿ç”¨æ—¥å¿—å¡«å……æ‚¨çš„ S3 å­˜å‚¨æ¡¶ã€‚

ğŸ“ **S3 ä¸­çš„ Spark æ—¥å¿—æ–‡ä»¶ç»“æ„ï¼š**
```
s3://${S3_BUCKET}/
â””â”€â”€ spark-application-logs/
    â””â”€â”€ spark-team-a/
        â”œâ”€â”€ spark-application-1234567890-driver/
        â”‚   â””â”€â”€ stdout
        â”œâ”€â”€ spark-application-1234567890-exec-1/
        â”‚   â””â”€â”€ stdout
        â””â”€â”€ spark-application-1234567890-exec-2/
            â””â”€â”€ stdout
```

æ¯ä¸ª `stdout` æ–‡ä»¶åŒ…å«æ¥è‡ª Fluent Bit çš„ Kubernetes å…ƒæ•°æ®ä¸°å¯Œçš„ JSON æ ¼å¼æ—¥å¿—ã€‚
:::

### æ­¥éª¤ 1ï¼šå¯ç”¨ Ray Data å¤„ç†

é€šè¿‡å¯ç”¨ `enable_raydata` å˜é‡éƒ¨ç½²å¸¦æœ‰ Ray Data ç»„ä»¶çš„ EKS é›†ç¾¤ã€‚è¿™å°†å®‰è£…ï¼š
- **KubeRay Operator** - åœ¨ Kubernetes ä¸Šç®¡ç† Ray é›†ç¾¤
- **Ray è‡ªå®šä¹‰èµ„æº** - RayJob å’Œ RayCluster CRD
- **AWS èµ„æº** - IAM è§’è‰²ã€S3 è®¿é—®ç­–ç•¥å’Œ Glue æ•°æ®åº“
- **Ray Data ç®¡é“** - å‘½åç©ºé—´ã€æœåŠ¡è´¦æˆ·å’Œ RBAC

<Tabs>
<TabItem value="terraform" label="ä½¿ç”¨ Terraform">

```bash
cd analytics/terraform/spark-k8s-operator

# éƒ¨ç½²å¯ç”¨ Ray Data æ”¯æŒçš„ EKS é›†ç¾¤
export TF_VAR_enable_raydata=true

terraform init
terraform plan
terraform apply -auto-approve
```

</TabItem>
<TabItem value="install-script" label="ä½¿ç”¨å®‰è£…è„šæœ¬">

```bash
cd analytics/terraform/spark-k8s-operator

# è®¾ç½®ç¯å¢ƒå˜é‡å¹¶è¿è¡Œå®‰è£…è„šæœ¬
export TF_VAR_enable_raydata=true

./install.sh
```

</TabItem>
</Tabs>

:::info éƒ¨ç½²æ—¶é—´
å®Œæ•´éƒ¨ç½²å¤§çº¦éœ€è¦ 20-25 åˆ†é’Ÿæ¥åˆ›å»º EKS é›†ç¾¤ã€å®‰è£…æ“ä½œå™¨å¹¶é…ç½®æ‰€æœ‰ Ray Data ç»„ä»¶ã€‚
:::

æ­¤éƒ¨ç½²åˆ›å»ºï¼š
- ğŸ¯ **KubeRay Operator** ç”¨äº Ray ä½œä¸šç¼–æ’
- ğŸ” **Ray æœåŠ¡è´¦æˆ·** ä¸ IRSAï¼ˆæœåŠ¡è´¦æˆ·çš„ IAM è§’è‰²ï¼‰
- ğŸ“ **IAM è§’è‰²** å…·æœ‰ S3 å’Œ Glue æƒé™
- ğŸ“Š **AWS Glue æ•°æ®åº“** ç”¨äº Iceberg ç›®å½•
- ğŸŒ **Kubernetes å‘½åç©ºé—´**ï¼ˆ`raydata`ï¼‰

### æ­¥éª¤ 2ï¼šéªŒè¯ KubeRay Operator å®‰è£…

ç¡®è®¤ KubeRay Operator æˆåŠŸè¿è¡Œï¼š

```bash
kubectl get po -n kuberay-operator
```

é¢„æœŸè¾“å‡ºï¼š
```
NAME                                READY   STATUS    RESTARTS   AGE
kuberay-operator-74fcdcc6bf-gpl5p   1/1     Running   0          10h
```

### æ­¥éª¤ 3ï¼šé…ç½® Ray ä½œä¸š

å¯¼èˆªåˆ°ç¤ºä¾‹ç›®å½•å¹¶åœ¨éƒ¨ç½²è„šæœ¬ä¸­æ›´æ–° S3 é…ç½®ã€‚

```bash
cd examples/raydata-sparklogs-processing-job
```

åœ¨è¿è¡Œä¹‹å‰ï¼Œåœ¨ `execute-rayjob.sh` shell è„šæœ¬ä¸­æ›¿æ¢ **S3_BUCKET**ã€**CLUSTER_NAME** å’Œ **AWS_REGION** å˜é‡ã€‚

### æ­¥éª¤ 4ï¼šéƒ¨ç½² Ray é›†ç¾¤å¹¶æ‰§è¡Œ Ray ä½œä¸š

```bash
# ä½¿è„šæœ¬å¯æ‰§è¡Œ
chmod +x execute-rayjob.sh

# éƒ¨ç½²å¤„ç†ä½œä¸š
./execute-rayjob.sh deploy
```

## ğŸ“Š ç›‘æ§ RayJob éƒ¨ç½²

### æ£€æŸ¥ä½œä¸šçŠ¶æ€

ä½¿ç”¨è¿™äº›å‘½ä»¤ç›‘æ§æ‚¨çš„ Ray ä½œä¸šï¼š

```bash
# å®æ—¶ç›‘æ§ä½œä¸šè¿›åº¦
./execute-rayjob.sh monitor

# æ£€æŸ¥å½“å‰çŠ¶æ€
./execute-rayjob.sh status

# æŸ¥çœ‹å¤„ç†æ—¥å¿—
./execute-rayjob.sh logs

```

#### æ£€æŸ¥ RayJob æ—¥å¿—

```text
2025-07-27 22:04:46,324 - spark-log-processor - INFO - âœ… Successfully processed 1287 records from spark-fb094270bf654473b372d0f773e86687
2025-07-27 22:04:46,324 - spark-log-processor - INFO - ğŸ¯ Processing Summary:
2025-07-27 22:04:46,324 - spark-log-processor - INFO -   ğŸ“Š Total records processed: 1287
2025-07-27 22:04:46,324 - spark-log-processor - INFO -   âœ… Successful folders: 1
2025-07-27 22:04:46,324 - spark-log-processor - INFO -   âŒ Failed folders: 0
2025-07-27 22:04:46,324 - spark-log-processor - INFO -   âœ… Successfully processed: ['spark-fb094270bf654473b372d0f773e86687']
2025-07-27 22:04:46,324 - spark-log-processor - INFO - âœ… Metadata-driven incremental processing completed
```

:::tip å¹•åå‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ

å½“æ‚¨éƒ¨ç½² RayJob æ—¶ï¼Œä¼šå‘ç”Ÿä»¥ä¸‹è‡ªåŠ¨åŒ–è¿‡ç¨‹ï¼š

1. **ğŸš€ Ray é›†ç¾¤åˆå§‹åŒ–** - KubeRay Operator åˆ›å»ºå¸¦æœ‰å¤´èŠ‚ç‚¹å’Œå·¥ä½œèŠ‚ç‚¹çš„ Ray é›†ç¾¤
2. **ğŸ” S3 å‘ç°** - Ray Data æ‰«æé…ç½®çš„ S3 å­˜å‚¨æ¡¶è·¯å¾„ä»¥æŸ¥æ‰¾åŒ¹é… `spark-*` æ¨¡å¼çš„æ–‡ä»¶å¤¹
3. **ğŸ“Š å…ƒæ•°æ®æ£€æŸ¥** - æŸ¥è¯¢ Iceberg å…ƒæ•°æ®è¡¨ä»¥è¯†åˆ«æœªå¤„ç†çš„æ–‡ä»¶å¤¹
4. **ğŸ“¥ å¹¶è¡Œå¤„ç†** - Ray å·¥ä½œå™¨å¹¶è¡Œä» S3 è¯»å– JSON æ—¥å¿—æ–‡ä»¶
5. **ğŸ”„ æ•°æ®è½¬æ¢** - ä» JSON æ—¥å¿—ä¸­æå–ç»“æ„åŒ–å­—æ®µï¼ˆæ—¶é—´æˆ³ã€æ—¥å¿—çº§åˆ«ã€ç»„ä»¶ç­‰ï¼‰
6. **âœï¸ Iceberg å†™å…¥** - ä½¿ç”¨ ACID ä¿è¯å°†è½¬æ¢åçš„æ•°æ®å†™å…¥ Apache Iceberg è¡¨
7. **ğŸ“ å…ƒæ•°æ®æ›´æ–°** - åœ¨å…ƒæ•°æ®è¡¨ä¸­è®°å½•å¤„ç†çŠ¶æ€ä»¥ç¡®ä¿å¹‚ç­‰æ€§
8. **ğŸ¯ å®Œæˆ** - æˆåŠŸå¤„ç†åå…³é—­ Ray é›†ç¾¤

æ•´ä¸ªè¿‡ç¨‹æ˜¯**å¹‚ç­‰çš„** - æ‚¨å¯ä»¥å®‰å…¨åœ°é‡æ–°è¿è¡Œå®ƒè€Œä¸ä¼šé‡å¤æ•°æ®ï¼Œå› ä¸ºå®ƒåªå¤„ç†æ–°çš„æ—¥å¿—æ–‡ä»¶å¤¹ã€‚
:::

### è®¿é—® Ray ä»ªè¡¨æ¿

<CollapsibleContent header={<h3>ğŸ¨ Ray ä»ªè¡¨æ¿è®¿é—®</h3>}>

```bash
# è·å–ä»ªè¡¨æ¿è®¿é—®ä¿¡æ¯
./execute-rayjob.sh dashboard

# ç«¯å£è½¬å‘åˆ°æœ¬åœ°æœºå™¨
kubectl port-forward svc/spark-log-processor-head-svc 8265:8265 -n raydata
```

æ‰“å¼€ http://localhost:8265 æŸ¥çœ‹ï¼š
- ğŸ“ˆ ä½œä¸šæ‰§è¡Œè¿›åº¦
- ğŸ’» èµ„æºåˆ©ç”¨ç‡
- âš¡ ä»»åŠ¡çº§æŒ‡æ ‡
- ğŸŒ é›†ç¾¤æ‹“æ‰‘

</CollapsibleContent>

## âœ… æ•°æ®éªŒè¯

### S3 å­˜å‚¨æ¡¶ç»“æ„

Ray Data å¯¹è¾“å…¥ Spark æ—¥å¿—å’Œè¾“å‡º Iceberg æ•°æ®ä½¿ç”¨**ç›¸åŒçš„ S3 å­˜å‚¨æ¡¶**ï¼Œåœ¨å•ç‹¬çš„è·¯å¾„ä¸­ç»„ç»‡ï¼š

```
s3://your-spark-logs-bucket/
â”œâ”€â”€ spark-application-logs/           # ğŸ“¥ è¾“å…¥ï¼šæ¥è‡ª Fluent Bit çš„åŸå§‹ Spark æ—¥å¿—
â”‚   â””â”€â”€ spark-team-a/
â”‚       â”œâ”€â”€ spark-application-1234567890-driver/
â”‚       â”‚   â””â”€â”€ stdout                # å¸¦æœ‰ Kubernetes å…ƒæ•°æ®çš„ JSON æ—¥å¿—
â”‚       â”œâ”€â”€ spark-application-1234567890-exec-1/
â”‚       â”‚   â””â”€â”€ stdout
â”‚       â””â”€â”€ spark-application-1234567890-exec-2/
â”‚           â””â”€â”€ stdout
â”‚
â””â”€â”€ iceberg-warehouse/                # ğŸ“¤ è¾“å‡ºï¼šå¤„ç†åçš„ Iceberg æ•°æ®
    â””â”€â”€ raydata_spark_logs.db/
        â””â”€â”€ spark_logs/
            â”œâ”€â”€ metadata/             # Iceberg å…ƒæ•°æ®æ–‡ä»¶
            â”‚   â”œâ”€â”€ 00000-xxx.metadata.json
            â”‚   â”œâ”€â”€ snap-xxx.avro     # æ—¶é—´æ—…è¡Œå¿«ç…§
            â”‚   â””â”€â”€ version-hint.text
            â””â”€â”€ data/                 # Parquet æ ¼å¼çš„å®é™…æ•°æ®
                â”œâ”€â”€ 00000-0-xxx.parquet
                â”œâ”€â”€ 00001-0-xxx.parquet
                â””â”€â”€ ...
```

:::tip ç›¸åŒå­˜å‚¨æ¡¶ï¼Œä¸åŒè·¯å¾„
- **è¾“å…¥è·¯å¾„**ï¼š`s3://bucket/spark-application-logs/` - åŒ…å«åŸå§‹ JSON æ—¥å¿—
- **è¾“å‡ºè·¯å¾„**ï¼š`s3://bucket/iceberg-warehouse/` - åŒ…å«ç»“æ„åŒ– Parquet æ–‡ä»¶
- **å­˜å‚¨æ ¼å¼**ï¼šIceberg ä½¿ç”¨é«˜æ•ˆçš„åˆ—å¼ Parquet æ ¼å¼å’Œç”¨äº ACID äº‹åŠ¡çš„å…ƒæ•°æ®
:::

åœ¨ AWS S3 æ§åˆ¶å°ä¸­ï¼Œå®ƒåº”è¯¥å¦‚ä¸‹æ‰€ç¤ºï¼š

![s3](../../../../../../docs/blueprints/data-analytics/img/raydata-s3-struc.png)

### RayData å¤„ç†åçš„æ—¥å¿—ç‰‡æ®µ

ä»¥ä¸‹æ˜¯ Ray Data å¤„ç†å‰åæ•°æ®è½¬æ¢çš„æ ·å­ï¼š

<Tabs>
<TabItem value="before" label="å¤„ç†å‰ï¼ˆåŸå§‹ S3 JSONï¼‰">

**S3 ä¸­çš„åŸå§‹ Fluent Bit æ—¥å¿—** - æ¯ä¸ªæ—¥å¿—è¡Œéƒ½åŒ…è£…åœ¨å¸¦æœ‰å†—ä½™å…ƒæ•°æ®çš„ JSON ä¸­ï¼š

```json
{
  "log": "2024-01-15 14:23:45 INFO SparkContext: Running Spark version 3.5.0\n",
  "stream": "stdout",
  "time": "2024-01-15T14:23:45.123456Z",
  "kubernetes": {
    "pod_name": "spark-driver-abc123",
    "namespace_name": "spark-team-a",
    "pod_id": "12345678-1234-1234-1234-123456789012",
    "labels": {
      "spark-role": "driver",
      "spark-app-id": "spark-application-12345"
    },
    "container_name": "spark-driver",
    "container_image": "spark:3.5.0"
  }
}
{
  "log": "2024-01-15 14:23:46 ERROR TaskSchedulerImpl: Lost executor 1: Container killed\n",
  "stream": "stderr",
  "time": "2024-01-15T14:23:46.234567Z",
  "kubernetes": {
    "pod_name": "spark-executor-def456",
    "namespace_name": "spark-team-a",
    "labels": {
      "spark-role": "executor",
      "spark-app-id": "spark-application-12345"
    }
  }
}
```

</TabItem>
<TabItem value="after" label="å¤„ç†åï¼ˆç»“æ„åŒ– Icebergï¼‰">

**Apache Iceberg ä¸­çš„å¤„ç†æ•°æ®** - ä¸ºæŸ¥è¯¢ä¼˜åŒ–çš„æ¸…æ´ã€ç»“æ„åŒ–æ¨¡å¼ï¼š

```sql
-- æŸ¥è¯¢å¤„ç†åçš„æ•°æ®
SELECT * FROM raydata_spark_logs.spark_logs LIMIT 2;
```

| timestamp | log_level | component | message | pod_name | namespace | spark_role | application_id |
|-----------|-----------|-----------|---------|----------|-----------|------------|----------------|
| 2024-01-15 14:23:45 | INFO | SparkContext | Running Spark version 3.5.0 | spark-driver-abc123 | spark-team-a | driver | spark-application-12345 |
| 2024-01-15 14:23:46 | ERROR | TaskSchedulerImpl | Lost executor 1: Container killed | spark-executor-def456 | spark-team-a | executor | spark-application-12345 |

**âœ… å…³é”®æ”¹è¿›ï¼š**
- **ç»“æ„åŒ–å­—æ®µ** - æ˜“äºæŸ¥è¯¢ç‰¹å®šæ—¥å¿—çº§åˆ«ã€ç»„ä»¶å’Œæ—¶é—´èŒƒå›´
- **å»é‡å…ƒæ•°æ®** - æ¯ä¸ªæ—¥å¿—è¡Œæ²¡æœ‰å†—ä½™çš„ Kubernetes å…ƒæ•°æ®
- **åˆ—å¼å­˜å‚¨** - ä½¿ç”¨ Parquet æ ¼å¼çš„é«˜æ•ˆå­˜å‚¨å’ŒæŸ¥è¯¢æ€§èƒ½
- **æ¨¡å¼æ¼”è¿›** - æ·»åŠ æ–°å­—æ®µè€Œä¸ç ´åç°æœ‰æŸ¥è¯¢
- **ACID äº‹åŠ¡** - å³ä½¿åœ¨å¹¶å‘å¤„ç†æœŸé—´ä¹Ÿèƒ½ä¿æŒä¸€è‡´çš„è¯»å–

</TabItem>
</Tabs>

### é€‰é¡¹ 1ï¼šæŸ¥è¯¢ Iceberg è¡¨

ä½¿ç”¨è“å›¾ä¸­æä¾›çš„å†…ç½®æ•°æ®éªŒè¯è„šæœ¬ï¼Œè¯¥è„šæœ¬è‡ªåŠ¨è®¾ç½® Python è™šæ‹Ÿç¯å¢ƒå’Œæ‰€æœ‰å¿…éœ€çš„ä¾èµ–é¡¹ï¼š

```bash
# ä½¿è„šæœ¬å¯æ‰§è¡Œ
chmod +x verify-iceberg-data.sh
```
åœ¨è¿è¡Œä¹‹å‰ï¼Œåœ¨ `verify-iceberg-data.sh` shell è„šæœ¬ä¸­æ›¿æ¢ **S3_BUCKET** å’Œ **AWS_REGION** å˜é‡ã€‚

```bash
./verify-iceberg-data.sh
```

è„šæœ¬è‡ªåŠ¨...
- âœ… åˆ›å»ºéš”ç¦»çš„ Python è™šæ‹Ÿç¯å¢ƒ
- âœ… å®‰è£… PyIceberg å’Œæ‰€æœ‰ä¾èµ–é¡¹ï¼ˆ`pyiceberg[glue,s3fs]==0.7.0`ï¼‰
- âœ… è¿æ¥åˆ° AWS Glue ç›®å½•å’Œ Iceberg è¡¨
- âœ… æ‰§è¡Œå…¨é¢çš„æ•°æ®éªŒè¯
- âœ… å®Œæˆåæ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œç¯å¢ƒ

<CollapsibleContent header={<h4>ğŸ“‹ ç¤ºä¾‹è„šæœ¬è¾“å‡º</h4>}>

```text
ğŸ” Connecting to Iceberg catalog...
âœ… Connected to Iceberg catalog in region: us-west-2
ğŸ“Š Loading table: raydata_spark_logs.spark_logs
âœ… Table loaded successfully

ğŸ“‹ Table Schema:
  - timestamp: timestamp (optional)
  - log_level: string (optional)
  - message: string (optional)
  - pod_name: string (optional)
  - namespace_name: string (optional)
  - app: string (optional)
  - spark_app_selector: string (optional)
  - queue: string (optional)
  - spark_app_name: string (optional)
  - spark_role: string (optional)
  - spark_version: string (optional)
  - submission_id: string (optional)
  - container_name: string (optional)
  - container_image: string (optional)

ğŸ” Scanning table data...
âœ… SUCCESS! Found 1287 records in Iceberg table

ğŸ“‹ Data Summary:
   ğŸ“Š Total Records: 1287
   ğŸ“… Date Range: 2025-07-08 19:52:43.079161 to 2025-07-08 20:00:29.393901
   ğŸ“± Unique Pods: 5

ğŸ“ˆ Log Level Distribution:
   INFO: 1269
   WARN: 14
   ERROR: 4

ğŸ“ Sample Records:

  Record 1:
    timestamp: 2025-07-08 19:52:43.079161
    log_level: WARN
    message: Unable to load native-hadoop library for your platform... using builtin-java classes where applicabl...

  Record 2:
    timestamp: 2025-07-08 19:52:43.460063
    log_level: WARN
    message: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.proper...

  Record 3:
    timestamp: 2025-07-08 19:52:46.170113
    log_level: INFO
    message: Running Spark version 3.5.3

ğŸ‰ VERIFICATION SUCCESSFUL!
âœ… Ray Data successfully processed and stored Spark logs in Iceberg format
âœ… Data is accessible and queryable via PyIceberg
âœ… You can now query this data using Amazon Athena or other SQL tools
[SUCCESS] Verification completed successfully!
==== Cleaning Up ====
[INFO] Removed verification script
[INFO] Removed virtual environment
[SUCCESS] Cleanup completed
```

</CollapsibleContent>

### é€‰é¡¹ 2ï¼šä½¿ç”¨ AWS CLI

åœ¨ä¸æŸ¥è¯¢æ•°æ®çš„æƒ…å†µä¸‹æ£€æŸ¥è¡¨å…ƒæ•°æ®ï¼š

```bash
# åœ¨ Glue ç›®å½•ä¸­æŸ¥çœ‹ Iceberg è¡¨
aws glue get-table \
  --database-name raydata_spark_logs \
  --name spark_logs \
  --query 'Table.StorageDescriptor.Location'
```

## ğŸ§¹ æ¸…ç†

è¦æ¸…ç†èµ„æºï¼š

```bash
# ä»…åˆ é™¤ Ray ä½œä¸šï¼ˆä¿ç•™åŸºç¡€è®¾æ–½ï¼‰
./execute-rayjob.sh cleanup

# åˆ é™¤æ‰€æœ‰åŸºç¡€è®¾æ–½
cd analytics/terraform/spark-k8s-operator
terraform destroy -var="enable_raydata_processing=true"
```

## ğŸŒŸ æ‰©å±•æ‚¨çš„æ•°æ®ç®¡é“

- **æ‰©å±•å¤„ç†**ï¼šåœ¨ `rayjob.yaml` ä¸­è°ƒæ•´ Ray å·¥ä½œå™¨æ•°é‡ä»¥å¤„ç†æ›´å¤§çš„å·¥ä½œè´Ÿè½½
- **æ·»åŠ åˆ†æ**ï¼šä½¿ç”¨ Amazon QuickSight æˆ– Grafana åˆ›å»ºä»ªè¡¨æ¿
- **è‡ªåŠ¨åŒ–**ï¼šä½¿ç”¨ Kubernetes CronJobs å®‰æ’å®šæœŸå¤„ç†
- **æ‰©å±•**ï¼šå¤„ç†å…¶ä»–æ•°æ®ç±»å‹ï¼Œå¦‚æŒ‡æ ‡ã€äº‹ä»¶æˆ–åº”ç”¨ç¨‹åºæ•°æ®

:::info äº†è§£æ›´å¤š
- ğŸ“š [Ray Data æ–‡æ¡£](https://docs.ray.io/en/latest/data/data.html)
- ğŸ§Š [Apache Iceberg æ–‡æ¡£](https://iceberg.apache.org/)
- ğŸ¯ [KubeRay æ–‡æ¡£](https://ray-project.github.io/kuberay/)
- â˜ï¸ [AWS Glue ç›®å½•](https://docs.aws.amazon.com/glue/latest/dg/catalog-and-crawler.html)
:::

æ­¤è“å›¾æ¼”ç¤ºäº† Ray Data å’Œ Apache Iceberg å¦‚ä½•ååŒå·¥ä½œï¼Œåœ¨ Amazon EKS ä¸Šæ„å»ºå¯æ‰©å±•ã€å¯é çš„æ•°æ®å¤„ç†ç®¡é“ã€‚è¿™ç§ç»„åˆæä¾›äº†å…·æœ‰åˆ†å¸ƒå¼å¤„ç†èƒ½åŠ›ã€ACID äº‹åŠ¡å’Œæ™ºèƒ½å…ƒæ•°æ®ç®¡ç†çš„ç°ä»£æ•°æ®æ¹–æ¶æ„ã€‚

<style>{`
.feature-grid {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
  gap: 1.5rem;
  margin: 2rem 0;
}

.feature-card {
  padding: 1.5rem;
  border: 1px solid var(--ifm-color-emphasis-300);
  border-radius: 8px;
  background: var(--ifm-background-surface-color);
  transition: transform 0.2s, box-shadow 0.2s;
}

.feature-card:hover {
  transform: translateY(-2px);
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
}

.feature-card h3 {
  margin-top: 0;
  margin-bottom: 0.5rem;
  font-size: 1.2rem;
}

.feature-card p {
  margin: 0;
  color: var(--ifm-color-content-secondary);
}
`}</style>
