---
title: Amazon EKSä¸Šçš„NVIDIA NIM LLM
sidebar_position: 4
---
import CollapsibleContent from '../../../../../../../src/components/CollapsibleContent';

:::caution

**EKSä¸Šçš„AI**å†…å®¹**æ­£åœ¨è¿ç§»**åˆ°ä¸€ä¸ªæ–°çš„ä»“åº“ã€‚
ğŸ”— ğŸ‘‰ [é˜…è¯»å®Œæ•´çš„è¿ç§»å…¬å‘Š Â»](https://awslabs.github.io/data-on-eks/docs/migration/migration-announcement)

:::

:::warning
åœ¨EKSä¸Šéƒ¨ç½²MLæ¨¡å‹éœ€è¦è®¿é—®GPUæˆ–Neuronå®ä¾‹ã€‚å¦‚æœæ‚¨çš„éƒ¨ç½²ä¸èµ·ä½œç”¨ï¼Œé€šå¸¸æ˜¯å› ä¸ºç¼ºå°‘å¯¹è¿™äº›èµ„æºçš„è®¿é—®ã€‚æ­¤å¤–ï¼Œä¸€äº›éƒ¨ç½²æ¨¡å¼ä¾èµ–äºKarpenterè‡ªåŠ¨æ‰©å±•å’Œé™æ€èŠ‚ç‚¹ç»„ï¼›å¦‚æœèŠ‚ç‚¹æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥Karpenteræˆ–èŠ‚ç‚¹ç»„çš„æ—¥å¿—ä»¥è§£å†³é—®é¢˜ã€‚
:::

:::warning

æ³¨æ„ï¼šåœ¨å®æ–½NVIDIA NIMä¹‹å‰ï¼Œè¯·æ³¨æ„å®ƒæ˜¯[NVIDIA AI Enterprise](https://www.nvidia.com/en-us/data-center/products/ai-enterprise/)çš„ä¸€éƒ¨åˆ†ï¼Œè¿™å¯èƒ½ä¼šä¸ºç”Ÿäº§ä½¿ç”¨å¼•å…¥æ½œåœ¨çš„æˆæœ¬å’Œè®¸å¯ã€‚

å¯¹äºè¯„ä¼°ï¼ŒNVIDIAè¿˜æä¾›90å¤©çš„å…è´¹è¯„ä¼°è®¸å¯ï¼Œè®©æ‚¨è¯•ç”¨NVIDIA AI Enterpriseï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å…¬å¸ç”µå­é‚®ä»¶[æ³¨å†Œ](https://enterpriseproductregistration.nvidia.com/?LicType=EVAL&ProductFamily=NVAIEnterprise)ã€‚
:::

:::info

æˆ‘ä»¬æ­£åœ¨ç§¯æå¢å¼ºæ­¤è“å›¾ï¼Œä»¥çº³å…¥å¯è§‚æµ‹æ€§ã€æ—¥å¿—è®°å½•å’Œå¯æ‰©å±•æ€§æ–¹é¢çš„æ”¹è¿›ã€‚
:::

# Amazon EKSä¸Šçš„NVIDIA NIM LLMéƒ¨ç½²

## ä»€ä¹ˆæ˜¯NVIDIA NIMï¼Ÿ

NVIDIA NIMä½¿ITå’ŒDevOpså›¢é˜Ÿèƒ½å¤Ÿåœ¨è‡ªå·±ç®¡ç†çš„ç¯å¢ƒä¸­è½»æ¾è‡ªæ‰˜ç®¡å¤§å‹è¯­è¨€æ¨¡å‹(LLM)ï¼ŒåŒæ—¶ä»ç„¶ä¸ºå¼€å‘äººå‘˜æä¾›è¡Œä¸šæ ‡å‡†APIï¼Œä½¿ä»–ä»¬èƒ½å¤Ÿæ„å»ºå¼ºå¤§çš„å‰¯é©¾é©¶ã€èŠå¤©æœºå™¨äººå’ŒAIåŠ©æ‰‹ï¼Œä»è€Œè½¬å˜ä»–ä»¬çš„ä¸šåŠ¡ã€‚åˆ©ç”¨NVIDIAçš„å°–ç«¯GPUåŠ é€Ÿå’Œå¯æ‰©å±•éƒ¨ç½²ï¼ŒNIMæä¾›äº†å…·æœ‰æ— ä¸ä¼¦æ¯”æ€§èƒ½çš„æ¨ç†æœ€å¿«è·¯å¾„ã€‚

## ä¸ºä»€ä¹ˆé€‰æ‹©NIMï¼Ÿ

NIMæŠ½è±¡äº†æ¨¡å‹æ¨ç†å†…éƒ¨ç»“æ„ï¼Œå¦‚æ‰§è¡Œå¼•æ“å’Œè¿è¡Œæ—¶æ“ä½œã€‚æ— è®ºæ˜¯ä½¿ç”¨TRT-LLMã€vLLMè¿˜æ˜¯å…¶ä»–ï¼Œå®ƒä»¬ä¹Ÿæ˜¯å¯ç”¨çš„æœ€é«˜æ€§èƒ½é€‰é¡¹ã€‚

NIMä»¥æ¯ä¸ªæ¨¡å‹/æ¨¡å‹ç³»åˆ—ä¸ºåŸºç¡€æ‰“åŒ…ä¸ºå®¹å™¨é•œåƒã€‚æ¯ä¸ªNIMå®¹å™¨éƒ½å¸¦æœ‰ä¸€ä¸ªæ¨¡å‹ï¼Œå¦‚`meta/llama3-8b-instruct`ã€‚è¿™äº›å®¹å™¨åŒ…æ‹¬ä¸€ä¸ªå¯ä»¥åœ¨ä»»ä½•å…·æœ‰è¶³å¤ŸGPUå†…å­˜çš„NVIDIA GPUä¸Šè¿è¡Œçš„è¿è¡Œæ—¶ï¼Œä½†æŸäº›æ¨¡å‹/GPUç»„åˆç»è¿‡äº†ä¼˜åŒ–ã€‚NIMè‡ªåŠ¨ä»NVIDIA NGCç›®å½•ä¸‹è½½æ¨¡å‹ï¼Œå¦‚æœå¯ç”¨ï¼Œåˆ™åˆ©ç”¨æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿç¼“å­˜ã€‚

## Amazon EKSä¸Šæ­¤éƒ¨ç½²æ¨¡å¼çš„æ¦‚è¿°

æ­¤æ¨¡å¼ç»“åˆäº†NVIDIA NIMã€Amazon Elastic Kubernetes Service (EKS)å’Œå„ç§AWSæœåŠ¡çš„åŠŸèƒ½ï¼Œæä¾›é«˜æ€§èƒ½å’Œæˆæœ¬ä¼˜åŒ–çš„æ¨¡å‹æœåŠ¡åŸºç¡€è®¾æ–½ã€‚

1. NVIDIA NIMå®¹å™¨é•œåƒï¼šNVIDIA NIMæä¾›äº†ä¸€ç§ç®€åŒ–çš„æ–¹æ³•ï¼Œå¯ä»¥åœ¨å®¹å™¨åŒ–ç¯å¢ƒä¸­æ‰˜ç®¡Llama3ç­‰LLMæ¨¡å‹ã€‚è¿™ä½¿å®¢æˆ·èƒ½å¤Ÿåˆ©ç”¨ä»–ä»¬çš„ç§æœ‰æ¨¡å‹ï¼ŒåŒæ—¶ç¡®ä¿ä¸ç°æœ‰åŸºç¡€è®¾æ–½çš„æ— ç¼é›†æˆã€‚æˆ‘ä»¬å°†æä¾›NIMéƒ¨ç½²çš„è¯¦ç»†è®¾ç½®æ­¥éª¤ã€‚

2. Karpenterç”¨äºå®ä¾‹çº§æ‰©å±•ï¼šKarpenteræ˜¯ä¸€ä¸ªå¼€æºèŠ‚ç‚¹é…ç½®é¡¹ç›®ï¼Œèƒ½å¤Ÿåœ¨å®ä¾‹çº§åˆ«å¿«é€Ÿé«˜æ•ˆåœ°æ‰©å±•Amazon EKSé›†ç¾¤ã€‚è¿™ç¡®ä¿äº†æ¨¡å‹æœåŠ¡åŸºç¡€è®¾æ–½èƒ½å¤Ÿé€‚åº”åŠ¨æ€å·¥ä½œè´Ÿè½½éœ€æ±‚ï¼Œä¼˜åŒ–èµ„æºåˆ©ç”¨ç‡å’Œæˆæœ¬æ•ˆç›Šã€‚

3. ç«ä»·å®ä¾‹ï¼šè€ƒè™‘åˆ°LLMæ˜¯æ— çŠ¶æ€çš„ï¼Œå®¢æˆ·å¯ä»¥åˆ©ç”¨ç«ä»·å®ä¾‹æ˜¾è‘—é™ä½æˆæœ¬ã€‚

4. Amazon Elastic File System (EFS)ï¼šAmazon EFSä¸ºAmazon EKSæä¾›å¯æ‰©å±•ã€å¼¹æ€§çš„æ–‡ä»¶å­˜å‚¨ã€‚å®ƒå…è®¸å¤šä¸ªpodåŒæ—¶è®¿é—®åŒä¸€æ–‡ä»¶ç³»ç»Ÿï¼Œéå¸¸é€‚åˆåœ¨é›†ç¾¤ä¸­å­˜å‚¨å’Œå…±äº«æ¨¡å‹å·¥ä»¶ã€æ•°æ®é›†å’Œå…¶ä»–æŒä¹…æ•°æ®ã€‚EFSä¼šéšç€æ‚¨æ·»åŠ å’Œåˆ é™¤æ–‡ä»¶è‡ªåŠ¨å¢é•¿å’Œç¼©å°ï¼Œæ— éœ€å®¹é‡è§„åˆ’å’Œç®¡ç†ã€‚

5. å¸¦æœ‰EKSè“å›¾çš„Terraformï¼šä¸ºäº†ç®€åŒ–æ­¤è§£å†³æ–¹æ¡ˆçš„éƒ¨ç½²å’Œç®¡ç†ï¼Œæˆ‘ä»¬åˆ©ç”¨Terraformå’ŒEKSè“å›¾ã€‚è¿™ç§åŸºç¡€è®¾æ–½å³ä»£ç çš„æ–¹æ³•å®ç°äº†æ•´ä¸ªå †æ ˆçš„è‡ªåŠ¨é…ç½®ï¼Œç¡®ä¿ä¸€è‡´æ€§ã€å¯é‡å¤æ€§å’Œé«˜æ•ˆçš„èµ„æºç®¡ç†ã€‚

é€šè¿‡ç»“åˆè¿™äº›ç»„ä»¶ï¼Œæˆ‘ä»¬æå‡ºçš„è§£å†³æ–¹æ¡ˆæä¾›äº†ä¸€ä¸ªå¼ºå¤§ä¸”ç»æµé«˜æ•ˆçš„æ¨¡å‹æœåŠ¡åŸºç¡€è®¾æ–½ï¼Œä¸“ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹é‡èº«å®šåˆ¶ã€‚å€ŸåŠ©NVIDIA NIMçš„æ— ç¼é›†æˆã€Amazon EKSä¸Karpenterçš„å¯æ‰©å±•æ€§ï¼Œå®¢æˆ·å¯ä»¥åœ¨æœ€å°åŒ–åŸºç¡€è®¾æ–½æˆæœ¬çš„åŒæ—¶å®ç°é«˜æ€§èƒ½ã€‚

![EKSä¸Šçš„NIMæ¶æ„](../../../../../../../docs/gen-ai/inference/img/nim-on-eks-arch.png)
## éƒ¨ç½²è§£å†³æ–¹æ¡ˆ

### å…ˆå†³æ¡ä»¶

åœ¨å¼€å§‹ä½¿ç”¨NVIDIA NIMä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å…·å¤‡ä»¥ä¸‹æ¡ä»¶ï¼š

<details>
<summary>ç‚¹å‡»å±•å¼€NVIDIA NIMè´¦æˆ·è®¾ç½®è¯¦æƒ…</summary>

**NVIDIA AI Enterpriseè´¦æˆ·**

- æ³¨å†ŒNVIDIA AI Enterpriseè´¦æˆ·ã€‚å¦‚æœæ‚¨æ²¡æœ‰ï¼Œå¯ä»¥ä½¿ç”¨æ­¤[é“¾æ¥](https://enterpriseproductregistration.nvidia.com/?LicType=EVAL&ProductFamily=NVAIEnterprise)æ³¨å†Œè¯•ç”¨è´¦æˆ·ã€‚

**NGC APIå¯†é’¥**

1. ç™»å½•æ‚¨çš„NVIDIA AI Enterpriseè´¦æˆ·
2. å¯¼èˆªåˆ°NGC (NVIDIA GPU Cloud) [é—¨æˆ·](https://org.ngc.nvidia.com/)
3. ç”Ÿæˆä¸ªäººAPIå¯†é’¥ï¼š
    - è¿›å…¥æ‚¨çš„è´¦æˆ·è®¾ç½®æˆ–ç›´æ¥å¯¼èˆªè‡³ï¼šhttps://org.ngc.nvidia.com/setup/personal-keys
    - ç‚¹å‡»"Generate Personal Key"
    - ç¡®ä¿ä»"Services Included"ä¸‹æ‹‰èœå•ä¸­è‡³å°‘é€‰æ‹©äº†"NGC Catalog"
    - å¤åˆ¶å¹¶å®‰å…¨å­˜å‚¨æ‚¨çš„APIå¯†é’¥ï¼Œå¯†é’¥åº”è¯¥æœ‰ä¸€ä¸ªå‰ç¼€ä¸º`nvapi-`

    ![NGC APIå¯†é’¥](../../../../../../../docs/gen-ai/inference/img/nim-ngc-api-key.png)

**éªŒè¯NGC APIå¯†é’¥å¹¶æµ‹è¯•é•œåƒæ‹‰å–**

è¦ç¡®ä¿æ‚¨çš„APIå¯†é’¥æœ‰æ•ˆå¹¶æ­£å¸¸å·¥ä½œï¼š
1. å°†æ‚¨çš„NGC APIå¯†é’¥è®¾ç½®ä¸ºç¯å¢ƒå˜é‡ï¼š
```bash
export NGC_API_KEY=<your_api_key_here>
```

2. ä½¿ç”¨NVIDIAå®¹å™¨æ³¨å†Œè¡¨éªŒè¯Dockerï¼š

```bash
echo "$NGC_API_KEY" | docker login nvcr.io --username '$oauthtoken' --password-stdin
```

3. æµ‹è¯•ä»NGCæ‹‰å–é•œåƒï¼š
```bash
docker pull nvcr.io/nim/meta/llama3-8b-instruct:latest
```
æ‚¨ä¸å¿…ç­‰å¾…å®ƒå®Œæˆï¼Œåªéœ€ç¡®ä¿APIå¯†é’¥æœ‰æ•ˆå¯ä»¥æ‹‰å–é•œåƒã€‚
</details>

è¿è¡Œæœ¬æ•™ç¨‹éœ€è¦ä»¥ä¸‹æ¡ä»¶
- å…·æœ‰ç®¡ç†å‘˜åŒç­‰æƒé™çš„æ´»è·ƒAWSè´¦æˆ·
- [aws cli](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html)
- [kubectl](https://Kubernetes.io/docs/tasks/tools/)
- [Terraform](https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli)

### éƒ¨ç½²

å…‹éš†ä»“åº“

```bash
git clone https://github.com/awslabs/data-on-eks.git
```

**1. é…ç½®NGC APIå¯†é’¥**

ä»[NVIDIA](https://docs.nvidia.com/ai-enterprise/deployment-guide-spark-rapids-accelerator/0.1.0/appendix-ngc.html)æ£€ç´¢æ‚¨çš„NGC APIå¯†é’¥å¹¶å°†å…¶è®¾ç½®ä¸ºç¯å¢ƒå˜é‡ï¼š

```bash
export TF_VAR_ngc_api_key=<replace-with-your-NGC-API-KEY>
```

**2. å®‰è£…**

é‡è¦æç¤ºï¼šåœ¨éƒ¨ç½²è“å›¾ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ›´æ–°variables.tfæ–‡ä»¶ä¸­çš„åŒºåŸŸã€‚æ­¤å¤–ï¼Œç¡®è®¤æ‚¨çš„æœ¬åœ°åŒºåŸŸè®¾ç½®ä¸æŒ‡å®šåŒºåŸŸåŒ¹é…ï¼Œä»¥é˜²æ­¢ä»»ä½•å·®å¼‚ã€‚ä¾‹å¦‚ï¼Œå°†æ‚¨çš„`export AWS_DEFAULT_REGION="<REGION>"`è®¾ç½®ä¸ºæ‰€éœ€åŒºåŸŸï¼š

è¿è¡Œå®‰è£…è„šæœ¬ï¼š

:::info


æ­¤æ¨¡å¼éƒ¨ç½²äº†ä¸€ä¸ªåä¸º`nvcr.io/nim/meta/llama3-8b-instruct`çš„æ¨¡å‹ã€‚æ‚¨å¯ä»¥ä¿®æ”¹`variables.tf`æ–‡ä»¶ä¸­çš„`nim_models`å˜é‡æ¥æ·»åŠ æ›´å¤šæ¨¡å‹ã€‚ä½¿ç”¨æ­¤æ¨¡å¼å¯ä»¥åŒæ—¶éƒ¨ç½²å¤šä¸ªæ¨¡å‹ã€‚
:::

:::caution

åœ¨é€šè¿‡è¿™äº›å˜é‡å¯ç”¨é¢å¤–æ¨¡å‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä¸ºæ¯ä¸ªæ¨¡å‹æŒ‡å®šäº†è¶³å¤Ÿçš„GPUã€‚æ­¤å¤–ï¼ŒéªŒè¯æ‚¨çš„AWSè´¦æˆ·æ˜¯å¦æœ‰æƒè®¿é—®è¶³å¤Ÿçš„GPUã€‚
æ­¤æ¨¡å¼ä½¿ç”¨Karpenteræ¥æ‰©å±•GPUèŠ‚ç‚¹ï¼Œé»˜è®¤é™åˆ¶ä¸ºG5å®ä¾‹ã€‚å¦‚æœéœ€è¦ï¼Œæ‚¨å¯ä»¥ä¿®æ”¹KarpenterèŠ‚ç‚¹æ± ä»¥åŒ…æ‹¬å…¶ä»–å®ä¾‹ï¼Œå¦‚p4å’Œp5ã€‚

:::


```bash
cd data-on-eks/ai-ml/nvidia-triton-server
export TF_VAR_enable_nvidia_nim=true
export TF_VAR_enable_nvidia_triton_server=false
./install.sh
```

æ­¤è¿‡ç¨‹å°†èŠ±è´¹å¤§çº¦20åˆ†é’Ÿå®Œæˆã€‚

**3. éªŒè¯å®‰è£…**

å®‰è£…å®Œæˆåï¼Œæ‚¨å¯ä»¥ä»è¾“å‡ºä¸­æ‰¾åˆ°configure_kubectlå‘½ä»¤ã€‚è¿è¡Œä»¥ä¸‹å‘½ä»¤é…ç½®EKSé›†ç¾¤è®¿é—®

```bash
# åˆ›å»ºk8sé…ç½®æ–‡ä»¶ä»¥ä¸EKSè¿›è¡Œèº«ä»½éªŒè¯
aws eks --region us-west-2 update-kubeconfig --name nvidia-triton-server
```

æ£€æŸ¥å·²éƒ¨ç½²çš„podçŠ¶æ€

```bash
kubectl get all -n nim
```

æ‚¨åº”è¯¥çœ‹åˆ°ç±»ä¼¼ä»¥ä¸‹çš„è¾“å‡ºï¼š
<details>
<summary>ç‚¹å‡»å±•å¼€éƒ¨ç½²è¯¦æƒ…</summary>

```text
NAME                               READY   STATUS    RESTARTS   AGE
pod/nim-llm-llama3-8b-instruct-0   1/1     Running   0          4h2m

NAME                                     TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
service/nim-llm-llama3-8b-instruct       ClusterIP   172.20.5.230   <none>        8000/TCP   4h2m
service/nim-llm-llama3-8b-instruct-sts   ClusterIP   None           <none>        8000/TCP   4h2m

NAME                                          READY   AGE
statefulset.apps/nim-llm-llama3-8b-instruct   1/1     4h2m

NAME                                                             REFERENCE                                TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
horizontalpodautoscaler.autoscaling/nim-llm-llama3-8b-instruct   StatefulSet/nim-llm-llama3-8b-instruct   2/5       1         5         1          4h2m
```
</details>

`llama3-8b-instruct`æ¨¡å‹ä»¥StatefulSetçš„å½¢å¼éƒ¨ç½²åœ¨`nim`å‘½åç©ºé—´ä¸­ã€‚ç”±äºå®ƒæ­£åœ¨è¿è¡Œï¼ŒKarpenteré…ç½®äº†ä¸€ä¸ªGPU
æ£€æŸ¥Karpenteré…ç½®çš„èŠ‚ç‚¹ã€‚

```bash
kubectl get node -l type=karpenter -L node.kubernetes.io/instance-type
```

```text
NAME                                         STATUS   ROLES    AGE     VERSION               INSTANCE-TYPE
ip-100-64-77-39.us-west-2.compute.internal   Ready    <none>   4m46s   v1.30.0-eks-036c24b   g5.2xlarge
```

**4. éªŒè¯å·²éƒ¨ç½²çš„æ¨¡å‹**

ä¸€æ—¦`nim`å‘½åç©ºé—´ä¸­çš„æ‰€æœ‰podéƒ½å‡†å¤‡å°±ç»ªï¼ŒçŠ¶æ€ä¸º`1/1`ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤éªŒè¯å®ƒæ˜¯å¦å·²å‡†å¤‡å¥½æä¾›æµé‡ã€‚è¦éªŒè¯ï¼Œä½¿ç”¨kubectlé€šè¿‡ç«¯å£è½¬å‘å…¬å¼€æ¨¡å‹æœåŠ¡æœåŠ¡ã€‚

```bash
kubectl port-forward -n nim service/nim-llm-llama3-8b-instruct 8000
```

ç„¶åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ç®€å•çš„HTTPè¯·æ±‚å’Œcurlå‘½ä»¤è°ƒç”¨å·²éƒ¨ç½²çš„æ¨¡å‹ã€‚

```bash
curl -X 'POST' \
  "http://localhost:8000/v1/completions" \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
      "model": "meta/llama3-8b-instruct",
      "prompt": "Once upon a time",
      "max_tokens": 64
      }'
```

æ‚¨å°†çœ‹åˆ°ç±»ä¼¼ä»¥ä¸‹çš„è¾“å‡º

```json
{
  "id": "cmpl-63a0b66aeda1440c8b6ca1ce3583b173",
  "object": "text_completion",
  "created": 1719742336,
  "model": "meta/llama3-8b-instruct",
  "choices": [
    {
      "index": 0,
      "text": ", there was a young man named Jack who lived in a small village at the foot of a vast and ancient forest. Jack was a curious and adventurous soul, always eager to explore the world beyond his village. One day, he decided to venture into the forest, hoping to discover its secrets.\nAs he wandered deeper into",
      "logprobs": null,
      "finish_reason": "length",
      "stop_reason": null
    }
  ],
  "usage": {
    "prompt_tokens": 5,
    "total_tokens": 69,
    "completion_tokens": 64
  }
}
```
### æµ‹è¯•ä½¿ç”¨NIMéƒ¨ç½²çš„Llama3æ¨¡å‹
æ˜¯æ—¶å€™æµ‹è¯•åˆšåˆšéƒ¨ç½²çš„Llama3äº†ã€‚é¦–å…ˆä¸ºæµ‹è¯•è®¾ç½®ä¸€ä¸ªç®€å•çš„ç¯å¢ƒã€‚

```bash
cd data-on-eks/gen-ai/inference/nvidia-nim/nim-client
python3 -m venv .venv
source .venv/bin/activate
pip install openai
```

æˆ‘ä»¬åœ¨prompts.txtä¸­å‡†å¤‡äº†ä¸€äº›æç¤ºï¼Œå®ƒåŒ…å«20ä¸ªæç¤ºã€‚æ‚¨å¯ä»¥ä½¿ç”¨è¿™äº›æç¤ºè¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥éªŒè¯ç”Ÿæˆçš„è¾“å‡ºã€‚

```bash
python3 client.py --input-prompts prompts.txt --results-file results.txt
```

æ‚¨å°†çœ‹åˆ°ç±»ä¼¼ä»¥ä¸‹çš„è¾“å‡ºï¼š

```text
Loading inputs from `prompts.txt`...
Model meta/llama3-8b-instruct - Request 14: 4.68s (4678.46ms)
Model meta/llama3-8b-instruct - Request 10: 6.43s (6434.32ms)
Model meta/llama3-8b-instruct - Request 3: 7.82s (7824.33ms)
Model meta/llama3-8b-instruct - Request 1: 8.54s (8540.69ms)
Model meta/llama3-8b-instruct - Request 5: 8.81s (8807.52ms)
Model meta/llama3-8b-instruct - Request 12: 8.95s (8945.85ms)
Model meta/llama3-8b-instruct - Request 18: 9.77s (9774.75ms)
Model meta/llama3-8b-instruct - Request 16: 9.99s (9994.51ms)
Model meta/llama3-8b-instruct - Request 6: 10.26s (10263.60ms)
Model meta/llama3-8b-instruct - Request 0: 10.27s (10274.35ms)
Model meta/llama3-8b-instruct - Request 4: 10.65s (10654.39ms)
Model meta/llama3-8b-instruct - Request 17: 10.75s (10746.08ms)
Model meta/llama3-8b-instruct - Request 11: 10.86s (10859.91ms)
Model meta/llama3-8b-instruct - Request 15: 10.86s (10857.15ms)
Model meta/llama3-8b-instruct - Request 8: 11.07s (11068.78ms)
Model meta/llama3-8b-instruct - Request 2: 12.11s (12105.07ms)
Model meta/llama3-8b-instruct - Request 19: 12.64s (12636.42ms)
Model meta/llama3-8b-instruct - Request 9: 13.37s (13370.75ms)
Model meta/llama3-8b-instruct - Request 13: 13.57s (13571.28ms)
Model meta/llama3-8b-instruct - Request 7: 14.90s (14901.51ms)
Storing results into `results.txt`...
Accumulated time for all requests: 206.31 seconds (206309.73 milliseconds)
PASS: NVIDIA NIM example
Actual execution time used with concurrency 20 is: 14.92 seconds (14.92 milliseconds)
```

`results.txt`çš„è¾“å‡ºåº”è¯¥å¦‚ä¸‹æ‰€ç¤º

<details>
<summary>ç‚¹å‡»å±•å¼€éƒ¨åˆ†è¾“å‡º</summary>

```text
ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹å’Œè¶…å¤§å‹è¯­è¨€æ¨¡å‹(vLLM)ä¹‹é—´çš„ä¸»è¦åŒºåˆ«æ˜¯ï¼š

1. **è§„æ¨¡**ï¼švLLMéå¸¸åºå¤§ï¼Œæ‹¥æœ‰æ•°åäº¿å‚æ•°ï¼Œè€Œä¼ ç»Ÿæ¨¡å‹é€šå¸¸åªæœ‰æ•°ç™¾ä¸‡å‚æ•°ã€‚
2. **è®­ç»ƒæ•°æ®**ï¼švLLMåœ¨å¤§é‡æ–‡æœ¬æ•°æ®ä¸Šè®­ç»ƒï¼Œé€šå¸¸æ¥æºäºäº’è”ç½‘ï¼Œè€Œä¼ ç»Ÿæ¨¡å‹åˆ™åœ¨è¾ƒå°çš„ã€ç²¾å¿ƒç­–åˆ’çš„æ•°æ®é›†ä¸Šè®­ç»ƒã€‚
3. **æ¶æ„**ï¼švLLMé€šå¸¸ä½¿ç”¨transformeræ¶æ„ï¼Œä¸“ä¸ºæ–‡æœ¬ç­‰é¡ºåºæ•°æ®è®¾è®¡ï¼Œè€Œä¼ ç»Ÿæ¨¡å‹å¯èƒ½ä½¿ç”¨å‰é¦ˆç½‘ç»œæˆ–å¾ªç¯ç¥ç»ç½‘ç»œã€‚
4. **è®­ç»ƒç›®æ ‡**ï¼švLLMé€šå¸¸ä½¿ç”¨æ©ç è¯­è¨€å»ºæ¨¡æˆ–ä¸‹ä¸€å¥é¢„æµ‹ä»»åŠ¡è¿›è¡Œè®­ç»ƒï¼Œè€Œä¼ ç»Ÿæ¨¡å‹å¯èƒ½ä½¿ç”¨åˆ†ç±»ã€å›å½’æˆ–èšç±»ç›®æ ‡ã€‚
5. **è¯„ä¼°æŒ‡æ ‡**ï¼švLLMé€šå¸¸ä½¿ç”¨å›°æƒ‘åº¦ã€å‡†ç¡®æ€§æˆ–æµç•…åº¦ç­‰æŒ‡æ ‡è¿›è¡Œè¯„ä¼°ï¼Œè€Œä¼ ç»Ÿæ¨¡å‹å¯èƒ½ä½¿ç”¨å‡†ç¡®ç‡ã€ç²¾ç¡®åº¦æˆ–å¬å›ç‡ç­‰æŒ‡æ ‡ã€‚
6. **å¯è§£é‡Šæ€§**ï¼šç”±äºå…¶åºå¤§çš„è§„æ¨¡å’Œå¤æ‚çš„æ¶æ„ï¼ŒvLLMé€šå¸¸è¾ƒéš¾è§£é‡Šï¼Œè€Œä¼ ç»Ÿæ¨¡å‹ç”±äºè§„æ¨¡è¾ƒå°å’Œæ¶æ„è¾ƒç®€å•ï¼Œå¯èƒ½æ›´å®¹æ˜“è§£é‡Šã€‚

è¿™äº›å·®å¼‚ä½¿vLLMåœ¨è¯­è¨€ç¿»è¯‘ã€æ–‡æœ¬ç”Ÿæˆå’Œå¯¹è¯AIç­‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œè€Œä¼ ç»Ÿæ¨¡å‹æ›´é€‚åˆå›¾åƒåˆ†ç±»æˆ–å›å½’ç­‰ä»»åŠ¡ã€‚

=========

TensorRT (Triton Runtime)é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¼˜åŒ–NVIDIAç¡¬ä»¶ä¸Šçš„LLM (å¤§å‹è¯­è¨€æ¨¡å‹)æ¨ç†ï¼š

1. **æ¨¡å‹å‰ªæ**ï¼šç§»é™¤ä¸å¿…è¦çš„æƒé‡å’Œè¿æ¥ï¼Œä»¥å‡å°‘æ¨¡å‹å¤§å°å’Œè®¡ç®—éœ€æ±‚ã€‚
2. **é‡åŒ–**ï¼šå°†æµ®ç‚¹æ¨¡å‹è½¬æ¢ä¸ºä½ç²¾åº¦æ•´æ•°æ ¼å¼ï¼ˆå¦‚INT8ï¼‰ï¼Œä»¥å‡å°‘å†…å­˜å¸¦å®½å¹¶æé«˜æ€§èƒ½ã€‚
3. **å†…æ ¸èåˆ**ï¼šå°†å¤šä¸ªå†…æ ¸å¯åŠ¨åˆå¹¶ä¸ºå•ä¸ªå¯åŠ¨ï¼Œä»¥å‡å°‘å¼€é”€å¹¶æé«˜å¹¶è¡Œæ€§ã€‚
4. **ä¼˜åŒ–çš„Tensor Cores**ï¼šåˆ©ç”¨NVIDIAçš„Tensor Coresè¿›è¡ŒçŸ©é˜µä¹˜æ³•ï¼Œæä¾›æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚
5. **æ‰¹å¤„ç†**ï¼šåŒæ—¶å¤„ç†å¤šä¸ªè¾“å…¥æ‰¹æ¬¡ä»¥æé«˜ååé‡ã€‚
6. **æ··åˆç²¾åº¦**ï¼šä½¿ç”¨æµ®ç‚¹å’Œæ•´æ•°ç²¾åº¦çš„ç»„åˆï¼Œå¹³è¡¡å‡†ç¡®æ€§å’Œæ€§èƒ½ã€‚
7. **å›¾ä¼˜åŒ–**ï¼šé‡æ–°æ’åºå’Œé‡ç»„è®¡ç®—å›¾ï¼Œä»¥æœ€å°åŒ–å†…å­˜è®¿é—®å¹¶ä¼˜åŒ–æ•°æ®ä¼ è¾“ã€‚

é€šè¿‡åº”ç”¨è¿™äº›ä¼˜åŒ–ï¼ŒTensorRTå¯ä»¥æ˜¾è‘—åŠ é€ŸNVIDIAç¡¬ä»¶ä¸Šçš„LLMæ¨ç†ï¼Œå®ç°æ›´å¿«çš„æ¨ç†æ—¶é—´å’Œæ”¹è¿›çš„æ€§èƒ½ã€‚

=========
```
</details>

## Open WebUIéƒ¨ç½²

:::info

[Open WebUI](https://github.com/open-webui/open-webui)ä»…ä¸ä½¿ç”¨OpenAI APIæœåŠ¡å™¨å’ŒOllamaå·¥ä½œçš„æ¨¡å‹å…¼å®¹ã€‚

:::

**1. éƒ¨ç½²WebUI**

é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤éƒ¨ç½²[Open WebUI](https://github.com/open-webui/open-webui)ï¼š

```sh
kubectl apply -f data-on-eks/gen-ai/inference/nvidia-nim/openai-webui-deployment.yaml
```

**2. ç«¯å£è½¬å‘ä»¥è®¿é—®WebUI**

ä½¿ç”¨kubectlç«¯å£è½¬å‘åœ¨æœ¬åœ°è®¿é—®WebUIï¼š

```sh
kubectl port-forward svc/open-webui 8081:80 -n openai-webui
```

**3. è®¿é—®WebUI**

æ‰“å¼€æµè§ˆå™¨å¹¶è®¿é—®http://localhost:8081

**4. æ³¨å†Œ**

ä½¿ç”¨æ‚¨çš„å§“åã€ç”µå­é‚®ä»¶å’Œè™šæ‹Ÿå¯†ç æ³¨å†Œã€‚

**5. å¼€å§‹æ–°çš„èŠå¤©**

ç‚¹å‡»æ–°å»ºèŠå¤©å¹¶ä»ä¸‹æ‹‰èœå•ä¸­é€‰æ‹©æ¨¡å‹ï¼Œå¦‚ä¸‹é¢çš„æˆªå›¾æ‰€ç¤ºï¼š

![alt text](../../../../../../../docs/gen-ai/inference/img/openweb-ui-nim-1.png)

**6. è¾“å…¥æµ‹è¯•æç¤º**

è¾“å…¥æ‚¨çš„æç¤ºï¼Œæ‚¨å°†çœ‹åˆ°æµå¼ç»“æœï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

![alt text](../../../../../../../docs/gen-ai/inference/img/openweb-ui-nim-2.png)
## ä½¿ç”¨NVIDIA GenAI-Perfå·¥å…·è¿›è¡Œæ€§èƒ½æµ‹è¯•

[GenAI-Perf](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/client/src/c%2B%2B/perf_analyzer/genai-perf/README.html)æ˜¯ä¸€ä¸ªå‘½ä»¤è¡Œå·¥å…·ï¼Œç”¨äºæµ‹é‡é€šè¿‡æ¨ç†æœåŠ¡å™¨æä¾›çš„ç”Ÿæˆå¼AIæ¨¡å‹çš„ååé‡å’Œå»¶è¿Ÿã€‚

GenAI-Perfå¯ä»¥ä½œä¸ºæ ‡å‡†å·¥å…·ä¸éƒ¨ç½²äº†æ¨ç†æœåŠ¡å™¨çš„å…¶ä»–æ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚ä½†æ­¤å·¥å…·éœ€è¦GPUã€‚ä¸ºäº†ç®€åŒ–æ“ä½œï¼Œæˆ‘ä»¬ä¸ºæ‚¨æä¾›äº†ä¸€ä¸ªé¢„é…ç½®çš„æ¸…å•`genaiperf-deploy.yaml`æ¥è¿è¡Œè¯¥å·¥å…·ã€‚

```bash
cd data-on-eks/gen-ai/inference/nvidia-nim
kubectl apply -f genaiperf-deploy.yaml
```

ä¸€æ—¦podå‡†å¤‡å°±ç»ªï¼ŒçŠ¶æ€ä¸º`1/1`ï¼Œå¯ä»¥æ‰§è¡Œè¿›å…¥podã€‚

```bash
export POD_NAME=$(kubectl get po -l app=tritonserver -ojsonpath='{.items[0].metadata.name}')
kubectl exec -it $POD_NAME -- bash
```

å¯¹å·²éƒ¨ç½²çš„NIM Llama3æ¨¡å‹è¿è¡Œæµ‹è¯•

```bash
genai-perf \
  -m meta/llama3-8b-instruct \
  --service-kind openai \
  --endpoint v1/completions \
  --endpoint-type completions \
  --num-prompts 100 \
  --random-seed 123 \
  --synthetic-input-tokens-mean 200 \
  --synthetic-input-tokens-stddev 0 \
  --output-tokens-mean 100 \
  --output-tokens-stddev 0 \
  --tokenizer hf-internal-testing/llama-tokenizer \
  --concurrency 10 \
  --measurement-interval 4000 \
  --profile-export-file my_profile_export.json \
  --url nim-llm-llama3-8b-instruct.nim:8000
```

æ‚¨åº”è¯¥çœ‹åˆ°ç±»ä¼¼ä»¥ä¸‹çš„è¾“å‡º

```bash
2024-07-11 03:32 [INFO] genai_perf.parser:166 - Model name 'meta/llama3-8b-instruct' cannot be used to create artifact directory. Instead, 'meta_llama3-8b-instruct' will be used.
2024-07-11 03:32 [INFO] genai_perf.wrapper:137 - Running Perf Analyzer : 'perf_analyzer -m meta/llama3-8b-instruct --async --input-data artifacts/meta_llama3-8b-instruct-openai-completions-concurrency10/llm_inputs.json --endpoint v1/completions --service-kind openai -u nim-llm.nim:8000 --measurement-interval 4000 --stability-percentage 999 --profile-export-file artifacts/meta_llama3-8b-instruct-openai-completions-concurrency10/my_profile_export.json -i http --concurrency-range 10'
                                                      LLM Metrics
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ            Statistic â”ƒ           avg â”ƒ           min â”ƒ           max â”ƒ           p99 â”ƒ           p90 â”ƒ           p75 â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Request latency (ns) â”‚ 3,934,624,446 â”‚ 3,897,758,114 â”‚ 3,936,987,882 â”‚ 3,936,860,185 â”‚ 3,936,429,317 â”‚ 3,936,333,682 â”‚
â”‚     Num output token â”‚           112 â”‚           105 â”‚           119 â”‚           119 â”‚           117 â”‚           115 â”‚
â”‚      Num input token â”‚           200 â”‚           200 â”‚           200 â”‚           200 â”‚           200 â”‚           200 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Output token throughput (per sec): 284.64
Request throughput (per sec): 2.54
```
æ‚¨åº”è¯¥èƒ½å¤Ÿçœ‹åˆ°genai-perfæ”¶é›†çš„[æŒ‡æ ‡](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/client/src/c%2B%2B/perf_analyzer/genai-perf/README.html#metrics)ï¼ŒåŒ…æ‹¬è¯·æ±‚å»¶è¿Ÿã€è¾“å‡ºä»¤ç‰Œååé‡ã€è¯·æ±‚ååé‡ã€‚

è¦äº†è§£å‘½ä»¤è¡Œé€‰é¡¹ï¼Œè¯·å‚é˜…[æ­¤æ–‡æ¡£](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/client/src/c%2B%2B/perf_analyzer/genai-perf/README.html#command-line-options)ã€‚

## å¯è§‚æµ‹æ€§

ä½œä¸ºæ­¤è“å›¾çš„ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬è¿˜éƒ¨ç½²äº†Kube Prometheuså †æ ˆï¼Œå®ƒæä¾›PrometheusæœåŠ¡å™¨å’ŒGrafanaéƒ¨ç½²ï¼Œç”¨äºç›‘æ§å’Œå¯è§‚æµ‹æ€§ã€‚

é¦–å…ˆï¼Œè®©æˆ‘ä»¬éªŒè¯Kube Prometheuså †æ ˆéƒ¨ç½²çš„æœåŠ¡ï¼š

```bash
kubectl get svc -n monitoring
```

æ‚¨åº”è¯¥çœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„è¾“å‡ºï¼š

```text
NAME                                             TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
kube-prometheus-stack-grafana                    ClusterIP   172.20.225.77    <none>        80/TCP              10m
kube-prometheus-stack-kube-state-metrics         ClusterIP   172.20.237.248   <none>        8080/TCP            10m
kube-prometheus-stack-operator                   ClusterIP   172.20.118.163   <none>        443/TCP             10m
kube-prometheus-stack-prometheus                 ClusterIP   172.20.132.214   <none>        9090/TCP,8080/TCP   10m
kube-prometheus-stack-prometheus-node-exporter   ClusterIP   172.20.213.178   <none>        9100/TCP            10m
prometheus-adapter                               ClusterIP   172.20.171.163   <none>        443/TCP             10m
prometheus-operated                              ClusterIP   None             <none>        9090/TCP            10m
```

NVIDIA NIM LLMæœåŠ¡é€šè¿‡`nim-llm-llama3-8b-instruct`æœåŠ¡çš„ç«¯å£`8000`ä¸Šçš„`/metrics`ç«¯ç‚¹å…¬å¼€æŒ‡æ ‡ã€‚é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤è¿›è¡ŒéªŒè¯

```bash
kubectl get svc -n nim
kubectl port-forward -n nim svc/nim-llm-llama3-8b-instruct 8000

curl localhost:8000/metrics # åœ¨å¦ä¸€ä¸ªç»ˆç«¯ä¸­è¿è¡Œæ­¤å‘½ä»¤
```

### Grafanaä»ªè¡¨æ¿

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªé¢„é…ç½®çš„Grafanaä»ªè¡¨æ¿ï¼Œä»¥æ›´å¥½åœ°å¯è§†åŒ–NIMçŠ¶æ€ã€‚åœ¨ä¸‹é¢çš„Grafanaä»ªè¡¨æ¿ä¸­ï¼Œå®ƒåŒ…å«å‡ ä¸ªé‡è¦æŒ‡æ ‡ï¼š

- **é¦–ä¸ªä»¤ç‰Œæ—¶é—´(TTFT)**ï¼šä»åˆå§‹æ¨ç†è¯·æ±‚åˆ°æ¨¡å‹è¿”å›ç¬¬ä¸€ä¸ªä»¤ç‰Œä¹‹é—´çš„å»¶è¿Ÿã€‚
- **ä»¤ç‰Œé—´å»¶è¿Ÿ(ITL)**ï¼šç¬¬ä¸€ä¸ªä»¤ç‰Œä¹‹åæ¯ä¸ªä»¤ç‰Œä¹‹é—´çš„å»¶è¿Ÿã€‚
- **æ€»ååé‡**ï¼šNIMæ¯ç§’ç”Ÿæˆçš„ä»¤ç‰Œæ€»æ•°ã€‚

æ‚¨å¯ä»¥ä»æ­¤[æ–‡æ¡£](https://docs.nvidia.com/nim/large-language-models/latest/observability.html)ä¸­æ‰¾åˆ°æ›´å¤šæŒ‡æ ‡æè¿°ã€‚

![NVIDIA LLMæœåŠ¡å™¨](../../../../../../../docs/gen-ai/inference/img/nim-dashboard.png)

æ‚¨å¯ä»¥ç›‘æ§é¦–ä¸ªä»¤ç‰Œæ—¶é—´ã€ä»¤ç‰Œé—´å»¶è¿Ÿã€KVç¼“å­˜åˆ©ç”¨ç‡ç­‰æŒ‡æ ‡ã€‚

![NVIDIA NIMæŒ‡æ ‡](../../../../../../../docs/gen-ai/inference/img/nim-dashboard-2.png)

è¦æŸ¥çœ‹Grafanaä»ªè¡¨æ¿ä»¥ç›‘æ§è¿™äº›æŒ‡æ ‡ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š

<details>
<summary>ç‚¹å‡»å±•å¼€è¯¦æƒ…</summary>

**1. æ£€ç´¢Grafanaå¯†ç ã€‚**

å¯†ç ä¿å­˜åœ¨AWS Secret Managerä¸­ã€‚ä»¥ä¸‹Terraformå‘½ä»¤å°†æ˜¾ç¤ºå¯†é’¥åç§°ã€‚

```bash
terraform output grafana_secret_name
```

ç„¶åä½¿ç”¨è¾“å‡ºçš„å¯†é’¥åç§°è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œ

```bash
aws secretsmanager get-secret-value --secret-id <grafana_secret_name_output> --region $AWS_REGION --query "SecretString" --output text
```

**2. å…¬å¼€GrafanaæœåŠ¡**

ä½¿ç”¨ç«¯å£è½¬å‘å…¬å¼€GrafanaæœåŠ¡ã€‚

```bash
kubectl port-forward svc/kube-prometheus-stack-grafana 3000:80 -n monitoring
```

**3. ç™»å½•Grafanaï¼š**

- æ‰“å¼€ç½‘ç»œæµè§ˆå™¨å¹¶å¯¼èˆªè‡³[http://localhost:3000](http://localhost:3000)ã€‚
- ä½¿ç”¨ç”¨æˆ·å`admin`å’Œä»AWS Secrets Manageræ£€ç´¢çš„å¯†ç ç™»å½•ã€‚

**4. æ‰“å¼€NIMç›‘æ§ä»ªè¡¨æ¿ï¼š**

- ç™»å½•åï¼Œç‚¹å‡»å·¦ä¾§è¾¹æ ä¸Šçš„"Dashboards"å¹¶æœç´¢"nim"
- æ‚¨å¯ä»¥ä»åˆ—è¡¨ä¸­æ‰¾åˆ°ä»ªè¡¨æ¿`NVIDIA NIM Monitoring`
- ç‚¹å‡»å¹¶è¿›å…¥ä»ªè¡¨æ¿ã€‚

ç°åœ¨æ‚¨åº”è¯¥å¯ä»¥çœ‹åˆ°Grafanaä»ªè¡¨æ¿ä¸Šæ˜¾ç¤ºçš„æŒ‡æ ‡ï¼Œä½¿æ‚¨èƒ½å¤Ÿç›‘æ§NVIDIA NIMæœåŠ¡éƒ¨ç½²çš„æ€§èƒ½ã€‚
</details>

:::info
åœ¨æ’°å†™æœ¬æŒ‡å—æ—¶ï¼ŒNVIDIAè¿˜æä¾›äº†ä¸€ä¸ªç¤ºä¾‹Grafanaä»ªè¡¨æ¿ã€‚æ‚¨å¯ä»¥ä»[è¿™é‡Œ](https://docs.nvidia.com/nim/large-language-models/latest/observability.html#grafana)æŸ¥çœ‹ã€‚
:::

## æ¸…ç†

è¦åˆ é™¤æ­¤éƒ¨ç½²åˆ›å»ºçš„æ‰€æœ‰èµ„æºï¼Œè¯·è¿è¡Œï¼š

```bash
./cleanup.sh
```
