---
sidebar_position: 1
sidebar_label: Introduction
---

# Data Analytics on EKS

Running data analytics tools on Kubernetes can provide a number of benefits for organizations looking to extract insights from large and complex data sets. Tools such as **Apache Spark** and **DASK** are designed to run on a cluster of machines, making them well-suited for deployment on Kubernetes. 

The **Spark Operator** for Kubernetes is a popular Kubernetes operator that simplifies the deployment and management of Apache Spark on Kubernetes. By using the Spark Operator, organizations can take advantage of features such as automatic scaling, rolling updates, and self-healing capabilities to ensure high availability and reliability of their data analytics pipelines. This can greatly simplify and automate the deployment, scaling, and management of these complex applications, freeing up data scientists and engineers to focus on the analysis and interpretation of the data. 

With its growing ecosystem of tools and support for a wide range of use cases, Kubernetes is becoming an increasingly popular choice for running data analytics platforms in production.
- [Spark Operator](https://github.com/GoogleCloudPlatform/spark-on-k8s-operator)
- [Spark Submit](https://spark.apache.org/docs/latest/running-on-kubernetes.html)
- [Karpenter](https://karpenter.sh/)
- [Apache YuniKorn](https://yunikorn.apache.org/)
- [Volcano](https://volcano.sh/en/)
