prometheus:
  serviceAccount:
    create: true
    name: ${amp_sa}
    annotations:
      eks.amazonaws.com/role-arn: ${amp_irsa}
  prometheusSpec:
    remoteWrite:
      - url: ${amp_remotewrite_url}
        sigv4:
          region: ${region}
        queueConfig:
          maxSamplesPerSend: 1000
          maxShards: 200
          capacity: 2500
    retention: 5h
    scrapeInterval: 30s
    evaluationInterval: 30s
    scrapeTimeout: 10s
    storageSpec:
      volumeClaimTemplate:
        metadata:
          name: data
        spec:
          storageClassName: gp3
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 50Gi
    # Find monitors in all namespaces
    podMonitorSelectorNilUsesHelmValues: false
    probeSelectorNilUsesHelmValues: false
    ruleSelectorNilUsesHelmValues: false
    serviceMonitorSelectorNilUsesHelmValues: false
    # Scrape Cost metrics for Karpenter and Yunikorn add-ons
    additionalScrapeConfigs:
      - job_name: yunikorn
        honor_labels: true
        scrape_interval: 15s
        scrape_timeout: 10s
        metrics_path: /ws/v1//metrics
        scheme: http
        dns_sd_configs:
          - names:
              - yunikorn-service.yunikorn.svc
            type: 'A'
            port: 9080
      - job_name: karpenter
        kubernetes_sd_configs:
        - role: endpoints
          namespaces:
            names:
            - karpenter
        relabel_configs:
        - source_labels:
          - __meta_kubernetes_endpoints_name
          - __meta_kubernetes_endpoint_port_name
          action: keep
          regex: karpenter;http-metrics
  # Monitors for Spark Jobs
  additionalPodMonitors:
    - name: "spark-job-monitoring"
      jobLabel: "spark-job-monitoring"
      selector:
        matchLabels:
          spark-role: driver
      namespaceSelector:
        matchNames:
          - spark-team-a
          - spark-team-b
          - spark-team-c
      podMetricsEndpoints:
        - port: "spark-ui"
          interval: 30s
          path: /metrics/driver/prometheus/
        - port: "spark-ui"
          interval: 30s
          path: /metrics/executors/prometheus/

alertmanager:
  enabled: false

grafana:
  enabled: true
  defaultDashboardsEnabled: true
# Adding AMP datasource to Grafana config
  serviceAccount:
    create: false
    name: ${amp_sa}
  grafana.ini:
    auth:
      sigv4_auth_enabled: true
  additionalDataSources:
    - name: AMP
      editable: true
      jsonData:
        sigV4Auth: true
        sigV4Region: ${region}
      type: prometheus
      isDefault: false
      url: ${amp_url}
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        editable: true
        options:
          path: /var/lib/grafana/dashboards/default
  dashboards:
    default:
      karpenter-capacity-dashboard:
        url: https://karpenter.sh/v1.2/getting-started/getting-started-with-karpenter/karpenter-capacity-dashboard.json
      karpenter-performance-dashboard:
        url: https://karpenter.sh/v1.2/getting-started/getting-started-with-karpenter/karpenter-performance-dashboard.json
      spark-job-dashboard:
        url: https://raw.githubusercontent.com/awslabs/data-on-eks/refs/heads/main/analytics/terraform/emr-eks-karpenter/emr-grafana-dashboard/emr-eks-grafana-dashboard.json
