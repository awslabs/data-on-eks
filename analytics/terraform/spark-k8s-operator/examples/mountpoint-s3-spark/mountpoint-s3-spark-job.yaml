# Pre-requisite before running this job
# Replace <S3_BUCKET_NAME> with your S3 bucket created by this blueprint(Check Terraform outputs)
# Verify that the version for spark matches

---
apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: "taxi-trip"
  namespace: spark-team-a
  labels:
    app: "taxi-trip"
    applicationId: "taxi-trip-nvme"
    queue: root.test
spec:
  type: Python
  sparkVersion: "3.4.0" # Mountpoint-S3 Configuration
  pythonVersion: "3"
  mode: cluster
  image: "apache/spark-py:v3.4.0" # Mountpoint-S3 Configuration
  imagePullPolicy: IfNotPresent
  mainApplicationFile: "local:///mnt/s3/jars/pyspark-taxi-trip.py"  # MainFile is the path to a bundled JAR, Python, or R file of the application
  deps:
    jars:
      - "local:///mnt/s3/jars/aws-java-sdk-bundle-1.12.647.jar" # Mountpoint-S3 Configuration
      - "local:///mnt/s3/jars/hadoop-aws-3.3.1.jar" # Mountpoint-S3 Configuration
  volumes:
    - name: spark-volume
      hostPath:
        path: /mnt/s3/jars # Mountpoint-S3 Configuration
        type: Directory
  arguments:
    - "s3a://<S3_BUCKET_NAME>/taxi-trip/input/"
    - "s3a://<S3_BUCKET_NAME>/taxi-trip/output/"
  hadoopConf:
    "fs.s3a.aws.credentials.provider": "com.amazonaws.auth.WebIdentityTokenCredentialsProvider"
    "fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
    "mapreduce.fileoutputcommitter.algorithm.version": "2"
  sparkConf:
    "spark.app.name": "taxi-trip"
    "spark.driver.extraClassPath": "mnt/s3/jars/*" # Mountpoint-S3 Configuration
    "spark.executor.extraClassPath": "mnt/s3/jars/*" # Mountpoint-S3 Configuration
    "spark.kubernetes.driver.pod.name": "taxi-trip"
    "spark.kubernetes.executor.podNamePrefix": "taxi-trip"
    "spark.speculation": "false"
    "spark.network.timeout": "2400"
    "spark.hadoop.fs.s3a.connection.timeout": "1200000"
    "spark.hadoop.fs.s3a.path.style.access": "true"
    "spark.hadoop.fs.s3a.connection.maximum": "200"
    "spark.hadoop.fs.s3a.fast.upload": "true"
    "spark.hadoop.fs.s3a.readahead.range": "256K"
    "spark.hadoop.fs.s3a.input.fadvise": "random"
    "spark.hadoop.fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"

    # Spark Event logs
    "spark.eventLog.enabled": "true"
    "spark.eventLog.dir": "s3a://<S3_BUCKET_NAME>/spark-event-logs"
    "spark.eventLog.rolling.enabled": "true"
    "spark.eventLog.rolling.maxFileSize": "64m"

    # Expose Spark metrics for Prometheus
    "spark.ui.prometheus.enabled": "true"
    "spark.executor.processTreeMetrics.enabled": "true"
    "spark.kubernetes.driver.annotation.prometheus.io/scrape": "true"
    "spark.kubernetes.driver.annotation.prometheus.io/path": "/metrics/executors/prometheus/"
    "spark.kubernetes.driver.annotation.prometheus.io/port": "4040"
    "spark.kubernetes.driver.service.annotation.prometheus.io/scrape": "true"
    "spark.kubernetes.driver.service.annotation.prometheus.io/path": "/metrics/driver/prometheus/"
    "spark.kubernetes.driver.service.annotation.prometheus.io/port": "4040"
    "spark.metrics.conf.*.sink.prometheusServlet.class": "org.apache.spark.metrics.sink.PrometheusServlet"
    "spark.metrics.conf.*.sink.prometheusServlet.path": "/metrics/driver/prometheus/"
    "spark.metrics.conf.master.sink.prometheusServlet.path": "/metrics/master/prometheus/"
    "spark.metrics.conf.applications.sink.prometheusServlet.path": "/metrics/applications/prometheus/"

  restartPolicy:
    type: OnFailure
    onFailureRetries: 3
    onFailureRetryInterval: 10
    onSubmissionFailureRetries: 5
    onSubmissionFailureRetryInterval: 20
  driver:
    podSecurityContext:
      fsGroup: 2000  # Group ID
      runAsUser: 1000  # User ID
    cores: 1
    coreLimit: "1200m"
    volumeMounts:
      - mountPath: /mnt/s3/jars # Mountpoint-S3 Configuration
        name: spark-volume
    memory: "4g"
    memoryOverhead: "4g"
    serviceAccount: spark-team-a
    labels:
      version: 3.4.0
    nodeSelector:
      multiArch: Spark

  executor:
    podSecurityContext:
      fsGroup: 2000  # Group ID
      runAsUser: 1000  # User ID
    cores: 1
    volumeMounts:
      - mountPath: /mnt/s3/jars # Mountpoint-S3 Configuration
        name: spark-volume
    coreLimit: "3400m"
    instances: 4
    memory: "4g"
    memoryOverhead: "4g"
    serviceAccount: spark-team-a
    labels:
      version: 3.4.0
    nodeSelector:
      multiArch: Spark
