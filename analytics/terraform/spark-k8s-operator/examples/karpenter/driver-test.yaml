apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"sparkoperator.k8s.io/v1beta2","kind":"SparkApplication","metadata":{"annotations":{},"labels":{"app":"pyspark-pi","applicationId":"pyspark-pi-karpenter-yunikorn","queue":"root.test"},"name":"pyspark-pi-karpenter-yunikorn","namespace":"spark-team-a"},"spec":{"batchScheduler":"yunikorn","batchSchedulerOptions":{"queue":"root.test"},"driver":{"annotations":{"yunikorn.apache.org/task-group-name":"spark-driver","yunikorn.apache.org/task-groups":"[\n  {\n    \"name\": \"spark-executor\",\n    \"minMember\": EXECUTOR_COUNT,\n    \"minResource\": {\n      \"cpu\": \"1\",\n      \"memory\": \"2Gi\"\n    }\n  },\n  {\n    \"name\": \"spark-driver\",\n    \"minMember\": 1,\n    \"minResource\": {\n      \"cpu\": \"1\",\n      \"memory\": \"2Gi\"\n    },\n    \"affinity\": {\n      \"podAffinity\": {\n        \"requiredDuringSchedulingIgnoredDuringExecution\": [\n          {\n            \"labelSelector\": {\n              \"matchExpressions\": [\n                {\n                  \"key\": \"spark-role\",\n                  \"operator\": \"In\",\n                  \"values\": [\"executor\"]\n                }\n              ]\n            },\n            \"topologyKey\": \"topology.kubernetes.io/zone\"\n          }\n        ]\n      }\n    }\n  }\n]\n"},"coreLimit":"4200m","cores":2,"labels":{"version":"3.2.1"},"memory":"4g","memoryOverhead":"2g","nodeSelector":{"NodeGroupType":"SparkComputeOnDemand"},"serviceAccount":"spark-team-a"},"executor":{"annotations":{"yunikorn.apache.org/task-group-name":"spark-executor"},"coreLimit":"2000m","cores":2,"instances":4,"labels":{"version":"3.2.1"},"memory":"4g","memoryOverhead":"2g","nodeSelector":{"NodeGroupType":"SparkComputeSpotR"},"serviceAccount":"spark-team-a"},"image":"public.ecr.aws/data-on-eks/spark:3.5.3-scala2.12-java17-python3-ubuntu","imagePullPolicy":"Always","mainApplicationFile":"local:///opt/spark/examples/src/main/python/pi.py","mode":"cluster","pythonVersion":"3","restartPolicy":{"onFailureRetries":1,"onFailureRetryInterval":10,"onSubmissionFailureRetries":5,"onSubmissionFailureRetryInterval":20,"type":"OnFailure"},"sparkConf":{"spark.eventLog.dir":"s3a://spark-operator-doeks-spark-logs-20251010151952658500000009/spark-event-logs","spark.eventLog.enabled":"true","spark.eventLog.rolling.enabled":"true","spark.eventLog.rolling.maxFileSize":"64m","spark.executor.processTreeMetrics.enabled":"true","spark.hadoop.fs.s3.impl":"org.apache.hadoop.fs.s3a.S3AFileSystem","spark.hadoop.fs.s3a.aws.credentials.provider":"software.amazon.awssdk.auth.credentials.WebIdentityTokenFileCredentialsProvider","spark.hadoop.fs.s3a.aws.credentials.provider.mapping":"com.amazonaws.auth.WebIdentityTokenCredentialsProvider=software.amazon.awssdk.auth.credentials.WebIdentityTokenFileCredentialsProvider","spark.metrics.conf.*.sink.prometheusServlet.class":"org.apache.spark.metrics.sink.PrometheusServlet","spark.metrics.conf.driver.sink.prometheusServlet.path":"/metrics/driver/prometheus/","spark.metrics.conf.executor.sink.prometheusServlet.path":"/metrics/executors/prometheus/","spark.ui.prometheus.enabled":"true"},"sparkVersion":"3.5.3","type":"Python"}}
  creationTimestamp: "2025-10-29T22:33:20Z"
  generation: 1
  labels:
    app: pyspark-pi
    applicationId: pyspark-pi-karpenter-yunikorn
    queue: root.test
  name: pyspark-pi-karpenter-yunikorn
  namespace: spark-team-a
  resourceVersion: "9962663"
  uid: 8882e339-1636-4eba-9665-743439cfb361
spec:
  batchScheduler: yunikorn
  batchSchedulerOptions:
    queue: root.test
  deps: {}
  driver:
    annotations:
      yunikorn.apache.org/task-group-name: spark-driver
      yunikorn.apache.org/task-groups: |
        [
          {
            "name": "spark-executor",
            "minMember": EXECUTOR_COUNT,
            "minResource": {
              "cpu": "1",
              "memory": "2Gi"
            }
          },
          {
            "name": "spark-driver",
            "minMember": 1,
            "minResource": {
              "cpu": "1",
              "memory": "2Gi"
            },
            "affinity": {
              "podAffinity": {
                "requiredDuringSchedulingIgnoredDuringExecution": [
                  {
                    "labelSelector": {
                      "matchExpressions": [
                        {
                          "key": "spark-role",
                          "operator": "In",
                          "values": ["executor"]
                        }
                      ]
                    },
                    "topologyKey": "topology.kubernetes.io/zone"
                  }
                ]
              }
            }
          }
        ]
    coreLimit: 4200m
    cores: 2
    labels:
      version: 3.2.1
    memory: 4g
    memoryOverhead: 2g
    nodeSelector:
      NodeGroupType: SparkComputeOnDemand
    serviceAccount: spark-team-a
  executor:
    annotations:
      yunikorn.apache.org/task-group-name: spark-executor
    coreLimit: 2000m
    cores: 2
    instances: 4
    labels:
      version: 3.2.1
    memory: 4g
    memoryOverhead: 2g
    nodeSelector:
      NodeGroupType: SparkComputeSpotR
    serviceAccount: spark-team-a
  image: public.ecr.aws/data-on-eks/spark:3.5.3-scala2.12-java17-python3-ubuntu
  imagePullPolicy: Always
  mainApplicationFile: local:///opt/spark/examples/src/main/python/pi.py
  mode: cluster
  pythonVersion: "3"
  restartPolicy:
    onFailureRetries: 1
    onFailureRetryInterval: 10
    onSubmissionFailureRetries: 5
    onSubmissionFailureRetryInterval: 20
    type: OnFailure
  sparkConf:
    spark.eventLog.dir: s3a://spark-operator-doeks-spark-logs-20251010151952658500000009/spark-event-logs
    spark.eventLog.enabled: "true"
    spark.eventLog.rolling.enabled: "true"
    spark.eventLog.rolling.maxFileSize: 64m
    spark.executor.processTreeMetrics.enabled: "true"
    spark.hadoop.fs.s3.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
    spark.hadoop.fs.s3a.aws.credentials.provider: software.amazon.awssdk.auth.credentials.WebIdentityTokenFileCredentialsProvider
    spark.hadoop.fs.s3a.aws.credentials.provider.mapping: com.amazonaws.auth.WebIdentityTokenCredentialsProvider=software.amazon.awssdk.auth.credentials.WebIdentityTokenFileCredentialsProvider
    spark.metrics.conf.*.sink.prometheusServlet.class: org.apache.spark.metrics.sink.PrometheusServlet
    spark.metrics.conf.driver.sink.prometheusServlet.path: /metrics/driver/prometheus/
    spark.metrics.conf.executor.sink.prometheusServlet.path: /metrics/executors/prometheus/
    spark.ui.prometheus.enabled: "true"
  sparkVersion: 3.5.3
  type: Python
status:
  applicationState:
    state: SUBMITTED
  driverInfo:
    podName: pyspark-pi-karpenter-yunikorn-driver
    webUIAddress: 172.20.222.239:4040
    webUIPort: 4040
    webUIServiceName: pyspark-pi-karpenter-yunikorn-ui-svc
  executionAttempts: 1
  lastSubmissionAttemptTime: "2025-10-29T22:33:20Z"
  sparkApplicationId: spark-11a49ab3e0fd4f3088a3d5523e7448a9
  submissionAttempts: 1
  submissionID: 83038329-d775-4f18-b2fb-bb7b3381c65f
  terminationTime: null
