# Test Native Spark (no Gluten) with new clean image
---
apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: "test-native-spark"
  namespace: spark-team-a
  labels:
    app: "test-native"
spec:
  type: Python
  sparkVersion: "3.5.2"
  mode: cluster
  image: "public.ecr.aws/data-on-eks/spark:3.5.3-scala2.12-java17-python3-ubuntu"
  imagePullPolicy: Always
  mainApplicationFile: "s3a://$S3_BUCKET/benchmarks/analytical-benchmark.py"
  arguments:
    - "native"
    - "1.0"  # Larger scale to show performance differences
  sparkConf:
    "spark.app.name": "test-native-spark"
    "spark.kubernetes.driver.pod.name": "test-native-driver"
    "spark.kubernetes.executor.podNamePrefix": "test-native"

    # Performance configurations (NO Gluten)
    "spark.sql.adaptive.enabled": "true"
    "spark.sql.adaptive.coalescePartitions.enabled": "true"
    "spark.sql.adaptive.skewJoin.enabled": "true"
    "spark.serializer": "org.apache.spark.serializer.KryoSerializer"

    # S3 Configuration
    "spark.hadoop.fs.s3a.connection.timeout": "1200000"
    "spark.hadoop.fs.s3a.path.style.access": "true"
    "spark.hadoop.fs.s3a.connection.maximum": "200"
    "spark.hadoop.fs.s3a.fast.upload": "true"
    "spark.hadoop.fs.s3a.aws.credentials.provider": "software.amazon.awssdk.auth.credentials.WebIdentityTokenFileCredentialsProvider"
    "spark.hadoop.fs.s3.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"

    # Event logs
    "spark.eventLog.enabled": "true"
    "spark.eventLog.dir": "s3a://$S3_BUCKET/spark-event-logs"

  restartPolicy:
    type: Never
  driver:
    cores: 2
    coreLimit: "2400m"
    memory: "4g"
    memoryOverhead: "1g"
    serviceAccount: spark-team-a
    nodeSelector:
      NodeGroupType: "SparkComputeOptimized"
      karpenter.sh/capacity-type: "on-demand"
  executor:
    cores: 2
    coreLimit: "3400m"
    instances: 3
    memory: "4g"
    memoryOverhead: "1g"
    serviceAccount: spark-team-a
    nodeSelector:
      NodeGroupType: "SparkComputeOptimized"
