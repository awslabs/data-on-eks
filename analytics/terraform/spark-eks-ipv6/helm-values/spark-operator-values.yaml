
# image:
#   registry: docker.io
#   repository: kubeflow/spark-operator
#   # -- Image tag.
#   # @default -- If not set, the chart appVersion will be used.
#   tag: ""

controller:
  replicas: 1
  # -- Reconcile concurrency, higher values might increase memory usage.
  workers: 10
  # -- Specifies the maximum number of Executor pods that can be tracked by the controller per SparkApplication.
  maxTrackedExecutorPerApp: 1000
  #------------------------------------
  # THIS WILL CREATE SERVICE AND INGRESS OBJECT FOR EACH SPARK APPLICATION
  #------------------------------------
  # -- Enable UI service creation for Spark application
  uiService:
    enable: true
  ### -- Ingress URL format.
  ### Requires the UI service to be enabled by setting `uiService.enable` to true.
  ### 1/ Enable ingressUrlFormat to create an Ingress object for each Spark Job submitted using Spark Operator
  ### 2/ This setup also requires ingres-nginx to be deployed with NLB as LB with IP based routing.
  ### 3. Enter the NLB DNS name or enter Custom Domain name from route53 below which points to the NLB
  # uiIngress:
  #   enable: false
  #   urlFormat: '<ENTER_NLB_DNS_NAME/CUSTOM_DOMAIN_NAME>/{{$appName}}'

  batchScheduler:
    # -- Specifies whether to enable batch scheduler for spark jobs scheduling.
    # If enabled, users can specify batch scheduler name in spark application.
    enable: true

  serviceAccount:
    # -- Specifies whether to create a service account for the controller.
    create: true
    # -- Optional name for the controller service account.
    name: ""
    # -- Extra annotations for the controller service account.
    annotations: {}

  # -- Node selector for controller pods.
  nodeSelector: {}
  # -- Affinity for controller pods.
  affinity: {}
  # -- List of node taints to tolerate for controller pods.
  tolerations: []

  # -- Environment variables for controller containers.
  env:
  - name: _JAVA_OPTIONS
    value: "-Djava.net.preferIPv6Addresses=true"
  - name: KUBERNETES_DISABLE_HOSTNAME_VERIFICATION
    value: "true"

  # -- Pod resource requests and limits for controller containers.
  # Note, that each job submission will spawn a JVM within the controller pods using "/usr/local/openjdk-11/bin/java -Xmx128m".
  # Kubernetes may kill these Java processes at will to enforce resource limits. When that happens, you will see the following error:
  # 'failed to run spark-submit for SparkApplication [...]: signal: killed' - when this happens, you may want to increase memory limits.
  resources:
    requests:
      cpu: 100m
      memory: 512Mi

webhook:
  # -- Enable webhook server
  enable: true
  # -- Webhook service port
  port: 9443

spark:
  # -- List of namespaces where to run spark jobs.
  # If empty string is included, all namespaces will be allowed.
  # Make sure the namespaces have already existed.
  jobNamespaces:
  - default

  serviceAccount:
    # -- Specifies whether to create a service account for spark applications.
    create: true
    # -- Optional name for the spark service account.
    name: ""
    # -- Optional annotations for the spark service account.
    annotations: {}

prometheus:
  metrics:
    # -- Specifies whether to enable prometheus metrics scraping.
    enable: true
  podMonitor:
    # -- Specifies whether to create pod monitor.
    # Note that prometheus metrics should be enabled as well.
    create: false