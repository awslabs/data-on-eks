apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: spark-history-server
  namespace: argocd
  labels:
    blueprint: spark-k8s-operator
    category: analytics
spec:
  project: data-platform
  source:
    repoURL: https://kubed-ai.github.io/spark-history-server
    chart: spark-history-server
    targetRevision: "1.5.1"
    helm:
      values: |
        sparkHistoryOpts: "-Dspark.history.fs.logDirectory=s3a://{{ .Values.s3BucketName }}/spark-event-logs"
        
        serviceAccount:
          create: true
          name: spark-history-server
          annotations:
            eks.amazonaws.com/role-arn: "{{ .Values.sparkHistoryServerRoleArn }}"
        
        nodeSelector:
          NodeGroupType: "core"
        
        tolerations:
          - key: "CriticalAddonsOnly"
            operator: "Exists"
        
        resources:
          requests:
            cpu: 100m
            memory: 512Mi
          limits:
            cpu: 200m
            memory: 1Gi
        
        service:
          type: ClusterIP
          port: 80
          targetPort: 18080
        
        ingress:
          enabled: false
          className: nginx
          hosts:
            - host: spark-history.{{ .Values.clusterName }}.local
              paths:
                - path: /
                  pathType: Prefix
        
        environment:
          SPARK_HISTORY_OPTS: "-Dspark.history.fs.logDirectory=s3a://{{ .Values.s3BucketName }}/spark-event-logs"
          SPARK_CONF_DIR: "/opt/spark/conf"
  
  destination:
    server: https://kubernetes.default.svc
    namespace: spark-history-server
  
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true