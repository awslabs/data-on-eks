# Spark on EKS - Karpenter Overrides for Dev Environment
# Overrides base karpenter config from infra/argocd/core/karpenter/values.yaml

# Override controller for dev
karpenter:
  controller:
    replicas: 1  # Single replica for dev

    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 500m
        memory: 1Gi

# Spark-specific NodePools (replaces base nodePoolDefaults)
sparkNodePools:
  # Compute-optimized for Spark drivers and executors
  - name: spark-compute-optimized
    metadata:
      labels:
        type: karpenter
        NodeGroupType: SparkComputeOptimized
        multiArch: Spark
        blueprint: spark-on-eks
        environment: dev
    spec:
      template:
        spec:
          nodeClassRef:
            apiVersion: karpenter.k8s.aws/v1
            kind: EC2NodeClass
            name: spark-compute-optimized

          requirements:
            - key: "karpenter.sh/capacity-type"
              operator: In
              values: ["spot", "on-demand"]
            - key: "kubernetes.io/arch"
              operator: In
              values: ["amd64"]
            - key: "karpenter.k8s.aws/instance-category"
              operator: In
              values: ["c"]
            - key: "karpenter.k8s.aws/instance-family"
              operator: In
              values: ["c5d"]
            - key: "karpenter.k8s.aws/instance-size"
              operator: In
              values: ["4xlarge", "9xlarge", "12xlarge", "18xlarge", "24xlarge"]
            - key: "karpenter.k8s.aws/instance-hypervisor"
              operator: In
              values: ["nitro"]
            - key: "karpenter.k8s.aws/instance-generation"
              operator: Gt
              values: ["2"]

          # Spark-specific startup taints
          startupTaints:
            - key: "spark.apache.org/node-type"
              value: "compute-optimized"
              effect: NoSchedule

          expireAfter: 30m
          terminationGracePeriod: 60s

      limits:
        cpu: 1000

      disruption:
        consolidationPolicy: WhenEmptyOrUnderutilized
        consolidateAfter: 1m
      weight: 100

  # Graviton memory-optimized for large Spark jobs
  - name: spark-graviton-memory-optimized
    metadata:
      labels:
        type: karpenter
        NodeGroupType: SparkGravitonMemoryOptimized
        multiArch: Spark
        blueprint: spark-on-eks
        environment: dev
    spec:
      template:
        spec:
          nodeClassRef:
            apiVersion: karpenter.k8s.aws/v1
            kind: EC2NodeClass
            name: spark-graviton-memory-optimized

          requirements:
            - key: "karpenter.sh/capacity-type"
              operator: In
              values: ["spot", "on-demand"]
            - key: "kubernetes.io/arch"
              operator: In
              values: ["arm64"]
            - key: "karpenter.k8s.aws/instance-category"
              operator: In
              values: ["r"]
            - key: "karpenter.k8s.aws/instance-family"
              operator: In
              values: ["r6g", "r6gd", "r7g", "r7gd", "r8g"]
            - key: "karpenter.k8s.aws/instance-size"
              operator: In
              values: ["4xlarge", "8xlarge", "12xlarge", "16xlarge"]
            - key: "karpenter.k8s.aws/instance-hypervisor"
              operator: In
              values: ["nitro"]
            - key: "karpenter.k8s.aws/instance-generation"
              operator: Gt
              values: ["2"]

          startupTaints:
            - key: "spark.apache.org/node-type"
              value: "graviton-memory-optimized"
              effect: NoSchedule

          expireAfter: 30m
          terminationGracePeriod: 120s

      limits:
        cpu: 1000

      disruption:
        consolidationPolicy: WhenEmptyOrUnderutilized
        consolidateAfter: 1m
      weight: 100

  # Memory-optimized for standard Spark jobs
  - name: spark-memory-optimized
    metadata:
      labels:
        type: karpenter
        NodeGroupType: SparkMemoryOptimized
        blueprint: spark-on-eks
        environment: dev
    spec:
      template:
        spec:
          nodeClassRef:
            apiVersion: karpenter.k8s.aws/v1
            kind: EC2NodeClass
            name: spark-memory-optimized

          requirements:
            - key: "karpenter.sh/capacity-type"
              operator: In
              values: ["spot", "on-demand"]
            - key: "kubernetes.io/arch"
              operator: In
              values: ["amd64"]
            - key: "karpenter.k8s.aws/instance-category"
              operator: In
              values: ["r"]
            - key: "karpenter.k8s.aws/instance-family"
              operator: In
              values: ["r5d"]
            - key: "karpenter.k8s.aws/instance-cpu"
              operator: In
              values: ["4", "8", "16", "32"]
            - key: "karpenter.k8s.aws/instance-hypervisor"
              operator: In
              values: ["nitro"]
            - key: "karpenter.k8s.aws/instance-generation"
              operator: Gt
              values: ["2"]

          startupTaints:
            - key: "spark.apache.org/node-type"
              value: "memory-optimized"
              effect: NoSchedule

          expireAfter: 30m
          terminationGracePeriod: 120s

      limits:
        cpu: 1000

      disruption:
        consolidationPolicy: WhenEmptyOrUnderutilized
        consolidateAfter: 1m
      weight: 50

  # Vertical EBS scale for specialized workloads
  - name: spark-vertical-ebs-scale
    metadata:
      labels:
        type: karpenter
        provisioner: spark-vertical-ebs-scale
        blueprint: spark-on-eks
        environment: dev
    spec:
      template:
        spec:
          nodeClassRef:
            apiVersion: karpenter.k8s.aws/v1
            kind: EC2NodeClass
            name: spark-vertical-ebs-scale

          requirements:
            - key: "karpenter.sh/capacity-type"
              operator: In
              values: ["spot", "on-demand"]
            - key: "karpenter.k8s.aws/instance-family"
              operator: In
              values: ["r4", "r5", "r5d", "r5n", "r5dn", "r5b", "m4", "m5", "m5n", "m5zn", "m5dn", "m5d", "c4", "c5", "c5n", "c5d"]
            - key: "kubernetes.io/arch"
              operator: In
              values: ["amd64"]
            - key: "karpenter.k8s.aws/instance-generation"
              operator: Gt
              values: ["2"]

          expireAfter: 30m
          terminationGracePeriod: 120s

      limits:
        cpu: 1000

      disruption:
        consolidationPolicy: WhenEmptyOrUnderutilized
        consolidateAfter: 1m
      weight: 100

  # Benchmark nodes for performance testing
  - name: spark-operator-benchmark
    metadata:
      labels:
        type: karpenter
        NodeGroupType: spark-operator-benchmark
        blueprint: spark-on-eks
        environment: dev
    spec:
      template:
        spec:
          nodeClassRef:
            apiVersion: karpenter.k8s.aws/v1
            kind: EC2NodeClass
            name: spark-operator-benchmark

          requirements:
            - key: "karpenter.sh/capacity-type"
              operator: In
              values: ["on-demand"]
            - key: "karpenter.k8s.aws/instance-category"
              operator: In
              values: ["c"]
            - key: "karpenter.k8s.aws/instance-family"
              operator: In
              values: ["c5"]
            - key: "karpenter.k8s.aws/instance-cpu"
              operator: In
              values: ["8", "36"]
            - key: "karpenter.k8s.aws/instance-hypervisor"
              operator: In
              values: ["nitro"]
            - key: "karpenter.k8s.aws/instance-generation"
              operator: Gt
              values: ["2"]

          expireAfter: 30m
          terminationGracePeriod: 120s

      limits:
        cpu: 1000

      disruption:
        consolidationPolicy: WhenEmptyOrUnderutilized
        consolidateAfter: 1m
      weight: 100

  # OnDemand compute for critical workloads
  - name: spark-compute-ondemand
    metadata:
      labels:
        type: karpenter
        NodeGroupType: SparkComputeOnDemand
        multiArch: Spark
        blueprint: spark-on-eks
        environment: dev
    spec:
      template:
        spec:
          nodeClassRef:
            apiVersion: karpenter.k8s.aws/v1
            kind: EC2NodeClass
            name: spark-compute-ondemand

          requirements:
            - key: "karpenter.sh/capacity-type"
              operator: In
              values: ["on-demand"]
            - key: "kubernetes.io/arch"
              operator: In
              values: ["amd64"]

          expireAfter: 60m
          terminationGracePeriod: 120s

      limits:
        cpu: 2000

      disruption:
        consolidationPolicy: WhenEmptyOrUnderutilized
        consolidateAfter: 1m
      weight: 100

  # Spot CMR instances for cost optimization
  - name: spark-compute-spot-cmr
    metadata:
      labels:
        type: karpenter
        NodeGroupType: SparkComputeSpotCMR
        multiArch: Spark
        blueprint: spark-on-eks
        environment: dev
    spec:
      template:
        spec:
          nodeClassRef:
            apiVersion: karpenter.k8s.aws/v1
            kind: EC2NodeClass
            name: spark-compute-spot-cmr

          requirements:
            - key: "karpenter.sh/capacity-type"
              operator: In
              values: ["spot"]
            - key: "kubernetes.io/arch"
              operator: In
              values: ["amd64"]
            - key: "karpenter.k8s.aws/instance-category"
              operator: In
              values: ["c", "m", "r"]

          expireAfter: 30m
          terminationGracePeriod: 60s

      limits:
        cpu: 2000

      disruption:
        consolidationPolicy: WhenEmptyOrUnderutilized
        consolidateAfter: 1m
      weight: 100

  # R-family spot instances
  - name: spark-compute-spot-r
    metadata:
      labels:
        type: karpenter
        NodeGroupType: SparkComputeSpotR
        multiArch: Spark
        blueprint: spark-on-eks
        environment: dev
    spec:
      template:
        spec:
          nodeClassRef:
            apiVersion: karpenter.k8s.aws/v1
            kind: EC2NodeClass
            name: spark-compute-spot-r

          requirements:
            - key: "karpenter.sh/capacity-type"
              operator: In
              values: ["spot"]
            - key: "kubernetes.io/arch"
              operator: In
              values: ["amd64"]
            - key: "karpenter.k8s.aws/instance-category"
              operator: In
              values: ["r"]
            - key: "karpenter.k8s.aws/instance-family"
              operator: In
              values: ["r5", "r5n", "r6i", "r6in", "r7i"]

          expireAfter: 30m
          terminationGracePeriod: 60s

      limits:
        cpu: 2000

      disruption:
        consolidationPolicy: WhenEmptyOrUnderutilized
        consolidateAfter: 1m
      weight: 100

  # Graviton OnDemand memory-optimized
  - name: spark-compute-graviton-od-memory
    metadata:
      labels:
        type: karpenter
        NodeGroupType: SparkComputeGravitonODMemory
        multiArch: Spark
        blueprint: spark-on-eks
        environment: dev
    spec:
      template:
        spec:
          nodeClassRef:
            apiVersion: karpenter.k8s.aws/v1
            kind: EC2NodeClass
            name: spark-compute-graviton-od-memory

          requirements:
            - key: "karpenter.sh/capacity-type"
              operator: In
              values: ["on-demand"]
            - key: "kubernetes.io/arch"
              operator: In
              values: ["arm64"]
            - key: "karpenter.k8s.aws/instance-category"
              operator: In
              values: ["r"]
            - key: "karpenter.k8s.aws/instance-cpu"
              operator: In
              values: ["4", "8", "16", "32"]
            - key: "karpenter.k8s.aws/instance-hypervisor"
              operator: In
              values: ["nitro"]
            - key: "karpenter.k8s.aws/instance-generation"
              operator: Gt
              values: ["2"]

          expireAfter: 60m
          terminationGracePeriod: 120s

      limits:
        cpu: 2000

      disruption:
        consolidationPolicy: WhenEmptyOrUnderutilized
        consolidateAfter: 1m
      weight: 100

  # General Graviton instances
  - name: spark-compute-graviton
    metadata:
      labels:
        type: karpenter
        NodeGroupType: SparkGravitonMemoryOptimized
        multiArch: Spark
        blueprint: spark-on-eks
        environment: dev
    spec:
      template:
        spec:
          nodeClassRef:
            apiVersion: karpenter.k8s.aws/v1
            kind: EC2NodeClass
            name: spark-compute-graviton

          requirements:
            - key: "karpenter.sh/capacity-type"
              operator: In
              values: ["spot", "on-demand"]
            - key: "kubernetes.io/arch"
              operator: In
              values: ["arm64"]
            - key: "karpenter.k8s.aws/instance-category"
              operator: In
              values: ["r"]
            - key: "karpenter.k8s.aws/instance-family"
              operator: In
              values: ["r6gd"]
            - key: "karpenter.k8s.aws/instance-cpu"
              operator: In
              values: ["4", "8", "16", "32"]
            - key: "karpenter.k8s.aws/instance-hypervisor"
              operator: In
              values: ["nitro"]
            - key: "karpenter.k8s.aws/instance-generation"
              operator: Gt
              values: ["2"]

          expireAfter: 30m
          terminationGracePeriod: 120s

      limits:
        cpu: 2000

      disruption:
        consolidationPolicy: WhenEmptyOrUnderutilized
        consolidateAfter: 1m
      weight: 100

  # NVME-enabled instances for high I/O
  - name: spark-compute-nitro-nvme
    metadata:
      labels:
        type: karpenter
        NodeGroupType: SparkComputeNitroNvme
        multiArch: Spark
        blueprint: spark-on-eks
        environment: dev
    spec:
      template:
        spec:
          nodeClassRef:
            apiVersion: karpenter.k8s.aws/v1
            kind: EC2NodeClass
            name: spark-compute-nitro-nvme

          requirements:
            - key: "karpenter.sh/capacity-type"
              operator: In
              values: ["spot", "on-demand"]
            - key: "kubernetes.io/arch"
              operator: In
              values: ["amd64"]
            - key: "karpenter.k8s.aws/instance-category"
              operator: In
              values: ["c"]
            - key: "karpenter.k8s.aws/instance-family"
              operator: In
              values: ["c5d"]
            - key: "karpenter.k8s.aws/instance-size"
              operator: In
              values: ["4xlarge", "9xlarge", "12xlarge", "18xlarge", "24xlarge"]
            - key: "karpenter.k8s.aws/instance-hypervisor"
              operator: In
              values: ["nitro"]
            - key: "karpenter.k8s.aws/instance-generation"
              operator: Gt
              values: ["2"]

          expireAfter: 30m
          terminationGracePeriod: 120s

      limits:
        cpu: 1000

      disruption:
        consolidationPolicy: WhenEmptyOrUnderutilized
        consolidateAfter: 1m
      weight: 100

# Spark-specific EC2NodeClasses (replaces base ec2NodeClassDefaults)
sparkEC2NodeClasses:
  - name: spark-compute-optimized
    metadata:
      labels:
        blueprint: spark-on-eks
        workload-type: compute-intensive
        environment: dev
    spec:
      amiFamily: AL2023
      instanceStorePolicy: RAID0

      tags:
        Blueprint: spark-on-eks
        Environment: dev
        WorkloadType: compute-intensive
        ManagedBy: karpenter

  - name: spark-graviton-memory-optimized
    metadata:
      labels:
        blueprint: spark-on-eks
        workload-type: graviton-memory-intensive
        environment: dev
    spec:
      amiFamily: AL2023
      instanceStorePolicy: RAID0

      blockDeviceMappings:
        - deviceName: /dev/xvda
          ebs:
            volumeSize: 200Gi
            volumeType: gp3
            encrypted: true
            deleteOnTermination: true

      tags:
        Blueprint: spark-on-eks
        Environment: dev
        WorkloadType: graviton-memory-intensive
        ManagedBy: karpenter

  - name: spark-memory-optimized
    metadata:
      labels:
        blueprint: spark-on-eks
        workload-type: memory-intensive
        environment: dev
    spec:
      amiFamily: AL2023
      instanceStorePolicy: RAID0

      tags:
        Blueprint: spark-on-eks
        Environment: dev
        WorkloadType: memory-intensive
        ManagedBy: karpenter

  - name: spark-vertical-ebs-scale
    metadata:
      labels:
        blueprint: spark-on-eks
        workload-type: vertical-ebs-scale
        environment: dev
    spec:
      amiFamily: AL2023

      userData: |
        MIME-Version: 1.0
        Content-Type: multipart/mixed; boundary="//"

        --//
        Content-Type: text/x-shellscript; charset="us-ascii"

        #!/bin/bash
        echo "Running a custom user data script"
        set -ex
        yum install mdadm -y

        IDX=1
        DEVICES=$(lsblk -o NAME,TYPE -dsn | awk '/disk/ {print $1}')

        DISK_ARRAY=()

        for DEV in $DEVICES
        do
          DISK_ARRAY+=("/dev/${DEV}")
        done

        DISK_COUNT=${#DISK_ARRAY[@]}

        if [ ${DISK_COUNT} -eq 0 ]; then
          echo "No SSD disks available. Creating new EBS volume according to number of cores available in the node."
          yum install -y jq awscli
          TOKEN=$(curl -s -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 3600")

          # Get instance info
          INSTANCE_ID=$(curl -s -H "X-aws-ec2-metadata-token: $TOKEN" http://169.254.169.254/latest/meta-data/instance-id)
          AVAILABILITY_ZONE=$(curl -s -H "X-aws-ec2-metadata-token: $TOKEN" http://169.254.169.254/latest/meta-data/placement/availability-zone)
          REGION=$(curl -s -H "X-aws-ec2-metadata-token: $TOKEN" http://169.254.169.254/latest/meta-data/placement/availability-zone | sed 's/[a-z]$//')

          # Get the number of cores available
          CORES=$(nproc --all)

          # Define volume size based on the number of cores and EBS volume size per core
          VOLUME_SIZE=$(expr $CORES \* 10) # 10GB per core. Change as desired

          # Create a volume
          VOLUME_ID=$(aws ec2 create-volume --availability-zone $AVAILABILITY_ZONE --size $VOLUME_SIZE --volume-type gp3 --region $REGION --output text --query 'VolumeId')

          # Check whether the volume is available
          while [ "$(aws ec2 describe-volumes --volume-ids $VOLUME_ID --region $REGION --query "Volumes[*].State" --output text)" != "available" ]; do
            echo "Waiting for volume to become available"
            sleep 5
          done

          # Attach the volume to the instance
          aws ec2 attach-volume --volume-id $VOLUME_ID --instance-id $INSTANCE_ID --device /dev/xvdb --region $REGION

          # Update the state to delete the volume when the node is terminated
          aws ec2 modify-instance-attribute --instance-id $INSTANCE_ID --block-device-mappings "[{\"DeviceName\": \"/dev/xvdb\",\"Ebs\":{\"DeleteOnTermination\":true}}]" --region $REGION

          # Wait for the volume to be attached
          while [ "$(aws ec2 describe-volumes --volume-ids $VOLUME_ID --region $REGION --query "Volumes[*].Attachments[*].State" --output text)" != "attached" ]; do
            echo "Waiting for volume to be attached"
            sleep 5
          done

          # Format the volume
          sudo mkfs -t ext4 /dev/xvdb # Improve this to get this value dynamically
          # Create a mount point
          sudo mkdir /mnt/k8s-disks # Change directory as you like
          # Mount the volume
          sudo mount /dev/xvdb /mnt/k8s-disks
          # To mount this EBS volume on every system reboot, you need to add an entry in /etc/fstab
          echo "/dev/xvdb /mnt/k8s-disks ext4 defaults,nofail 0 2" | sudo tee -a /etc/fstab

          # Adding permissions to the mount
          /usr/bin/chown -hR +999:+1000 /mnt/k8s-disks
        else
          if [ ${DISK_COUNT} -eq 1 ]; then
            TARGET_DEV=${DISK_ARRAY[0]}
            mkfs.xfs ${TARGET_DEV}
          else
            mdadm --create --verbose /dev/md0 --level=0 --raid-devices=${DISK_COUNT} ${DISK_ARRAY[@]}
            mkfs.xfs /dev/md0
            TARGET_DEV=/dev/md0
          fi

          mkdir -p /mnt/k8s-disks
          echo ${TARGET_DEV} /mnt/k8s-disks xfs defaults,noatime 1 2 >> /etc/fstab
          mount -a
          /usr/bin/chown -hR +999:+1000 /mnt/k8s-disks
        fi

        --//--

      tags:
        Blueprint: spark-on-eks
        Environment: dev
        WorkloadType: vertical-ebs-scale
        ManagedBy: karpenter

  - name: spark-operator-benchmark
    metadata:
      labels:
        blueprint: spark-on-eks
        workload-type: benchmark
        environment: dev
    spec:
      amiFamily: AL2023

      tags:
        Blueprint: spark-on-eks
        Environment: dev
        WorkloadType: benchmark
        ManagedBy: karpenter

  - name: spark-compute-ondemand
    metadata:
      labels:
        blueprint: spark-on-eks
        workload-type: compute-ondemand
        environment: dev
    spec:
      amiFamily: AL2023
      instanceStorePolicy: RAID0

      tags:
        Blueprint: spark-on-eks
        Environment: dev
        WorkloadType: compute-ondemand
        ManagedBy: karpenter

  - name: spark-compute-spot-cmr
    metadata:
      labels:
        blueprint: spark-on-eks
        workload-type: spot-cmr
        environment: dev
    spec:
      amiFamily: AL2023
      instanceStorePolicy: RAID0

      tags:
        Blueprint: spark-on-eks
        Environment: dev
        WorkloadType: spot-cmr
        ManagedBy: karpenter

  - name: spark-compute-spot-r
    metadata:
      labels:
        blueprint: spark-on-eks
        workload-type: spot-r
        environment: dev
    spec:
      amiFamily: AL2023
      instanceStorePolicy: RAID0

      tags:
        Blueprint: spark-on-eks
        Environment: dev
        WorkloadType: spot-r
        ManagedBy: karpenter

  - name: spark-compute-graviton-od-memory
    metadata:
      labels:
        blueprint: spark-on-eks
        workload-type: graviton-od-memory
        environment: dev
    spec:
      amiFamily: AL2023
      instanceStorePolicy: RAID0

      tags:
        Blueprint: spark-on-eks
        Environment: dev
        WorkloadType: graviton-od-memory
        ManagedBy: karpenter

  - name: spark-compute-graviton
    metadata:
      labels:
        blueprint: spark-on-eks
        workload-type: graviton
        environment: dev
    spec:
      amiFamily: AL2023
      instanceStorePolicy: RAID0

      tags:
        Blueprint: spark-on-eks
        Environment: dev
        WorkloadType: graviton
        ManagedBy: karpenter

  - name: spark-compute-nitro-nvme
    metadata:
      labels:
        blueprint: spark-on-eks
        workload-type: nitro-nvme
        environment: dev
    spec:
      amiFamily: AL2023
      instanceStorePolicy: RAID0

      tags:
        Blueprint: spark-on-eks
        Environment: dev
        WorkloadType: nitro-nvme
        ManagedBy: karpenter
