# ArgoCD Application Values ConfigMap
# This ConfigMap provides centralized values for all Spark on EKS ArgoCD applications
apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-on-eks-values
  namespace: argocd
  labels:
    blueprint: spark-on-eks
    component: argocd-values
    managed-by: terraform
data:
  # Cluster configuration (populated by Terraform)
  clusterName: "{{ .Values.clusterName }}"
  clusterEndpoint: "{{ .Values.clusterEndpoint }}"
  clusterCA: "{{ .Values.clusterCA }}"
  region: "{{ .Values.region }}"
  environment: "{{ .Values.environment | default \"dev\" }}"
  
  # Karpenter configuration
  karpenterNodeInstanceProfile: "{{ .Values.karpenterNodeInstanceProfile }}"
  
  # Spark configuration
  s3BucketName: "{{ .Values.s3BucketName }}"
  sparkHistoryServerRoleArn: "{{ .Values.sparkHistoryServerRoleArn }}"
  
  # Git repository configuration
  gitRepoUrl: "{{ .Values.gitRepoUrl }}"
  gitRevision: "{{ .Values.gitRevision | default \"HEAD\" }}"
  
  # Blueprint metadata
  blueprintName: "spark-on-eks"
  blueprintVersion: "2.0"
  managedBy: "argocd"
  
  # Sync wave ordering
  syncWave:
    appOfApps: "1"
    karpenterNodePools: "2" 
    sparkOperator: "3"
    sparkHistoryServer: "4"

---
# Application ordering documentation
apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-on-eks-deployment-order
  namespace: argocd
  labels:
    blueprint: spark-on-eks
    component: documentation
data:
  deployment-order.md: |
    # Spark on EKS Deployment Order
    
    The ArgoCD applications are deployed in the following order using sync waves:
    
    1. **Wave 1**: App of Apps (`spark-app-of-apps.yaml`)
       - Bootstrap application that manages all child applications
    
    2. **Wave 2**: Karpenter NodePools (`karpenter-spark-nodepools.yaml`)
       - Deploy Spark-optimized compute and memory NodePools
       - Ensures nodes are available before workloads
    
    3. **Wave 3**: Spark Operator (`spark-operator.yaml`)
       - Deploy Spark Operator with Pod Identity integration
       - Depends on Karpenter nodes for placement
    
    4. **Wave 4**: Spark History Server (`spark-history-server.yaml`)
       - Deploy history server for Spark job monitoring
       - Depends on Spark Operator being ready
    
    ## Pod Identity Integration
    
    All components use Pod Identity instead of IRSA:
    - Karpenter: Uses Pod Identity for node management
    - Spark Operator: Uses Pod Identity for job management
    - Spark History Server: Uses Pod Identity for S3 access
    
    ## Karpenter v1.6 Features
    
    - Stable v1 API for NodePool and EC2NodeClass
    - Enhanced disruption budgets with time-based policies
    - Instance store optimization for Spark workloads
    - Multi-architecture support (AMD64/ARM64)
    - Advanced startup taints and node selectors