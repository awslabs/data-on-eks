"use strict";(self.webpackChunkdoeks_website=self.webpackChunkdoeks_website||[]).push([[8282],{5098:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>a,toc:()=>c});var r=t(5893),s=t(1151);const o={},i="Troubleshooting",a={id:"blueprints/troubleshooting/troubleshooting",title:"Troubleshooting",description:"You will find troubleshooting info for Data on Amazon EKS(DoEKS) installation issues",source:"@site/docs/blueprints/troubleshooting/troubleshooting.md",sourceDirName:"blueprints/troubleshooting",slug:"/blueprints/troubleshooting/",permalink:"/data-on-eks/docs/blueprints/troubleshooting/",draft:!1,unlisted:!1,editUrl:"https://github.com/awslabs/data-on-eks/blob/main/website/docs/blueprints/troubleshooting/troubleshooting.md",tags:[],version:"current",frontMatter:{},sidebar:"blueprints",previous:{title:"Apache Pinot",permalink:"/data-on-eks/docs/blueprints/distributed-databases/pinot"}},l={},c=[{value:"Error: local-exec provisioner error",id:"error-local-exec-provisioner-error",level:2},{value:"Issue Description:",id:"issue-description",level:3},{value:"Solution",id:"solution",level:3},{value:"Timeouts during Terraform Destroy",id:"timeouts-during-terraform-destroy",level:2},{value:"Issue Description:",id:"issue-description-1",level:3},{value:"Symptoms:",id:"symptoms",level:3},{value:"Solution:",id:"solution-1",level:3},{value:"Error: could not download chart",id:"error-could-not-download-chart",level:2},{value:"Issue Description:",id:"issue-description-2",level:3},{value:"Solution:",id:"solution-2",level:3},{value:"Terraform apply/destroy error to authenticate with EKS Cluster",id:"terraform-applydestroy-error-to-authenticate-with-eks-cluster",level:2},{value:"EMR Containers Virtual Cluster (dhwtlq9yx34duzq5q3akjac00) delete: unexpected state &#39;ARRESTED&#39;",id:"emr-containers-virtual-cluster-dhwtlq9yx34duzq5q3akjac00-delete-unexpected-state-arrested",level:2},{value:"Terminating namespace issue",id:"terminating-namespace-issue",level:2}];function u(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,s.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h1,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,r.jsx)(n.p,{children:"You will find troubleshooting info for Data on Amazon EKS(DoEKS) installation issues"}),"\n",(0,r.jsx)(n.h2,{id:"error-local-exec-provisioner-error",children:"Error: local-exec provisioner error"}),"\n",(0,r.jsx)(n.p,{children:"If you encounter the following error during the execution of the local-exec provisioner:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:'Error: local-exec provisioner error \\\nwith module.eks-blueprints.module.emr_on_eks["data_team_b"].null_resource.update_trust_policy,\\\n on .terraform/modules/eks-blueprints/modules/emr-on-eks/main.tf line 105, in resource "null_resource" \\\n "update_trust_policy":\u2502 105: provisioner "local-exec" {\u2502 \u2502 Error running command \'set -e\u2502 \u2502 aws emr-containers update-role-trust-policy \\\n \u2502 --cluster-name emr-on-eks \\\u2502 --namespace emr-data-team-b \\\u2502 --role-name emr-on-eks-emr-eks-data-team-b\n'})}),"\n",(0,r.jsx)(n.h3,{id:"issue-description",children:"Issue Description:"}),"\n",(0,r.jsx)(n.p,{children:"The error message indicates that the emr-containers command is not present in the AWS CLI version being used. This issue has been addressed and fixed in AWS CLI version 2.0.54."}),"\n",(0,r.jsx)(n.h3,{id:"solution",children:"Solution"}),"\n",(0,r.jsx)(n.p,{children:"To resolve the issue, update your AWS CLI version to 2.0.54 or a later version by executing the following command:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:"pip install --upgrade awscliv2\n"})}),"\n",(0,r.jsx)(n.p,{children:"By updating the AWS CLI version, you will ensure that the necessary emr-containers command is available and can be executed successfully during the provisioning process."}),"\n",(0,r.jsxs)(n.p,{children:["If you continue to experience any issues or require further assistance, please consult the ",(0,r.jsx)(n.a,{href:"https://github.com/aws/aws-cli/issues/6162",children:"AWS CLI GitHub issue"})," for more details or contact our support team for additional guidance."]}),"\n",(0,r.jsx)(n.h2,{id:"timeouts-during-terraform-destroy",children:"Timeouts during Terraform Destroy"}),"\n",(0,r.jsx)(n.h3,{id:"issue-description-1",children:"Issue Description:"}),"\n",(0,r.jsx)(n.p,{children:"Customers may experience timeouts during the deletion of their environments, specifically when VPCs are being deleted. This is a known issue related to the vpc-cni component."}),"\n",(0,r.jsx)(n.h3,{id:"symptoms",children:"Symptoms:"}),"\n",(0,r.jsx)(n.p,{children:"ENIs (Elastic Network Interfaces) remain attached to subnets even after the environment is destroyed.\nThe EKS managed security group associated with the ENI cannot be deleted by EKS."}),"\n",(0,r.jsx)(n.h3,{id:"solution-1",children:"Solution:"}),"\n",(0,r.jsx)(n.p,{children:"To overcome this issue, follow the recommended solution below:"}),"\n",(0,r.jsxs)(n.p,{children:["Utilize the provided ",(0,r.jsx)(n.code,{children:"cleanup.sh"})," scripts to ensure a proper cleanup of resources. Run the `cleanup.sh`` script, which is included in the blueprint.\nThis script will handle the removal of any lingering ENIs and associated security groups."]}),"\n",(0,r.jsx)(n.h2,{id:"error-could-not-download-chart",children:"Error: could not download chart"}),"\n",(0,r.jsx)(n.p,{children:"If you encounter the following error while attempting to download a chart:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:'\u2502 Error: could not download chart: failed to download "oci://public.ecr.aws/karpenter/karpenter" at version "v0.18.1"\n\u2502\n\u2502   with module.eks_blueprints_kubernetes_addons.module.karpenter[0].module.helm_addon.helm_release.addon[0],\n\u2502   on .terraform/modules/eks_blueprints_kubernetes_addons/modules/kubernetes-addons/helm-addon/main.tf line 1, in resource "helm_release" "addon":\n\u2502    1: resource "helm_release" "addon" {\n\u2502\n'})}),"\n",(0,r.jsx)(n.p,{children:"Follow the steps below to resolve the issue:"}),"\n",(0,r.jsx)(n.h3,{id:"issue-description-2",children:"Issue Description:"}),"\n",(0,r.jsx)(n.p,{children:"The error message indicates that there was a failure in downloading the specified chart. This issue can occur due to a bug in Terraform during the installation of Karpenter."}),"\n",(0,r.jsx)(n.h3,{id:"solution-2",children:"Solution:"}),"\n",(0,r.jsx)(n.p,{children:"To resolve the issue, you can try the following steps:"}),"\n",(0,r.jsx)(n.p,{children:"Authenticate with ECR: Run the following command to authenticate with the ECR (Elastic Container Registry) where the chart is located:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:"aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws\n"})}),"\n",(0,r.jsx)(n.p,{children:"Re-run terraform apply: Execute the terraform apply command again with the --auto-approve flag to reapply the Terraform configuration:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:"terraform apply --auto-approve\n"})}),"\n",(0,r.jsx)(n.p,{children:"By authenticating with ECR and re-running the terraform apply command, you will ensure that the necessary chart can be downloaded successfully during the installation process."}),"\n",(0,r.jsx)(n.h2,{id:"terraform-applydestroy-error-to-authenticate-with-eks-cluster",children:"Terraform apply/destroy error to authenticate with EKS Cluster"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'ERROR:\n\u2577\n\u2502 Error: Get "http://localhost/api/v1/namespaces/kube-system/configmaps/aws-auth": dial tcp [::1]:80: connect: connection refused\n\u2502\n\u2502   with module.eks.kubernetes_config_map_v1_data.aws_auth[0],\n\u2502   on .terraform/modules/eks/main.tf line 550, in resource "kubernetes_config_map_v1_data" "aws_auth":\n\u2502  550: resource "kubernetes_config_map_v1_data" "aws_auth" {\n\u2502\n\u2575\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Solution:"}),"\nIn this situation Terraform is unable to refresh the data resources and authenticate with EKS Cluster.\nSee the discussion ",(0,r.jsx)(n.a,{href:"https://github.com/terraform-aws-modules/terraform-aws-eks/issues/1234",children:"here"})]}),"\n",(0,r.jsx)(n.p,{children:"Try this approach first by using exec plugin."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-terraform",children:'provider "kubernetes" {\n  host                   = module.eks_blueprints.eks_cluster_endpoint\n  cluster_ca_certificate = base64decode(module.eks_blueprints.eks_cluster_certificate_authority_data)\n\n  exec {\n    api_version = "client.authentication.k8s.io/v1beta1"\n    command     = "aws"\n    args = ["eks", "get-token", "--cluster-name", module.eks_blueprints.eks_cluster_id]\n  }\n}\n\n\n'})}),"\n",(0,r.jsx)(n.p,{children:"If the issue still persists even after the above change then you can use alternative approach of using local kube config file.\nNOTE: This approach might not be ideal for production. It helps you to apply/destroy clusters with your local kube config."}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Create a local kubeconfig for your cluster"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"aws eks update-kubeconfig --name <EKS_CLUSTER_NAME> --region <CLUSTER_REGION>\n"})}),"\n",(0,r.jsxs)(n.ol,{start:"2",children:["\n",(0,r.jsxs)(n.li,{children:["Update the ",(0,r.jsx)(n.code,{children:"providers.tf"})," file with the below config by just using the config_path."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-terraform",children:'provider "kubernetes" {\n    config_path = "<HOME_PATH>/.kube/config"\n}\n\nprovider "helm" {\n    kubernetes {\n        config_path = "<HOME_PATH>/.kube/config"\n    }\n}\n\nprovider "kubectl" {\n    config_path = "<HOME_PATH>/.kube/config"\n}\n'})}),"\n",(0,r.jsx)(n.h2,{id:"emr-containers-virtual-cluster-dhwtlq9yx34duzq5q3akjac00-delete-unexpected-state-arrested",children:"EMR Containers Virtual Cluster (dhwtlq9yx34duzq5q3akjac00) delete: unexpected state 'ARRESTED'"}),"\n",(0,r.jsx)(n.p,{children:"If you encounter an error message stating \"waiting for EMR Containers Virtual Cluster (xwbc22787q6g1wscfawttzzgb) delete: unexpected state 'ARRESTED', wanted target ''. last error: %!s(nil)\", you can follow the steps below to resolve the issue:"}),"\n",(0,r.jsxs)(n.p,{children:["Note: Replace ",(0,r.jsx)(n.code,{children:"<REGION>"})," with the appropriate AWS region where the virtual cluster is located."]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Open a terminal or command prompt."}),"\n",(0,r.jsx)(n.li,{children:'Run the following command to list the virtual clusters in the "ARRESTED" state:'}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:"aws emr-containers list-virtual-clusters --region <REGION> --states ARRESTED \\\n--query 'virtualClusters[0].id' --output text\n"})}),"\n",(0,r.jsx)(n.p,{children:'This command retrieves the ID of the virtual cluster in the "ARRESTED" state.'}),"\n",(0,r.jsxs)(n.ol,{start:"3",children:["\n",(0,r.jsx)(n.li,{children:"Run the following command to delete the virtual cluster:"}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:"aws emr-containers list-virtual-clusters --region <REGION> --states ARRESTED \\\n--query 'virtualClusters[0].id' --output text | xargs -I{} aws emr-containers delete-virtual-cluster \\\n--region <REGION> --id {}\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Replace ",(0,r.jsx)(n.code,{children:"<VIRTUAL_CLUSTER_ID>"})," with the ID of the virtual cluster obtained from the previous step."]}),"\n",(0,r.jsx)(n.p,{children:'By executing these commands, you will be able to delete the virtual cluster that is in the "ARRESTED" state. This should resolve the unexpected state issue and allow you to proceed with further operations.'}),"\n",(0,r.jsx)(n.h2,{id:"terminating-namespace-issue",children:"Terminating namespace issue"}),"\n",(0,r.jsx)(n.p,{children:'If you encounter the issue where a namespace is stuck in the "Terminating" state and cannot be deleted, you can use the following command to remove the finalizers on the namespace:'}),"\n",(0,r.jsxs)(n.p,{children:["Note: Replace ",(0,r.jsx)(n.code,{children:"<namespace>"})," with the name of the namespace you want to delete."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:'NAMESPACE=<namespace>\nkubectl get namespace $NAMESPACE -o json | sed \'s/"kubernetes"//\' | kubectl replace --raw "/api/v1/namespaces/$NAMESPACE/finalize" -f -\n'})}),"\n",(0,r.jsx)(n.p,{children:'This command retrieves the namespace details in JSON format, removes the "kubernetes" finalizer, and performs a replace operation to remove the finalizer from the namespace. This should allow the namespace to complete the termination process and be successfully deleted.'}),"\n",(0,r.jsx)(n.p,{children:"Please ensure that you have the necessary permissions to perform this operation. If you continue to experience issues or require further assistance, please reach out to our support team for additional guidance and troubleshooting steps."})]})}function d(e={}){const{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(u,{...e})}):u(e)}},1151:(e,n,t)=>{t.d(n,{Z:()=>a,a:()=>i});var r=t(7294);const s={},o=r.createContext(s);function i(e){const n=r.useContext(o);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),r.createElement(o.Provider,{value:n},e.children)}}}]);