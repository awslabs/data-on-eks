"use strict";(self.webpackChunkdoeks_website=self.webpackChunkdoeks_website||[]).push([[4161],{9175:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>a,metadata:()=>c,toc:()=>r});var o=s(4848),t=s(8453);const a={title:"AWS Batch on EKS",sidebar_position:5},i="AWS Batch on EKS",c={id:"blueprints/job-schedulers/aws-batch",title:"AWS Batch on EKS",description:"AWS Batch is a fully-managed AWS-native batch computing service that plans, schedules, and runs your containerized batch workloads (machine-learning, simulation, and analytics) on top of AWS managed container orchestrations services like Amazon Elastic Kubernetes Service (EKS).",source:"@site/docs/blueprints/job-schedulers/aws-batch.md",sourceDirName:"blueprints/job-schedulers",slug:"/blueprints/job-schedulers/aws-batch",permalink:"/data-on-eks/docs/blueprints/job-schedulers/aws-batch",draft:!1,unlisted:!1,editUrl:"https://github.com/awslabs/data-on-eks/blob/main/website/docs/blueprints/job-schedulers/aws-batch.md",tags:[],version:"current",sidebarPosition:5,frontMatter:{title:"AWS Batch on EKS",sidebar_position:5},sidebar:"blueprints",previous:{title:"Argo Workflows on EKS",permalink:"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks"},next:{title:"Distributed Databases on EKS",permalink:"/data-on-eks/docs/category/distributed-databases-on-eks"}},l={},r=[{value:"Considerations",id:"considerations",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Deploy",id:"deploy",level:2},{value:"Validate",id:"validate",level:2},{value:"Run an example job on your EKS cluster using AWS Batch",id:"run-an-example-job-on-your-eks-cluster-using-aws-batch",level:2},{value:"Run <code>update-kubeconfig</code> command",id:"run-update-kubeconfig-command",level:3},{value:"List the nodes",id:"list-the-nodes",level:3},{value:"Running the &quot;Hello World!&quot; job",id:"running-the-hello-world-job",level:3},{value:"Checking the status",id:"checking-the-status",level:2},{value:"Cleaning up",id:"cleaning-up",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",div:"div",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"aws-batch-on-eks",children:"AWS Batch on EKS"})}),"\n",(0,o.jsx)(n.p,{children:"AWS Batch is a fully-managed AWS-native batch computing service that plans, schedules, and runs your containerized batch workloads (machine-learning, simulation, and analytics) on top of AWS managed container orchestrations services like Amazon Elastic Kubernetes Service (EKS)."}),"\n",(0,o.jsx)(n.p,{children:"AWS Batch adds the necessary operational semantics and resources for high performance compute workloads so that they run efficiently and cost-effectively on your existing EKS clusters."}),"\n",(0,o.jsx)(n.p,{children:"Specifically, Batch provides an always-on job queue to accept work requests. You create a an AWS Batch job definition, which is a template for a job, then submit them to the Batch job queue. Batch then takes care of provisioning nodes for your EKS cluster in a Batch-specific namespace, and places pods on these instances to run your workloads."}),"\n",(0,o.jsx)(n.p,{children:"This example provides a blueprint for standing up a complete environment for running your workloads on Amazon EKS cluster using AWS Batch, including:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"All necessary supporting infrastructure such as a VPC, IAM roles, security groups, etc."}),"\n",(0,o.jsx)(n.li,{children:"An EKS cluster for your workloads"}),"\n",(0,o.jsx)(n.li,{children:"AWS Batch resources for running jobs on EC2 On-Demand and Spot Instances."}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["You can find the blueprint ",(0,o.jsx)(n.a,{href:"https://github.com/awslabs/data-on-eks/tree/main/schedulers/terraform/aws-batch-eks",children:"here"}),"."]}),"\n",(0,o.jsx)(n.h2,{id:"considerations",children:"Considerations"}),"\n",(0,o.jsx)(n.p,{children:"AWS Batch is meant for offline analytics and data processing tasks, such as reformatting media, training ML models, batch inference, or other compute and data intensive tasks that are not interactive with a user."}),"\n",(0,o.jsxs)(n.p,{children:["In particular, Batch ",(0,o.jsx)(n.em,{children:"is tuned for running jobs that are greater than three minutes"}),". If your jobs are short (less than a minute), consider packing more work into a single AWS Batch job request to increase the total runtime of the job."]}),"\n",(0,o.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsx)(n.p,{children:"Ensure that you have the following tools installed locally:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html",children:"aws cli"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://Kubernetes.io/docs/tasks/tools/",children:"kubectl"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://learn.hashicorp.com/tutorials/terraform/install-cli",children:"terraform"})}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"deploy",children:"Deploy"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"To provision this example:"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["Clone the repository to your local machine.","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"git clone https://github.com/awslabs/data-on-eks.git\ncd data-on-eks/schedulers/terraform/aws-batch\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["Run the install script.","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"/bin/sh install.sh\n"})}),"\n","Enter region at command prompt to continue."]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"The script will run Terraform to stand up all of the resources. Once done, you will see terraform output like below."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"terraform output",src:s(2730).A+"",width:"1262",height:"270"})}),"\n",(0,o.jsx)(n.p,{children:"The following components are provisioned in your environment:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"A sample VPC, with 2 Private Subnets and 2 Public Subnets"}),"\n",(0,o.jsx)(n.li,{children:"Internet gateway for Public Subnets and NAT Gateway for Private Subnets"}),"\n",(0,o.jsx)(n.li,{children:"EKS Cluster Control plane with one managed node group."}),"\n",(0,o.jsx)(n.li,{children:"EKS Managed Add-ons: VPC_CNI, CoreDNS, EBS_CSI_Driver, CloudWatch"}),"\n",(0,o.jsxs)(n.li,{children:["AWS Batch resources including","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"An On-Demand compute environment and job queue"}),"\n",(0,o.jsx)(n.li,{children:"A Spot compute environment and job queue"}),"\n",(0,o.jsxs)(n.li,{children:["An example Batch job definition to run ",(0,o.jsx)(n.code,{children:'echo "hello world!"'})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"validate",children:"Validate"}),"\n",(0,o.jsx)(n.h2,{id:"run-an-example-job-on-your-eks-cluster-using-aws-batch",children:"Run an example job on your EKS cluster using AWS Batch"}),"\n",(0,o.jsxs)(n.p,{children:["The following command will update the ",(0,o.jsx)(n.code,{children:"kubeconfig"})," on your local machine and allow you to interact with your EKS Cluster using ",(0,o.jsx)(n.code,{children:"kubectl"})," to validate the deployment."]}),"\n",(0,o.jsxs)(n.h3,{id:"run-update-kubeconfig-command",children:["Run ",(0,o.jsx)(n.code,{children:"update-kubeconfig"})," command"]}),"\n",(0,o.jsxs)(n.p,{children:["Run the command from the ",(0,o.jsx)(n.code,{children:"configure_kubectl_cmd"})," output value from ",(0,o.jsx)(n.code,{children:"terraform apply"}),". If you do not have this available, you can get the terraform stack output values using the ",(0,o.jsx)(n.code,{children:"terraform output"})," command."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"# DO NOT COPY THIS! This is only an example, see above for what to run.\naws eks --region us-east-1 update-kubeconfig --name doeks-batch\n"})}),"\n",(0,o.jsx)(n.h3,{id:"list-the-nodes",children:"List the nodes"}),"\n",(0,o.jsxs)(n.p,{children:["Once ",(0,o.jsx)(n.code,{children:"kubectl"})," is configured, you can use it to inspect the cluster nodes and namespaces. To get the node information, run the following command."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"kubectl get nodes\n"})}),"\n",(0,o.jsx)(n.p,{children:"The output should look like the following."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"NAME                           STATUS   ROLES    AGE    VERSION\nip-10-1-107-168.ec2.internal   Ready    <none>   3m7s   v1.30.2-eks-1552ad0\nip-10-1-141-25.ec2.internal    Ready    <none>   3m7s   v1.30.2-eks-1552ad0\n"})}),"\n",(0,o.jsx)(n.p,{children:"To get the created namespaces of the cluster, run the following command."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"kubectl get ns\n"})}),"\n",(0,o.jsx)(n.p,{children:"The output should look like the following."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"NAME                STATUS   AGE\namazon-cloudwatch   Active   2m22s\ndefault             Active   10m\ndoeks-aws-batch     Active   103s\nkube-node-lease     Active   10m\nkube-public         Active   10m\nkube-system         Active   10m\n"})}),"\n",(0,o.jsxs)(n.p,{children:["The namespace ",(0,o.jsx)(n.code,{children:"doeks-aws-batch"})," will be used by Batch to add Batch-managed EC2 instances for nodes and run jobs on these nodes."]}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsxs)(n.p,{children:["The AWS Batch kubernetes namespace is configurable as an input variable to terraform. If you chose to change it in the ",(0,o.jsx)(n.code,{children:"variables.tf"})," file, then you will need to adjust later commands to account for the change."]})}),"\n",(0,o.jsx)(n.h3,{id:"running-the-hello-world-job",children:'Running the "Hello World!" job'}),"\n",(0,o.jsxs)(n.p,{children:["The output of ",(0,o.jsx)(n.code,{children:"terraform apply"})," contained the AWS CLI command to run the example ",(0,o.jsx)(n.strong,{children:"Hello World!"})," job definition on both the On-Demand and Spot job queues. You can view these commands again using ",(0,o.jsx)(n.code,{children:"terraform output"}),"."]}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"To run the example job definition on the On-Demand resources:"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["Run the provided command from the terraform output ",(0,o.jsx)(n.code,{children:"run_example_aws_batch_job"}),". It should look something like:","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"JOB_ID=$(aws batch --region us-east-1  submit-job --job-definition arn:aws:batch:us-east-1:653295002771:job-definition/doeks-hello-world:2 --job-queue doeks-JQ1_OD --job-name doeks_hello_example --output text --query jobId) && echo $JOB_ID\n## Output should be the Batch job ID\nbe1f781d-753e-4d10-a7d4-1b6de68574fc\n"})}),"\n","The response will populate the ",(0,o.jsx)(n.code,{children:"JOB_ID"})," shell variable, which you can use in later steps."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"checking-the-status",children:"Checking the status"}),"\n",(0,o.jsx)(n.p,{children:"You can use the AWS CLI to check the status of the job from the AWS Batch API:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:'aws batch --no-cli-pager \\\ndescribe-jobs --jobs $JOB_ID --query "jobs[].[jobId,status]"\n'})}),"\n",(0,o.jsx)(n.p,{children:"This will output something like the following:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'[\n    [\n        "a13e1cff-121c-4a0b-a9c5-fab953136e20",\n        "RUNNABLE"\n    ]\n]\n'})}),"\n",(0,o.jsxs)(n.div,{children:[(0,o.jsxs)(n.p,{children:["If you see an empty result, it is likely that you are using a different default AWS Region than the one that was deployed to. Adjust the value of your default Region by setting the ",(0,o.jsx)(n.code,{children:"AWS_DEFAULT_REGION"})," shell variable."]}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"export AWS_DEFAULT_REGION=us-east-1\n"})})]}),"\n",(0,o.jsxs)(n.p,{children:["We can monitor the status of Nodes and Pods that Batch manages using ",(0,o.jsx)(n.code,{children:"kubectl"}),". First, let's track the nodes as they launch and join the cluster:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"kubectl get nodes -w\n"})}),"\n",(0,o.jsx)(n.p,{children:"This will continuously monitor the state of EKS Nodes, and periodically output their ready state."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"NAME                           STATUS   ROLES    AGE   VERSION\nip-10-1-107-168.ec2.internal   Ready    <none>   12m   v1.30.2-eks-1552ad0\nip-10-1-141-25.ec2.internal    Ready    <none>   12m   v1.30.2-eks-1552ad0\nip-10-1-60-65.ec2.internal     NotReady   <none>   0s    v1.30.2-eks-1552ad0\nip-10-1-60-65.ec2.internal     NotReady   <none>   0s    v1.30.2-eks-1552ad0\nip-10-1-60-65.ec2.internal     NotReady   <none>   0s    v1.30.2-eks-1552ad0\n# ... more lines\n"})}),"\n",(0,o.jsxs)(n.p,{children:["When the new Batch-managed nodes are launching (new nodes with ",(0,o.jsx)(n.strong,{children:"NotReady"})," status), you can press the ",(0,o.jsx)(n.code,{children:"Control-c"})," key combination to exit the watch process. This will allow you to monitor the state of pods launching in the AWS Batch namespace:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"kubectl get pods -n doeks-aws-batch -w\n"})}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsxs)(n.p,{children:["The AWS Batch kubernetes namespace is configurable as an input variable to terraform. If you chose to change it in the ",(0,o.jsx)(n.code,{children:"variables.tf"})," file, then you will need to adjust the previous command to account for the change."]})}),"\n",(0,o.jsx)(n.p,{children:"This will continuously monitor the state of the Pods that Batch places on the cluster, and periodically output their state."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"NAME                                             READY   STATUS    RESTARTS   AGE\naws-batch.32d8f53f-29dc-31b4-9ce4-13504ccf74c1   0/1     Pending   0          0s\naws-batch.32d8f53f-29dc-31b4-9ce4-13504ccf74c1   0/1     ContainerCreating   0          0s\naws-batch.32d8f53f-29dc-31b4-9ce4-13504ccf74c1   1/1     Running             0          17s\naws-batch.32d8f53f-29dc-31b4-9ce4-13504ccf74c1   0/1     Completed           0          52s\naws-batch.32d8f53f-29dc-31b4-9ce4-13504ccf74c1   0/1     Completed           0          53s\naws-batch.32d8f53f-29dc-31b4-9ce4-13504ccf74c1   0/1     Terminating         0          53s\naws-batch.32d8f53f-29dc-31b4-9ce4-13504ccf74c1   0/1     Terminating         0          53s\n"})}),"\n",(0,o.jsxs)(n.p,{children:["Once the Pods are ",(0,o.jsx)(n.strong,{children:"Terminating"}),", you can exit the watch process by hitting the ",(0,o.jsx)(n.code,{children:"Control-c"})," key combination. To view the status of the job from AWS Batch, use to following command:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:'aws batch --no-cli-pager \\\ndescribe-jobs --jobs $JOB_ID --query "jobs[].[jobId,status]"\n'})}),"\n",(0,o.jsxs)(n.p,{children:["This will show the job ID and the status, which should be ",(0,o.jsx)(n.code,{children:"SUCCEEDED"}),"."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'[\n    [\n        "a13e1cff-121c-4a0b-a9c5-fab953136e20",\n        "SUCCEEDED"\n    ]\n]\n'})}),"\n",(0,o.jsxs)(n.p,{children:["To find the application container logs in the CloudWatch Log Groups management console, we will need the application container's Pod name. The ",(0,o.jsx)(n.code,{children:"kubestl get pods"})," output did not give us a good way to determine which of those Pods was the one with the application container.  Also, once Pods are terminated, the Kubernetes scheduler can no longer provide any information on the job's nodes or Pods. Good thing that AWS Batch keeps a record of the job!"]}),"\n",(0,o.jsxs)(n.p,{children:["We can use AWS Batch's API to query for the main node's ",(0,o.jsx)(n.code,{children:"podName"})," and other information. To get information on a specific node from an MNP job, you suffix the job ID with the pattern ",(0,o.jsx)(n.code,{children:'"#<NODE_INDEX>"'}),". For the main node, which we defined as index ",(0,o.jsx)(n.code,{children:'"0"'})," in our job definition, that would translate to the following AWS CLI command:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:'aws batch describe-jobs --jobs "$JOB_ID" --query "jobs[].eksAttempts[].{nodeName: nodeName, podName: podName}"\n'})}),"\n",(0,o.jsx)(n.p,{children:"The output should be similar to the following."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:'[\n    {\n        "nodeName": "ip-10-1-60-65.ec2.internal",\n        "podName": "aws-batch.32d8f53f-29dc-31b4-9ce4-13504ccf74c1"\n    }\n]\n'})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"To view the application container logs:"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["Navigate to the ",(0,o.jsx)(n.a,{href:"https://console.aws.amazon.com/cloudwatch/home?#logsV2:log-groups$3FlogGroupNameFilter$3Ddoeks-batch",children:"Amazon CloudWatch management console Log Groups panel"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["In the ",(0,o.jsx)(n.strong,{children:"Log groups"})," listing table, choose the application logs for your cluster. These are identified by your cluster's name, and the suffix ",(0,o.jsx)(n.code,{children:"application"}),".\n",(0,o.jsx)(n.img,{alt:"CloudWatch management console, showing the location of the application logs.",src:s(4996).A+"",width:"932",height:"406"})]}),"\n",(0,o.jsxs)(n.li,{children:["In the ",(0,o.jsx)(n.strong,{children:"Log streams"})," listing table, enter the value for ",(0,o.jsx)(n.code,{children:"podName"})," from the previous step. This will highlight two logs for the two containers in the Pod. Choose the log stream for the ",(0,o.jsx)(n.code,{children:"application"})," container.\n",(0,o.jsx)(n.img,{alt:"CloudWatch log stream panel showing the filtered set using the pod name.",src:s(1980).A+"",width:"1151",height:"293"})]}),"\n",(0,o.jsxs)(n.li,{children:["In the ",(0,o.jsx)(n.strong,{children:"Log events"})," section, in the filter bar, choose ",(0,o.jsx)(n.strong,{children:"Display"}),' then choose **View in plain text". You should see the log messages "Hello World!" in the ',(0,o.jsx)(n.code,{children:'"log"'})," property of the log event."]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"cleaning-up",children:"Cleaning up"}),"\n",(0,o.jsxs)(n.p,{children:["To clean up your environment\u2014remove all AWS Batch resources and kubernetes constructs from your cluster\u2014run the ",(0,o.jsx)(n.code,{children:"cleanup.sh"})," script."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"chmod +x cleanup.sh\n./cleanup.sh\n"})}),"\n",(0,o.jsxs)(n.p,{children:["To avoid data charges from CloudWatch logs, you should also delete the log groups from your cluster. You can find these by navigating to the ",(0,o.jsxs)(n.a,{href:"https://console.aws.amazon.com/cloudwatch/home?#logsV2:log-groups$3FlogGroupNameFilter$3Ddoeks-batch",children:[(0,o.jsx)(n.strong,{children:"Log groups"})," page of the CloudWatch management console"]}),"."]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},4996:(e,n,s)=>{s.d(n,{A:()=>o});const o=s.p+"assets/images/cw-logs-1-0b2871cd1d41c4c0b4d9ba48380e7264.png"},1980:(e,n,s)=>{s.d(n,{A:()=>o});const o=s.p+"assets/images/cw-logs-2-e2fc658655fed80bc603f34d0a7cde09.png"},2730:(e,n,s)=>{s.d(n,{A:()=>o});const o=s.p+"assets/images/tf-apply-output-2840b7d1411f1d192f5e67d6250b5ee4.png"},8453:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>c});var o=s(6540);const t={},a=o.createContext(t);function i(e){const n=o.useContext(a);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),o.createElement(a.Provider,{value:n},e.children)}}}]);