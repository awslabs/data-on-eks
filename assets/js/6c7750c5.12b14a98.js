"use strict";(self.webpackChunkdoeks_website=self.webpackChunkdoeks_website||[]).push([["9595"],{32203:function(e,n,r){r.r(n),r.d(n,{frontMatter:()=>a,default:()=>h,toc:()=>l,metadata:()=>s,assets:()=>c,contentTitle:()=>i});var s=JSON.parse('{"id":"benchmarks/spark-operator-eks-benchmark","title":"Kubeflow Spark Operator Benchmarks \uD83D\uDE80","description":"This document serves as a comprehensive guide for conducting a scale test for the Kubeflow Spark Operator on Amazon EKS. The primary objective is to evaluate the performance, scalability, and stability of the Spark Operator under heavy workloads by submitting thousands of jobs and analyzing its behavior under stress.","source":"@site/docs/benchmarks/spark-operator-eks-benchmark.md","sourceDirName":"benchmarks","slug":"/benchmarks/spark-operator-eks-benchmark","permalink":"/data-on-eks/docs/benchmarks/spark-operator-eks-benchmark","draft":false,"unlisted":false,"editUrl":"https://github.com/awslabs/data-on-eks/blob/main/website/docs/benchmarks/spark-operator-eks-benchmark.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"sidebar_label":"Kubeflow Spark Operator Benchmarks"},"sidebar":"benchmarks","previous":{"title":"Gravtion R-series Results","permalink":"/data-on-eks/docs/benchmarks/spark-operator-benchmark/graviton-r-data"}}'),t=r(85893),o=r(50065);let a={sidebar_position:3,sidebar_label:"Kubeflow Spark Operator Benchmarks"},i="Kubeflow Spark Operator Benchmarks \uD83D\uDE80",c={},l=[{value:"\u2728 Why We Need the Benchmark Tests",id:"-why-we-need-the-benchmark-tests",level:3},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Updates to the Cluster",id:"updates-to-the-cluster",level:3},{value:"Load Test Configuration and Execution",id:"load-test-configuration-and-execution",level:3},{value:"Results Verification",id:"results-verification",level:3},{value:"Summary of Results",id:"summary-of-results",level:2},{value:"Cleanup",id:"cleanup",level:2}];function d(e){let n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"kubeflow-spark-operator-benchmarks-",children:"Kubeflow Spark Operator Benchmarks \uD83D\uDE80"})}),"\n",(0,t.jsx)(n.p,{children:"This document serves as a comprehensive guide for conducting a scale test for the Kubeflow Spark Operator on Amazon EKS. The primary objective is to evaluate the performance, scalability, and stability of the Spark Operator under heavy workloads by submitting thousands of jobs and analyzing its behavior under stress."}),"\n",(0,t.jsx)(n.p,{children:"This guide provides a step-by-step approach to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Steps to ",(0,t.jsx)(n.strong,{children:"configure the Spark Operator"})," for high-scale job submissions."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Infrastructure setup"})," modifications for performance optimization."]}),"\n",(0,t.jsxs)(n.li,{children:["Load testing execution details using ",(0,t.jsx)(n.strong,{children:"Locust"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Grafana dashboard"})," for monitoring Spark Operator metrics and Kubernetes metrics"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"-why-we-need-the-benchmark-tests",children:"\u2728 Why We Need the Benchmark Tests"}),"\n",(0,t.jsx)(n.p,{children:"Benchmark testing is a critical step in assessing the efficiency and reliability of the Spark Operator when handling large-scale job submissions. These tests provide valuable insights into:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Identifying performance bottlenecks:"}),"  Pinpointing areas where the system struggles under heavy loads."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Ensuring optimized resource utilization:"})," Ensuring that CPU, memory, and other resources are used efficiently."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Evaluating system stability under heavy workloads:"})," Testing the system\u2019s ability to maintain performance and reliability under extreme conditions."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"By conducting these tests, you can ensure that the Spark Operator is capable of handling real-world, high-demand scenarios effectively."}),"\n",(0,t.jsx)(n.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Before running the benchmark tests, ensure you have deployed the ",(0,t.jsx)(n.strong,{children:"Spark Operator"})," EKS cluster by following the instructions ",(0,t.jsx)(n.a,{href:"https://awslabs.github.io/data-on-eks/docs/blueprints/data-analytics/spark-operator-yunikorn#deploy",children:"here"}),"."]}),"\n",(0,t.jsx)(n.li,{children:"Access to the necessary AWS resources and permissions to modify EKS configurations."}),"\n",(0,t.jsxs)(n.li,{children:["Familiarity with ",(0,t.jsx)(n.strong,{children:"Terraform"}),", ",(0,t.jsx)(n.strong,{children:"Kubernetes"}),", and ",(0,t.jsx)(n.strong,{children:"Locust"})," for load testing."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"updates-to-the-cluster",children:"Updates to the Cluster"}),"\n",(0,t.jsx)(n.p,{children:"To prepare the cluster for benchmark testing, apply the following modifications:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Step 1: Update Spark Operator Helm Configuration"})}),"\n",(0,t.jsxs)(n.p,{children:["Uncomment the specified Spark Operator Helm values in the file ",(0,t.jsx)(n.a,{href:"https://github.com/awslabs/data-on-eks/blob/main/analytics/terraform/spark-k8s-operator/addons.tf",children:"analytics/terraform/spark-k8s-operator/addons.tf"})," (from the ",(0,t.jsx)(n.code,{children:"-- Start"})," to ",(0,t.jsx)(n.code,{children:"-- End"})," section). Then, run terraform apply to apply the changes."]}),"\n",(0,t.jsx)(n.p,{children:"These updates ensure that:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["The Spark Operator and webhook pods are deployed on a dedicated ",(0,t.jsx)(n.code,{children:"c5.9xlarge"})," instance using Karpenter."]}),"\n",(0,t.jsxs)(n.li,{children:["The instance provides ",(0,t.jsx)(n.code,{children:"36 vCPUs"})," to handle ",(0,t.jsx)(n.code,{children:"6000"})," application submissions."]}),"\n",(0,t.jsx)(n.li,{children:"High CPU and memory resources are allocated for both the Controller pod and Webhook pods."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Here\u2019s the updated configuration:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'enable_spark_operator = true\n  spark_operator_helm_config = {\n    version = "2.1.0"\n    timeout = "120"\n    values = [\n      <<-EOT\n        controller:\n          replicas: 1\n          # -- Reconcile concurrency, higher values might increase memory usage.\n          # -- Increased from 10 to 20 to leverage more cores from the instance\n          workers: 20\n          # -- Change this to True when YuniKorn is deployed\n          batchScheduler:\n            enable: false\n            # default: "yunikorn"\n#  -- Start: Uncomment this section in the code for Spark Operator scale test\n          # -- Spark Operator is CPU bound so add more CPU or use compute optimized instance for handling large number of job submissions\n          nodeSelector:\n            NodeGroupType: spark-operator-benchmark\n          resources:\n            requests:\n              cpu: 33000m\n              memory: 50Gi\n        webhook:\n          nodeSelector:\n            NodeGroupType: spark-operator-benchmark\n          resources:\n            requests:\n              cpu: 1000m\n              memory: 10Gi\n#  -- End: Uncomment this section in the code for Spark Operator scale test\n        spark:\n          jobNamespaces:\n            - default\n            - spark-team-a\n            - spark-team-b\n            - spark-team-c\n          serviceAccount:\n            create: false\n          rbac:\n            create: false\n        prometheus:\n          metrics:\n            enable: true\n            port: 8080\n            portName: metrics\n            endpoint: /metrics\n            prefix: ""\n          podMonitor:\n            create: true\n            labels: {}\n            jobLabel: spark-operator-podmonitor\n            podMetricsEndpoint:\n              scheme: http\n              interval: 5s\n      EOT\n    ]\n  }\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Step 2: Prometheus Best practices for Large scale clusters"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"To efficiently monitor 32,000+ pods across 200 nodes, Prometheus should run on a dedicated node with increased CPU and memory allocation. Ensure Prometheus is deployed on core node groups using NodeSelectors in the Prometheus Helm chart. This prevents interference from workload pods."}),"\n",(0,t.jsxs)(n.li,{children:["At scale, ",(0,t.jsx)(n.strong,{children:"Prometheus"})," can consume significant CPU and memory, so running it on dedicated infrastructure ensures it doesn\u2019t compete with your apps. It\u2019s common to dedicate a node or node pool solely to monitoring components (Prometheus, Grafana, etc.) using node selectors or taints."]}),"\n",(0,t.jsx)(n.li,{children:"Prometheus is memory-intensive and, when monitoring hundreds or thousands of pods, will also demand substantial CPU\u200B"}),"\n",(0,t.jsx)(n.li,{children:"Allocating dedicated resources (and even using Kubernetes priority classes or QoS to favor Prometheus) helps keep your monitoring reliable under stress."}),"\n",(0,t.jsx)(n.li,{children:"Please note that full observability stack (metrics, logs, tracing) might consume roughly one-third of your infrastructure resources at scale\u200B, so plan capacity accordingly."}),"\n",(0,t.jsxs)(n.li,{children:["Allocate ample memory and CPU from the start, and prefer requests without strict low limits for Prometheus. For example, if you estimate Prometheus needs ",(0,t.jsx)(n.code,{children:"~8\xa0GB"}),", don\u2019t cap it at ",(0,t.jsx)(n.code,{children:"4\xa0GB"}),". It\u2019s better to reserve an entire node or a large chunk of one for Prometheus."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Step 3: Configure VPC CNI for High Pod Density:"})}),"\n",(0,t.jsxs)(n.p,{children:["Modify ",(0,t.jsx)(n.a,{href:"https://github.com/awslabs/data-on-eks/blob/main/analytics/terraform/spark-k8s-operator/eks.tf",children:"analytics/terraform/spark-k8s-operator/eks.tf"})," to enable ",(0,t.jsx)(n.code,{children:"prefix delegation"})," in the ",(0,t.jsx)(n.code,{children:"vpc-cni"})," addon. This increases the pod capacity per node from ",(0,t.jsx)(n.code,{children:"110 to 200"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-hcl",children:'cluster_addons = {\n  vpc-cni = {\n    configuration_values = jsonencode({\n      env = {\n        ENABLE_PREFIX_DELEGATION = "true"\n        WARM_PREFIX_TARGET       = "1"\n      }\n    })\n  }\n}\n'})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Important Note:"})," After making these changes, run ",(0,t.jsx)(n.code,{children:"terraform apply"})," to update the VPC CNI configuration."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Step 4: Create a Dedicated Node Group for Spark Load Testing"})}),"\n",(0,t.jsxs)(n.p,{children:["We have created a dedicated Managed node group called ",(0,t.jsx)(n.strong,{children:"spark_operator_bench"})," for placing the Spark Jobs pods. Configured a ",(0,t.jsx)(n.code,{children:"200-node"})," managed node group with ",(0,t.jsx)(n.code,{children:"m6a.4xlarge"})," instances for Spark load test pods. The user-data has been modified to allow up to ",(0,t.jsx)(n.code,{children:"220 pods per node"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Note:"})," This step is informational only, and no changes need to be applied manually."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-hcl",children:'spark_operator_bench = {\n  name        = "spark_operator_bench"\n  description = "Managed node group for Spark Operator Benchmarks with EBS using x86 or ARM"\n\n  min_size     = 0\n  max_size     = 200\n  desired_size = 0\n  ...\n\n  cloudinit_pre_nodeadm = [\n    {\n      content_type = "application/node.eks.aws"\n      content      = <<-EOT\n        ---\n        apiVersion: node.eks.aws/v1alpha1\n        kind: NodeConfig\n        spec:\n          kubelet:\n            config:\n              maxPods: 220\n      EOT\n    }\n  ]\n...\n\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Step 5: Manually Update Node Group Min Size to 200"})}),"\n",(0,t.jsx)(n.admonition,{type:"caution",children:(0,t.jsx)(n.p,{children:"Running 200 nodes can incur significant costs. If you plan to run this test independently, carefully estimate the expenses in advance to ensure budget feasibility."})}),"\n",(0,t.jsxs)(n.p,{children:["Initially, set ",(0,t.jsx)(n.code,{children:"min_size = 0"}),". Before starting the load test, update ",(0,t.jsx)(n.code,{children:"min_size"})," and ",(0,t.jsx)(n.code,{children:"desired_size"})," to ",(0,t.jsx)(n.code,{children:"200"})," in the AWS console. This pre-creates all nodes required for the load test, ensuring all DaemonSets are running."]}),"\n",(0,t.jsx)(n.h3,{id:"load-test-configuration-and-execution",children:"Load Test Configuration and Execution"}),"\n",(0,t.jsxs)(n.p,{children:["To simulate high-scale concurrent job submissions, we developed ",(0,t.jsx)(n.strong,{children:"Locust"})," scripts that dynamically create Spark Operator templates and submit jobs concurrently by simulating multiple users."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 1: Set Up a Python Virtual Environment"}),"\nOn your local machine (Mac or desktop), create a Python virtual environment and install the required dependencies:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"cd analytics/terraform/spark-k8s-operator/examples/benchmark/spark-operator-benchmark-kit\npython3.12 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 2: Run the Load Test"}),"\nExecute the following command to start the load test:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"locust --headless --only-summary -u 3 -r 1 \\\n--job-limit-per-user 2000 \\\n--jobs-per-min 1000 \\\n--spark-namespaces spark-team-a,spark-team-b,spark-team-c\n"})}),"\n",(0,t.jsx)(n.p,{children:"This command:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Starts a test with ",(0,t.jsx)(n.strong,{children:"3 concurrent users"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Each user submits ",(0,t.jsx)(n.strong,{children:"2000 jobs"})," at a rate of ",(0,t.jsx)(n.strong,{children:"1000 jobs per minute"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Total of ",(0,t.jsx)(n.strong,{children:"6000 jobs"})," are submitted by this command. Each Spark job consists of ",(0,t.jsx)(n.strong,{children:"6 pods"})," (1 Driver and 5 executor pods)"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Generates ",(0,t.jsx)(n.strong,{children:"36,000 pods"})," across ",(0,t.jsx)(n.strong,{children:"200 nodes"})," using ",(0,t.jsx)(n.strong,{children:"3 namespaces"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Locust script uses the Spark job template located at: ",(0,t.jsx)(n.code,{children:"analytics/terraform/spark-k8s-operator/examples/benchmark/spark-operator-benchmark-kit/spark-app-with-webhook.yaml"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Spark job uses a simple ",(0,t.jsx)(n.code,{children:"spark-pi-sleep.jar"})," that sleeps for a specified duration. The testing image is available at: ",(0,t.jsx)(n.code,{children:"public.ecr.aws/data-on-eks/spark:pi-sleep-v0.0.2"})]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"results-verification",children:"Results Verification"}),"\n",(0,t.jsx)(n.p,{children:"The load test runs for approximately 1 hour. During this time, you can monitor the Spark Operator metrics, cluster performance and resource utilization using Grafana. Follow the steps below to access the monitoring dashboard:"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step1: Port-forward Grafana Service"}),"\nRun the following command to create a local port-forward, making Grafana accessible from your local machine:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"kubectl port-forward svc/kube-prometheus-stack-grafana 3000:80 -n kube-prometheus-stack\n"})}),"\n",(0,t.jsx)(n.p,{children:"This maps port 3000 on your local system to Grafana's service inside the cluster."}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step2: Access Grafana"}),"\nTo log into Grafana, retrieve the secret name storing the admin credentials:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"terraform output grafana_secret_name\n"})}),"\n",(0,t.jsx)(n.p,{children:"Then, use the retrieved secret name to fetch credentials from AWS Secrets Manager:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'aws secretsmanager get-secret-value --secret-id <grafana_secret_name_output> --region $AWS_REGION --query "SecretString" --output text\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Step 3: Access Grafana Dashboard"})}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Open a web browser and navigate to ",(0,t.jsx)(n.a,{href:"http://localhost:3000",children:"http://localhost:3000"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:["Enter username as ",(0,t.jsx)(n.code,{children:"admin"})," and password as the retrieved password from the previous command."]}),"\n",(0,t.jsx)(n.li,{children:"Navigate to the Spark Operator Load Test Dashboard to visualize:"}),"\n"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"The number of Spark jobs submitted."}),"\n",(0,t.jsx)(n.li,{children:"Cluster-wide CPU and memory consumption."}),"\n",(0,t.jsx)(n.li,{children:"Pod scaling behavior and resource allocation."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"summary-of-results",children:"Summary of Results"}),"\n",(0,t.jsx)(n.admonition,{type:"tip",children:(0,t.jsxs)(n.p,{children:["For a detailed analysis, refer to the ",(0,t.jsx)(n.a,{href:"https://www.kubeflow.org/docs/components/spark-operator/overview/",children:"Kubeflow Spark Operator Website"})]})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"CPU Utilization:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"The Spark Operator controller pod is CPU-bound, utilizing all 36 cores during peak processing."}),"\n",(0,t.jsx)(n.li,{children:"CPU constraints limit job processing speed, making compute power a key factor for scalability."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Memory Usage:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Memory consumption remains stable, regardless of the number of applications processed."}),"\n",(0,t.jsx)(n.li,{children:"This indicates that memory is not a bottleneck, and increasing RAM would not improve performance."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Job Processing Rate:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"The Spark Operator processes applications at ~130 apps per minute."}),"\n",(0,t.jsx)(n.li,{children:"The processing rate is capped by CPU limitations, preventing further scaling without additional compute resources."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Time to Process Jobs:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"~15 minutes to process 2,000 applications."}),"\n",(0,t.jsx)(n.li,{children:"~30 minutes to process 4,000 applications."}),"\n",(0,t.jsx)(n.li,{children:"These numbers align with the observed 130 apps per minute processing rate."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Work Queue Duration Metric Reliability:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"The default work queue duration metric becomes unreliable once it exceeds 16 minutes."}),"\n",(0,t.jsx)(n.li,{children:"Under high concurrency, this metric fails to provide accurate insights into queue processing times."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"API Server Performance Impact:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Kubernetes API request duration increases significantly under high workload conditions."}),"\n",(0,t.jsx)(n.li,{children:"This is caused by Spark querying executor pods frequently, not a limitation of the Spark Operator itself."}),"\n",(0,t.jsx)(n.li,{children:"The increased API server load affects job submission latency and monitoring performance across the cluster."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"cleanup",children:"Cleanup"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Step 1: Scale Down Node Group"})}),"\n",(0,t.jsxs)(n.p,{children:["To avoid unnecessary costs, first scale down the ",(0,t.jsx)(n.strong,{children:"spark_operator_bench"})," node group by setting its minimum and desired node count to zero:"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Log in to the AWS Console."}),"\n",(0,t.jsx)(n.li,{children:"Navigate to the EKS section."}),"\n",(0,t.jsxs)(n.li,{children:["Locate and select the ",(0,t.jsx)(n.strong,{children:"spark_operator_bench"})," node group."]}),"\n",(0,t.jsx)(n.li,{children:"Edit the node group and update the Min Size and Desired Size to 0."}),"\n",(0,t.jsx)(n.li,{children:"Save the changes to scale down the nodes."}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 2: Destroy the Cluster"}),"\nOnce the nodes have been scaled down, you can proceed with cluster teardown using the following script:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"cd ${DOEKS_HOME}/analytics/terraform/spark-k8s-operator && chmod +x cleanup.sh\n./cleanup.sh\n"})})]})}function h(e={}){let{wrapper:n}={...(0,o.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},50065:function(e,n,r){r.d(n,{Z:()=>i,a:()=>a});var s=r(67294);let t={},o=s.createContext(t);function a(e){let n=s.useContext(o);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);