"use strict";(self.webpackChunkdoeks_website=self.webpackChunkdoeks_website||[]).push([[2337],{6336:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>h,frontMatter:()=>o,metadata:()=>l,toc:()=>d});var a=n(4848),r=n(8453),s=(n(1470),n(9365),n(2450));const o={sidebar_position:2,sidebar_label:"Data Generation"},i="Data Generation for Running Spark Benchmark Tests on Amazon EKS",l={id:"benchmarks/spark-operator-benchmark/data-generation",title:"Data Generation for Running Spark Benchmark Tests on Amazon EKS",description:"The following guide provides instructions on how to generate the data set for running the TPCDS benchmark tests for Spark.",source:"@site/docs/benchmarks/spark-operator-benchmark/data-generation.md",sourceDirName:"benchmarks/spark-operator-benchmark",slug:"/benchmarks/spark-operator-benchmark/data-generation",permalink:"/data-on-eks/docs/benchmarks/spark-operator-benchmark/data-generation",draft:!1,unlisted:!1,editUrl:"https://github.com/awslabs/data-on-eks/blob/main/website/docs/benchmarks/spark-operator-benchmark/data-generation.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2,sidebar_label:"Data Generation"},sidebar:"benchmarks",previous:{title:"Introduction to Spark Benchmarks",permalink:"/data-on-eks/docs/benchmarks/spark-operator-benchmark/spark-operator-eks-benchmark"}},c={},d=[{value:"Deploying the data generation toolkit",id:"deploying-the-data-generation-toolkit",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Deploy",id:"deploy",level:3},{value:"Generating Test Dataset for Running the TPCDS Benchmark",id:"generating-test-dataset-for-running-the-tpcds-benchmark",level:2},{value:"Cost Considerations",id:"cost-considerations",level:2}];function u(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",span:"span",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"data-generation-for-running-spark-benchmark-tests-on-amazon-eks",children:"Data Generation for Running Spark Benchmark Tests on Amazon EKS"})}),"\n",(0,a.jsx)(t.p,{children:"The following guide provides instructions on how to generate the data set for running the TPCDS benchmark tests for Spark."}),"\n",(0,a.jsx)(t.h2,{id:"deploying-the-data-generation-toolkit",children:"Deploying the data generation toolkit"}),"\n",(0,a.jsxs)(t.p,{children:["In this ",(0,a.jsx)(t.a,{href:"https://github.com/awslabs/data-on-eks/tree/main/analytics/terraform/spark-k8s-operator",children:"example"}),", you will provision the following resources required to run Spark Jobs with open source Spark Operator."]}),"\n",(0,a.jsx)(t.p,{children:"This example deploys an EKS Cluster running the Spark K8s Operator into a new VPC."}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"Creates a new sample VPC, 2 Private Subnets and 2 Public Subnets"}),"\n",(0,a.jsx)(t.li,{children:"Creates Internet gateway for Public Subnets and NAT Gateway for Private Subnets"}),"\n",(0,a.jsx)(t.li,{children:"Creates EKS Cluster Control plane with public endpoint (for demo reasons only) with core managed node group, on-demand node group and Spot node group for Spark workloads."}),"\n",(0,a.jsx)(t.li,{children:"Deploys Metrics server, Cluster Autoscaler, Spark-k8s-operator, Karpenter, Grafana, AMP and Prometheus server."}),"\n"]}),"\n",(0,a.jsx)(t.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,a.jsx)(t.p,{children:"Ensure that you have installed the following tools on your machine."}),"\n",(0,a.jsxs)(t.ol,{children:["\n",(0,a.jsx)(t.li,{children:(0,a.jsx)(t.a,{href:"https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html",children:"aws cli"})}),"\n",(0,a.jsx)(t.li,{children:(0,a.jsx)(t.a,{href:"https://Kubernetes.io/docs/tasks/tools/",children:"kubectl"})}),"\n",(0,a.jsx)(t.li,{children:(0,a.jsx)(t.a,{href:"https://learn.hashicorp.com/tutorials/terraform/install-cli",children:"terraform"})}),"\n"]}),"\n",(0,a.jsx)(t.h3,{id:"deploy",children:"Deploy"}),"\n",(0,a.jsx)(t.p,{children:"Clone the repository."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"git clone https://github.com/awslabs/data-on-eks.git\ncd data-on-eks\nexport DOEKS_HOME=$(pwd)\n"})}),"\n",(0,a.jsxs)(t.p,{children:["If DOEKS_HOME is ever unset, you can always set it manually using ",(0,a.jsx)(t.code,{children:"export DATA_ON_EKS=$(pwd)"})," from your data-on-eks directory."]}),"\n",(0,a.jsxs)(t.p,{children:["Export the following environment variables to set the minimum and desired number of ssd enabled ",(0,a.jsx)(t.code,{children:"c5d12xlarge"})," instances. In our tests, we've set both of these to ",(0,a.jsx)(t.code,{children:"6"})," based on the size of the dataset. Please adjust the number of instances as per your requirement and the size of the dataset you plan to run."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"export TF_VAR_spark_benchmark_ssd_min_size=6\nexport TF_VAR_spark_benchmark_ssd_desired_size=6\n"})}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Note :"})," If you don't have access to ",(0,a.jsx)(t.code,{children:"c5d"})," instances, feel free to use other EC2 instances that are equipped with local NVMe-based SSD block level storage. NVMe-based SSD instance storage enabled EC2 instances are a great fit for running the Spark benchmark data generation toolkit."]}),"\n",(0,a.jsxs)(t.p,{children:["Navigate into the following directory and run ",(0,a.jsx)(t.code,{children:"install.sh"})," script."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"cd ${DOEKS_HOME}/analytics/terraform/spark-k8s-operator\nchmod +x install.sh\n./install.sh\n"})}),"\n",(0,a.jsx)(t.p,{children:"Now create an S3_BUCKET variable that holds the name of the bucket created\nduring the install. This bucket will be used in later examples to store output\ndata. If S3_BUCKET is ever unset, you can run the following commands again."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"export S3_BUCKET=$(terraform output -raw s3_bucket_id_spark_history_server)\necho $S3_BUCKET\n"})}),"\n",(0,a.jsx)(t.h2,{id:"generating-test-dataset-for-running-the-tpcds-benchmark",children:"Generating Test Dataset for Running the TPCDS Benchmark"}),"\n",(0,a.jsx)(t.p,{children:"In order to generate the dataset for TPCDS benchmark tests, navigate to the following directory and execute the below commands."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"cd ${DOEKS_HOME}/analytics/terraform/spark-k8s-operator/examples/benchmark\nkubectl apply -f tpcds-benchmark-data-generation-1t.yaml\n"})}),"\n",(0,a.jsxs)(t.p,{children:["Once you apply the ",(0,a.jsx)(t.code,{children:"tpcds-benchmark-data-generation-1t.yaml"})," manifest, you should see the the driver and executor Pods coming up. It takes about an hour to finish the execution of the test data generation script. Once the execution is completed, you can see go into the AWS S3 console and validate the bucket size."]}),"\n",(0,a.jsxs)(t.p,{children:["Navigate to the S3 bucket that got created as part of running the blueprint. Tick the checkbox besides the folder named ",(0,a.jsx)(t.code,{children:"TPCDS-TEST-1TB"})," and click on ",(0,a.jsx)(t.code,{children:"Actions"})," dropdown and then click on ",(0,a.jsx)(t.code,{children:"Calculate total size"})," option as shown below."]}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"img1.png",src:n(5589).A+"",width:"2688",height:"1310"})}),"\n",(0,a.jsx)(t.p,{children:"For our dataset, the total size is 310 GB."}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"img2.png",src:n(3486).A+"",width:"2694",height:"1158"})}),"\n",(0,a.jsxs)(t.p,{children:["Once you go inside the ",(0,a.jsx)(t.code,{children:"TPCDS-TEST-1TB"})," folder, you should see lot of subfolders that got generated (as shown below)."]}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"img3.png",src:n(7357).A+"",width:"2694",height:"1002"})}),"\n",(0,a.jsx)(t.p,{children:"Each subfolder should have a .parquet file inside it that contains the generated data."}),"\n",(0,a.jsx)(t.p,{children:(0,a.jsx)(t.img,{alt:"img4.png",src:n(4850).A+"",width:"2694",height:"1244"})}),"\n",(0,a.jsx)(t.p,{children:"Also, check the Spark driver Pod execution status and logs to see if there are any errors."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",children:"kubectl get pod -n spark-team-a\n"})}),"\n",(0,a.jsx)(t.p,{children:"Output:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-text",children:"NAME                               READY   STATUS      RESTARTS   AGE\ntpcds-data-generation-1tb-driver   0/1     Completed   0          59m\n"})}),"\n",(0,a.jsxs)(t.p,{children:["The log snippet of the ",(0,a.jsx)(t.code,{children:"tpcds-data-generation-1tb-driver"})," pod should look like below"]}),"\n",(0,a.jsx)(s.A,{header:(0,a.jsx)(t.h2,{children:(0,a.jsx)(t.span,{children:"Driver Pod Log Snippet"})}),children:(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-text",children:"24/11/01 15:29:42 INFO FileFormatWriter: Start to commit write Job xxxx.\n24/11/01 15:29:42 INFO FileFormatWriter: Write Job xxxx committed. Elapsed time: 158 ms.\n24/11/01 15:29:42 INFO FileFormatWriter: Finished processing stats for write job xxxx.\nData generated at s3a://spark-operator-doeks-spark-logs-xxx/TPCDS-TEST-1TB\n24/11/01 15:29:42 INFO SparkContext: SparkContext is stopping with exitCode 0.\n24/11/01 15:29:42 INFO SparkUI: Stopped Spark web UI at http://tpcds-data-generation-1tb-yyyyy-driver-svc.spark-team-a.svc:4040\n24/11/01 15:29:42 INFO KubernetesClusterSchedulerBackend: Shutting down all executors\n24/11/01 15:29:42 INFO KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint: Asking each executor to shut down\n24/11/01 15:29:42 WARN ExecutorPodsWatchSnapshotSource: Kubernetes client has been closed.\n24/11/01 15:29:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n24/11/01 15:29:42 INFO MemoryStore: MemoryStore cleared\n24/11/01 15:29:42 INFO BlockManager: BlockManager stopped\n24/11/01 15:29:42 INFO BlockManagerMaster: BlockManagerMaster stopped\n24/11/01 15:29:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n24/11/01 15:29:42 INFO SparkContext: Successfully stopped SparkContext\n"})})}),"\n",(0,a.jsx)(t.h2,{id:"cost-considerations",children:"Cost Considerations"}),"\n",(0,a.jsx)(t.p,{children:"When utilizing c5d instances for data generation, it's important to keep cost implications in mind. These compute-optimized instances with local NVMe storage offer high performance but can be more expensive than standard c5 instances. To optimize costs, it's crucial to carefully monitor usage and scale resources appropriately. The local NVMe storage provides fast I/O, but data persistence is not guaranteed, so you should factor in the cost of data transfer and backup solutions. Spot instances can offer significant savings for interruptible workloads. Additionally, reserving instances for long-term, predictable usage can lead to substantial discounts. Also, it's essential to terminate these instances when they're no longer needed by adjusting the nodegroup's minimum and desired size to 0. This practice helps avoid unnecessary costs from idle resources."})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(u,{...e})}):u(e)}},9365:(e,t,n)=>{n.d(t,{A:()=>o});n(6540);var a=n(4164);const r={tabItem:"tabItem_Ymn6"};var s=n(4848);function o(e){let{children:t,hidden:n,className:o}=e;return(0,s.jsx)("div",{role:"tabpanel",className:(0,a.A)(r.tabItem,o),hidden:n,children:t})}},1470:(e,t,n)=>{n.d(t,{A:()=>S});var a=n(6540),r=n(4164),s=n(3104),o=n(6347),i=n(205),l=n(7485),c=n(1682),d=n(679);function u(e){return a.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,a.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function h(e){const{values:t,children:n}=e;return(0,a.useMemo)((()=>{const e=t??function(e){return u(e).map((e=>{let{props:{value:t,label:n,attributes:a,default:r}}=e;return{value:t,label:n,attributes:a,default:r}}))}(n);return function(e){const t=(0,c.XI)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function p(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function m(e){let{queryString:t=!1,groupId:n}=e;const r=(0,o.W6)(),s=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,l.aZ)(s),(0,a.useCallback)((e=>{if(!s)return;const t=new URLSearchParams(r.location.search);t.set(s,e),r.replace({...r.location,search:t.toString()})}),[s,r])]}function g(e){const{defaultValue:t,queryString:n=!1,groupId:r}=e,s=h(e),[o,l]=(0,a.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!p({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const a=n.find((e=>e.default))??n[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:t,tabValues:s}))),[c,u]=m({queryString:n,groupId:r}),[g,b]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[r,s]=(0,d.Dv)(n);return[r,(0,a.useCallback)((e=>{n&&s.set(e)}),[n,s])]}({groupId:r}),f=(()=>{const e=c??g;return p({value:e,tabValues:s})?e:null})();(0,i.A)((()=>{f&&l(f)}),[f]);return{selectedValue:o,selectValue:(0,a.useCallback)((e=>{if(!p({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);l(e),u(e),b(e)}),[u,b,s]),tabValues:s}}var b=n(2303);const f={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var x=n(4848);function k(e){let{className:t,block:n,selectedValue:a,selectValue:o,tabValues:i}=e;const l=[],{blockElementScrollPositionUntilNextRender:c}=(0,s.a_)(),d=e=>{const t=e.currentTarget,n=l.indexOf(t),r=i[n].value;r!==a&&(c(t),o(r))},u=e=>{let t=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const n=l.indexOf(e.currentTarget)+1;t=l[n]??l[0];break}case"ArrowLeft":{const n=l.indexOf(e.currentTarget)-1;t=l[n]??l[l.length-1];break}}t?.focus()};return(0,x.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":n},t),children:i.map((e=>{let{value:t,label:n,attributes:s}=e;return(0,x.jsx)("li",{role:"tab",tabIndex:a===t?0:-1,"aria-selected":a===t,ref:e=>l.push(e),onKeyDown:u,onClick:d,...s,className:(0,r.A)("tabs__item",f.tabItem,s?.className,{"tabs__item--active":a===t}),children:n??t},t)}))})}function j(e){let{lazy:t,children:n,selectedValue:s}=e;const o=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=o.find((e=>e.props.value===s));return e?(0,a.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,x.jsx)("div",{className:"margin-top--md",children:o.map(((e,t)=>(0,a.cloneElement)(e,{key:t,hidden:e.props.value!==s})))})}function v(e){const t=g(e);return(0,x.jsxs)("div",{className:(0,r.A)("tabs-container",f.tabList),children:[(0,x.jsx)(k,{...t,...e}),(0,x.jsx)(j,{...t,...e})]})}function S(e){const t=(0,b.A)();return(0,x.jsx)(v,{...e,children:u(e.children)},String(t))}},2450:(e,t,n)=>{n.d(t,{A:()=>m});var a=n(6540),r=n(5556),s=n.n(r),o=n(4164);const i="collapsibleContent_q3kw",l="header_QCEw",c="icon_PckA",d="content_qLC1",u="expanded_iGsi";var h=n(4848);function p(e){let{children:t,header:n}=e;const[r,s]=(0,a.useState)(!1);return(0,h.jsxs)("div",{className:i,children:[(0,h.jsxs)("div",{className:(0,o.A)(l,{[u]:r}),onClick:()=>{s(!r)},children:[n,(0,h.jsx)("span",{className:(0,o.A)(c,{[u]:r}),children:r?"\ud83d\udc47":"\ud83d\udc48"})]}),r&&(0,h.jsx)("div",{className:d,children:t})]})}p.propTypes={children:s().node.isRequired,header:s().node.isRequired};const m=p},7357:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/datagen-3-8e60f6b610a4ce3bc2f5877e150f1b52.png"},4850:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/datagen-4-a59a02a6bcf2659066d14d9e0cb0f919.png"},5589:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/datagen-bucket1-ddde1c31b663ce9540dbad2461543c20.png"},3486:(e,t,n)=>{n.d(t,{A:()=>a});const a=n.p+"assets/images/datagen-bucket2-c8168d3114ef6006b2e5740c06a591f4.png"},8453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>i});var a=n(6540);const r={},s=a.createContext(r);function o(e){const t=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),a.createElement(s.Provider,{value:t},e.children)}}}]);