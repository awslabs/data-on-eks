{"searchDocs":[{"title":"Amazon EMR on Amazon EKS provides up to 61% lower costs and up to 68% performance improvement for Spark workloads","type":0,"sectionRef":"#","url":"/data-on-eks/docs/benchmarks/emr-on-eks","content":"","keywords":"","version":"Next"},{"title":"How does Amazon EMR on EKS reduce cost and improve performance?‚Äã","type":1,"pageTitle":"Amazon EMR on Amazon EKS provides up to 61% lower costs and up to 68% performance improvement for Spark workloads","url":"/data-on-eks/docs/benchmarks/emr-on-eks#how-does-amazon-emr-on-eks-reduce-cost-and-improve-performance","content":" The EMR runtime for Spark is a performance-optimized runtime for Apache Spark that is 100% API compatible with open-source Apache Spark. It‚Äôs enabled by default with Amazon EMR on EKS. It helps run Spark workloads faster, leading to lower running costs. It includes multiple performance optimization features, such as Adaptive Query Execution (AQE), dynamic partition pruning, flattening scalar subqueries, bloom filter join, and more.  In addition to the cost benefit brought by the EMR runtime for Spark, Amazon EMR on EKS can take advantage of other AWS features to further optimize cost. For example, you can run Amazon EMR on EKS jobs on Amazon Elastic Compute Cloud (Amazon EC2) Spot Instances, providing up to 90% cost savings when compared to On-Demand Instances. Also, Amazon EMR on EKS supports Arm-based Graviton EC2 instances, which creates a 15% performance improvement and up to 30% cost savings when compared a Graviton2-based M6g to M5 instance type.  The recent graceful executor decommissioning feature makes Amazon EMR on EKS workloads more robust by enabling Spark to anticipate Spot Instance interruptions. Without the need to recompute or rerun impacted Spark jobs, Amazon EMR on EKS can further reduce job costs via critical stability and performance improvements.  Additionally, through container technology, Amazon EMR on EKS offers more options to debug and monitor Spark jobs. For example, you can choose Spark History Server, Amazon CloudWatch, or Amazon Managed Prometheus and Amazon Managed Grafana (for more details, refer to the Monitoring and Logging workshop). Optionally, you can use familiar command line tools such as kubectl to interact with a job processing environment and observe Spark jobs in real time, which provides a fail-fast and productive development experience.  Amazon EMR on EKS supports multi-tenant needs and offers application-level security control via a job execution role. It enables seamless integrations to other AWS native services without a key-pair set up in Amazon EKS. The simplified security design can reduce your engineering overhead and lower the risk of data breach. Furthermore, Amazon EMR on EKS handles security and performance patches so you can focus on building your applications.  ","version":"Next","tagName":"h2"},{"title":"Benchmarking‚Äã","type":1,"pageTitle":"Amazon EMR on Amazon EKS provides up to 61% lower costs and up to 68% performance improvement for Spark workloads","url":"/data-on-eks/docs/benchmarks/emr-on-eks#benchmarking","content":" This post provides an end-to-end Spark benchmark solution so you can get hands-on with the performance test process. The solution uses unmodified TPC-DS data schema and table relationships, but derives queries from TPC-DS to support the Spark SQL test case. It is not comparable to other published TPC-DS benchmark results.  Key concepts Transaction Processing Performance Council-Decision Support (TPC-DS) is a decision support benchmark that is used to evaluate the analytical performance of big data technologies. Our test data is a TPC-DS compliant dataset based on the TPC-DS Standard Specification, Revision 2.4 document, which outlines the business model and data schema, relationship, and more. As the whitepaper illustrates, the test data contains 7 fact tables and 17 dimension tables, with an average of 18 columns. The schema consists of essential retailer business information, such as customer, order, and item data for the classic sales channels: store, catalog, and internet. This source data is designed to represent real-world business scenarios with common data skews, such as seasonal sales and frequent names. Additionally, the TPC-DS benchmark offers a set of discrete scaling points (scale factors) based on the approximate size of the raw data. In our test, we chose the 3 TB scale factor, which produces 17.7 billion records, approximately 924 GB compressed data in Parquet file format.  Test approach A single test session consists of 104 Spark SQL queries that were run sequentially. To get a fair comparison, each session of different deployment types, such as Amazon EMR on EKS, was run three times. The average runtime per query from these three iterations is what we analyze and discuss in this post. Most importantly, it derives two summarized metrics to represent our Spark performance:  Total execution time ‚Äì The sum of the average runtime from three iterations Geomean ‚Äì The geometric mean of the average runtime Test results In the test result summary (see the following figure), we discovered that the Amazon EMR-optimized Spark runtime used by Amazon EMR on EKS is approximately 2.1 times better than the open-source Spark on Amazon EKS in geometric mean and 3.5 times faster by the total runtime.    The following figure breaks down the performance summary by queries. We observed that EMR runtime for Spark was faster in every query compared to open-source Spark. Query q67 was the longest query in the performance test. The average runtime with open-source Spark was 1019.09 seconds. However, it took 150.02 seconds with Amazon EMR on EKS, which is 6.8 times faster. The highest performance gain in these long-running queries was q72‚Äî319.70 seconds (open-source Spark) vs. 26.86 seconds (Amazon EMR on EKS), a 11.9 times improvement.    For full blog link ","version":"Next","tagName":"h2"},{"title":"EKS Best Practices","type":0,"sectionRef":"#","url":"/data-on-eks/docs/bestpractices/eks-best-practices","content":"","keywords":"","version":"Next"},{"title":"EKS Best Practices Guides‚Äã","type":1,"pageTitle":"EKS Best Practices","url":"/data-on-eks/docs/bestpractices/eks-best-practices#eks-best-practices-guides","content":" The primary goal of this EKS Best practices is to offer a set of best practices for day 2 operations for Amazon EKS. We elected to publish this guidance to GitHub so we could iterate quickly, provide timely and effective recommendations for variety of concerns, and easily incorporate suggestions from the broader community.  Checkout the EKS Best practices GitHub docs here ","version":"Next","tagName":"h2"},{"title":"EMR on EKS Best Practices","type":0,"sectionRef":"#","url":"/data-on-eks/docs/bestpractices/emr-on-eks","content":"","keywords":"","version":"Next"},{"title":"EMR Containers Best Practices Guides‚Äã","type":1,"pageTitle":"EMR on EKS Best Practices","url":"/data-on-eks/docs/bestpractices/emr-on-eks#emr-containers-best-practices-guides","content":" Amazon EMR on Amazon EKS enables you to submit Apache Spark jobs on demand on Amazon Elastic Kubernetes Service (EKS) without provisioning clusters. With EMR on EKS, you can consolidate analytical workloads with your other Kubernetes-based applications on the same Amazon EKS cluster to improve resource utilization and simplify infrastructure management.  This link provides the best practices and templates to get started with Amazon EMR on EKS. We publish this guide on GitHub so we could iterate the content quickly, provide timely and effective recommendations for variety of concerns, and easily incorporate suggestions from the broader community.  Checkout the EMR on EKS Best practices GitHub docs here  ","version":"Next","tagName":"h2"},{"title":"Architecture‚Äã","type":1,"pageTitle":"EMR on EKS Best Practices","url":"/data-on-eks/docs/bestpractices/emr-on-eks#architecture","content":" The following diagram illustrates the solution architecture Amazon EMR on EKS.   ","version":"Next","tagName":"h3"},{"title":"Introduction","type":0,"sectionRef":"#","url":"/data-on-eks/docs/bestpractices/intro","content":"Introduction info COMING SOON Please note that this section is currently a work in progress and will provide a collection of best practices for running Data and ML workloads on EKS. These best practices will cover various aspects, including cluster configuration, resource management, data storage, security, monitoring, and more. By following these recommended practices, you can optimize the performance, reliability, and security of your data and ML workloads on EKS. Stay tuned for valuable insights and guidance on how to achieve the best outcomes in your EKS environment. Through working with AWS customers, we‚Äôve identified a number of Best Practices that we have recommended for Spark or other large data workloads. We continue to collect and post those recommendations here. Because this is an ongoing effort, please open an Issue or Pull Request if you find something outdated so we can update it. These Data on EKS Best Practices are meant to expand upon the EKS Best Practices Guide for data-centric use cases (e.g., batch processing, stream processing, and machine learning) and we recommend reviewing the EKS Best Practices as a primer before diving into these. The Data on EKS Best Practices are not comprehensive and we recommend you read through the guidance and determine what‚Äôs best for your environment. The recommendations here were built from working with customers one of two designs (listed below). Each data use case (e.g., batch processing, stream processing) aligns more closely to one of the two cluster designs, which we will call out in our recommendations. The first design is dynamic clusters that scale, or ‚Äúchurn‚Äù, a lot. These clusters run batch processing with Spark, or other workloads that create pods for a relatively short time but can vary greatly on the scale at any given time. These clusters create and delete resources like pods and nodes, or churn, at a high rate which adds unique pressures to Kubernetes and critical components.The other design is ‚Äústatic‚Äù clusters. These clusters are often large but have less volatile scaling behavior and are generally running longer-lived jobs, like streaming or training. Avoid interruptions for these workloads is a key concern and care must be taken when making changes. When we talk about large clusters or high rates of churn, it‚Äôs difficult to put a specific number to those phrases because of the complexity of kubernetes scalability. In general, these clusters have &gt;500 nodes and &gt;5000 pods, or are creating/destroying hundreds of resources a minute; however, the scalability constraints are different for every workload (even between two different Spark jobs).","keywords":"","version":"Next"},{"title":"JupyterHub on EKS","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/ai-ml/jupyterhub","content":"","keywords":"","version":"Next"},{"title":"Introduction‚Äã","type":1,"pageTitle":"JupyterHub on EKS","url":"/data-on-eks/docs/blueprints/ai-ml/jupyterhub#introduction","content":" JupyterHub is a powerful multi-user server that enables users to access and interact with Jupyter notebooks and other Jupyter-compatible environments. It provides a collaborative platform where multiple users can simultaneously access and utilize notebooks, fostering collaboration and sharing among users. JupyterHub allows users to create their own isolated computing environments (known as &quot;spawners&quot;) and launch Jupyter notebooks or other interactive computing environments within those environments. This provides each user with their own workspace, including files, code, and computational resources.  ","version":"Next","tagName":"h2"},{"title":"JupyterHub on EKS‚Äã","type":1,"pageTitle":"JupyterHub on EKS","url":"/data-on-eks/docs/blueprints/ai-ml/jupyterhub#jupyterhub-on-eks-1","content":" JupyterHub on Amazon Elastic Kubernetes Service (EKS) combines the versatility of JupyterHub with the scalability and flexibility of Kubernetes. By deploying JupyterHub on EKS, you can easily manage and maintain a shared Jupyter notebook environment for multiple users. This environment serves as a collaborative and interactive platform for various tasks such as data science, machine learning, and research. The JupyterHub add-on is built upon the JupyterHub project, which supports a multi-user Hub capable of spawning, managing, and proxying multiple instances of single-user Jupyter notebook servers.  By leveraging the capabilities of EKS, you can seamlessly scale your JupyterHub environment to meet the needs of your users, ensuring efficient resource utilization and optimal performance. With EKS, you can take advantage of Kubernetes features such as automated scaling, high availability, and easy deployment of updates and upgrades. This enables you to provide a reliable and robust JupyterHub experience for your users, empowering them to collaborate, explore, and analyze data effectively. To get started with JupyterHub on EKS, follow the instructions in this guide to set up and configure your JupyterHub environment.  Deploying the Solution üëà  Verify the resources üëà  ","version":"Next","tagName":"h2"},{"title":"Login into JupyterHub via Amazon Cognito‚Äã","type":1,"pageTitle":"JupyterHub on EKS","url":"/data-on-eks/docs/blueprints/ai-ml/jupyterhub#login-into-jupyterhub-via-amazon-cognito","content":" Add the CNAME DNS record in ChangeIP for the JupyterHub domain with the load balancer DNS name.    info When adding the load balancer DNS name in the value field of CNAME in ChangeIP make sure to add a dot(.) at the end of the load-balancer DNS name.  Now typing the domain url in the browser should redirect to the Cognito login page.    Follow the Cognito sign-up and sign-in process to login.    Successful sign-in will open up the JupyterHub environment for the logged in user.    To test the setup of the shared and personal directories in JupyterHub, you can follow these steps:  Open a terminal window from the launcher dashboard.    execute the command  df -h   Verify EFS mounts created. Each user's private home directory is available at /home/jovyan. The shared directory is available at /home/shared  Cleanup üëà ","version":"Next","tagName":"h3"},{"title":"AI/ML Platforms on EKS","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/ai-ml","content":"AI/ML Platforms on EKS Running AI/ML platforms on Kubernetes can greatly simplify and automate the deployment, scaling, and management of these complex applications. There are a number of popular tools and technologies that have emerged to support this use case, including TensorFlow, PyTorch, Ray, MLFlow, etc. These tools make it easy to deploy AI/ML models in a containerized environment, and provide features such as automatic scaling, rolling updates, and self-healing capabilities to ensure high availability and reliability. By leveraging the power of Kubernetes, organizations can focus on building and training their AI/ML models, rather than worrying about the underlying infrastructure. With its robust ecosystem of tools and support for a wide range of use cases, Kubernetes is becoming an increasingly popular choice for running AI/ML platforms in production. The following Terraform templates are available to deploy. Ray on EKS: This template deploys RayCluster on EKS. EMR NVIDIA Spark-RAPIDS: This template deploys the EMR NVIDIA Spark-RAPIDS blueprint with NVIDIA GPU Operator.","keywords":"","version":"Next"},{"title":"Ray on EKS","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/ai-ml/ray","content":"","keywords":"","version":"Next"},{"title":"Introduction‚Äã","type":1,"pageTitle":"Ray on EKS","url":"/data-on-eks/docs/blueprints/ai-ml/ray#introduction","content":" Ray is an open-source framework for building scalable and distributed applications. It is designed to make it easy to write parallel and distributed Python applications by providing a simple and intuitive API for distributed computing. It has a growing community of users and contributors, and is actively maintained and developed by the Ray team at Anyscale, Inc.  To deploy Ray in production across multiple machines users must first deploy Ray Cluster. A Ray Cluster consists of head nodes and worker nodes which can be autoscaled using the built-in Ray Autoscaler.    Source: https://docs.ray.io/en/latest/cluster/key-concepts.html  ","version":"Next","tagName":"h2"},{"title":"Ray on Kubernetes‚Äã","type":1,"pageTitle":"Ray on EKS","url":"/data-on-eks/docs/blueprints/ai-ml/ray#ray-on-kubernetes","content":" Deploying Ray Cluster on Kubernetes including on Amazon EKS is supported via the KubeRay Operator. The operator provides a Kubernetes-native way to manage Ray clusters. The installation of KubeRay Operator involves deploying the operator and the CRDs for RayCluster, RayJob and RayService as documented here.  Deploying Ray on Kubernetes can provide several benefits:  Scalability: Kubernetes allows you to scale your Ray cluster up or down based on your workload requirements, making it easy to manage large-scale distributed applications. Fault tolerance: Kubernetes provides built-in mechanisms for handling node failures and ensuring high availability of your Ray cluster. Resource allocation: With Kubernetes, you can easily allocate and manage resources for your Ray workloads, ensuring that they have access to the necessary resources for optimal performance. Portability: By deploying Ray on Kubernetes, you can run your workloads across multiple clouds and on-premises data centers, making it easy to move your applications as needed. Monitoring: Kubernetes provides rich monitoring capabilities, including metrics and logging, making it easy to troubleshoot issues and optimize performance.  Overall, deploying Ray on Kubernetes can simplify the deployment and management of distributed applications, making it a popular choice for many organizations that need to run large-scale machine learning workloads.  Before moving forward with the deployment please make sure you have read the pertinent sections of the official documentation.    Source: https://docs.ray.io/en/latest/cluster/kubernetes/index.html  ","version":"Next","tagName":"h2"},{"title":"Deploying the Example‚Äã","type":1,"pageTitle":"Ray on EKS","url":"/data-on-eks/docs/blueprints/ai-ml/ray#deploying-the-example","content":" In this example, you will provision Ray Cluster on Amazon EKS using the KubeRay Operator. The example also demonstrates the use of Karpenter of autoscaling of worker nodes for job specific Ray Clusters.    Pre-requisites üëà  Deploy the EKS Cluster with KubeRay Operator üëà  Verify Deployment üëà  Deploy Ray Clusters and Workloads üëà  Teardown üëà ","version":"Next","tagName":"h2"},{"title":"Amazon EMR on EKS","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks","content":"","keywords":"","version":"Next"},{"title":"Benefits of EMR on EKS‚Äã","type":1,"pageTitle":"Amazon EMR on EKS","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks#benefits-of-emr-on-eks","content":" ","version":"Next","tagName":"h2"},{"title":"Simplify management‚Äã","type":1,"pageTitle":"Amazon EMR on EKS","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks#simplify-management","content":" You get the same EMR benefits for Apache Spark on EKS that you get on EC2 today. This includes fully managed versions of Apache Spark 2.4 and 3.0, automatic provisioning, scaling, performance optimized runtime, and tools like EMR Studio for authoring jobs and an Apache Spark UI for debugging.  ","version":"Next","tagName":"h3"},{"title":"Reduce Costs‚Äã","type":1,"pageTitle":"Amazon EMR on EKS","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks#reduce-costs","content":" With EMR on EKS, your compute resources can be shared between your Apache Spark applications and your other Kubernetes applications. Resources are allocated and removed on-demand to eliminate over-provisioning or under-utilization of these resources, enabling you to lower costs as you only pay for the resources you use.  ","version":"Next","tagName":"h3"},{"title":"Optimize Performance‚Äã","type":1,"pageTitle":"Amazon EMR on EKS","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks#optimize-performance","content":" By running analytics applications on EKS, you can reuse existing EC2 instances in your shared Kubernetes cluster and avoid the startup time of creating a new cluster of EC2 instances dedicated for analytics. You can also get 3x faster performance running performance optimized Spark with EMR on EKS compared to standard Apache Spark on EKS.  ","version":"Next","tagName":"h3"},{"title":"EMR on EKS Deployment patterns with Terraform‚Äã","type":1,"pageTitle":"Amazon EMR on EKS","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks#emr-on-eks-deployment-patterns-with-terraform","content":" The following Terraform templates are available to deploy.  EMR on EKS with Karpenter: üëà:skin-tone-3: Start Here if you are new to EMR on EKS. This template deploys EMR on EKS cluster and uses Karpenter to scale Spark jobs.ACK controller for EMR on EKS: This template deploys EMR on EKS cluster and uses ACK controller to manage Spark jobs ","version":"Next","tagName":"h2"},{"title":"ACK Controller for EMR on EKS","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-ack","content":"","keywords":"","version":"Next"},{"title":"Introduction‚Äã","type":1,"pageTitle":"ACK Controller for EMR on EKS","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-ack#introduction","content":" In this post, we will learn to build EMR on EKS Spark workloads by using AWS Controllers for Kubernetes (ACK). We will also build a end-to-end observability for Spark workloads by leveraging Amazon Managed Service for Prometheus to collect and store the metrics generated by Spark Applications and then use Amazon Managed Grafana to build dashboards for monitoring use cases.  Deploying the Solution üëà  ","version":"Next","tagName":"h2"},{"title":"Setup Amazon Managed Grafana with SSO‚Äã","type":1,"pageTitle":"ACK Controller for EMR on EKS","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-ack#setup-amazon-managed-grafana-with-sso","content":" Currently, this step is manual. Please follow the steps in this blog to create Amazon Managed Grafana with SSO enabled in your account. You can visualize the Spark jobs runs and metrics using Amazon Managed Prometheus and Amazon Managed Grafana.  Execute Sample Spark job - EMR Virtual Cluster üëà  Cleanup üëà  caution To avoid unwanted charges to your AWS account, delete all the AWS resources created during this deployment ","version":"Next","tagName":"h3"},{"title":"Networking for Data","type":0,"sectionRef":"#","url":"/data-on-eks/docs/bestpractices/networking","content":"","keywords":"","version":"Next"},{"title":"VPC and IP Considerations‚Äã","type":1,"pageTitle":"Networking for Data","url":"/data-on-eks/docs/bestpractices/networking#vpc-and-ip-considerations","content":" ","version":"Next","tagName":"h2"},{"title":"Plan for a large amount of IP address usage in your EKS clusters.‚Äã","type":1,"pageTitle":"Networking for Data","url":"/data-on-eks/docs/bestpractices/networking#plan-for-a-large-amount-of-ip-address-usage-in-your-eks-clusters","content":" The AWS VPC CNI maintains a ‚Äúwarm pool‚Äù of IP addresses on the EKS worker nodes to assign to Pods. When more IP addresses are needed for your Pods, the CNI must communicate with EC2 APIs to assign the addresses to your nodes. During periods of high churn or large scale out these EC2 API calls can be rate throttled, which will delay the provisioning of Pods and thus delay the execution of workloads. When designing the VPC for your environment plan for more IP addresses than just your pods to accommodate this warm pool.  With the default VPC CNI configuration larger nodes will consume more IP addresses. For example a m5.8xlarge node that is running 10 pods will hold 60 IPs total (to satisfy WARM_ENI=1). However a m5.16xlarge node would hold 100 IPs. Configuring the VPC CNI to minimize this warm pool can increase the EC2 API calls from your nodes and increase the risk of rate throttling. Planning for this extra IP address usage can avoid rate throttling problems and managing the IP address usage.  ","version":"Next","tagName":"h3"},{"title":"Consider using a secondary CIDR if your IP space is constrained.‚Äã","type":1,"pageTitle":"Networking for Data","url":"/data-on-eks/docs/bestpractices/networking#consider-using-a-secondary-cidr-if-your-ip-space-is-constrained","content":" If you are working with a network that spans multiple connected VPCs or sites the routable address space may be limited. For example, your VPC may be limited to small subnets like below. In this VPC we wouldn‚Äôt be able to run more than one m5.16xlarge node without adjusting the CNI configuration.    You can add additional VPC CIDRs from a range that is not routable across VPCs (such as the RFC 6598 range, 100.64.0.0/10). In this case we added 100.64.0.0/16, 100.65.0.0/16, and 100.66.0.0/16 to the VPC (as this is the maximum CIDR size), then created new subnets with those CIDRs. Finally we recreated the node groups in the new subnets, leaving the existing EKS cluster control plane in place.    With this configuration you can still communicate with the EKS cluster control plane from connected VPCs but your nodes and pods have plenty of IP addresses to accommodate your workloads and the warm pool.  ","version":"Next","tagName":"h3"},{"title":"Tuning the VPC CNI‚Äã","type":1,"pageTitle":"Networking for Data","url":"/data-on-eks/docs/bestpractices/networking#tuning-the-vpc-cni","content":" ","version":"Next","tagName":"h2"},{"title":"VPC CNI and EC2 Rate Throttling‚Äã","type":1,"pageTitle":"Networking for Data","url":"/data-on-eks/docs/bestpractices/networking#vpc-cni-and-ec2-rate-throttling","content":" When an EKS worker node is launched it initially has a single ENI with a single IP address attached for the EC2 instance to communicate. As the VPC CNI launches it tries to provision a Warm Pool of IP addresses that can be assigned to Kubernetes Pods (More details in the EKS Best Practices Guide).  The VPC CNI must make AWS EC2 API calls (like AssignPrivateIpV4Address and DescribeNetworkInterfaces) to assign those additional IPs and ENIs to the worker node. When the EKS cluster scales out the number of Nodes or Pods there could be a spike in the number of these EC2 API calls. This surge of calls could encounter rate throttling from the EC2 API to help the performance of the service, and to ensure fair usage for all Amazon EC2 customers. This rate throttling can cause the pool of IP address to be exhausted while the CNI tries to allocate more IPs.  These failures will cause errors like the one below, indicating that the provisioning of the container network namespace has failed because the VPC CNI could not provision an IP address.  Failed to create pod sandbox: rpc error: code = Unknown desc = failed to set up sandbox container &quot;xxxxxxxxxxxxxxxxxxxxxx&quot; network for pod &quot;test-pod&quot;: networkPlugin cni failed to set up pod test-pod_default&quot; network: add cmd: failed to assign an IP address to container   This failure delays the launch of the Pod and adds pressure to the kubelet and worker node as this action is retried until the IP address is assigned. To avoid this delay you can configure the CNI to reduce the number of EC2 API calls needed.  ","version":"Next","tagName":"h3"},{"title":"Avoid using WARM_IP_TARGET in large clusters, or cluster with a lot of churn‚Äã","type":1,"pageTitle":"Networking for Data","url":"/data-on-eks/docs/bestpractices/networking#avoid-using-warm_ip_target-in-large-clusters-or-cluster-with-a-lot-of-churn","content":" WARM_IP_TARGET can help limit the ‚Äúwasted‚Äù IPs for small clusters, or clusters that has very low pod churn. However, this environment variable on the VPC CNI needs to be carefully configured in large clusters as it may increase the number of EC2 API calls, increasing the risk and impact of rate throttling.  For clusters that have a lot of Pod churn, it is recommended to set MINIMUM_IP_TARGET to a value slightly higher than the expected number of pods you plan to run on each node. This will allow the CNI to provision all of those IP addresses in a single (or few) calls.   [...] # EKS Addons cluster_addons = { vpc-cni = { configuration_values = jsonencode({ env = { MINIMUM_IP_TARGET = &quot;30&quot; } }) } } [...]   ","version":"Next","tagName":"h3"},{"title":"Limit the number of IPs per node on large instance types with MAX_ENI and max-pods‚Äã","type":1,"pageTitle":"Networking for Data","url":"/data-on-eks/docs/bestpractices/networking#limit-the-number-of-ips-per-node-on-large-instance-types-with-max_eni-and-max-pods","content":" When using larger instance types such as 16xlarge or 24xlarge the number of IP addresses that can be assigned per ENI can be fairly large. For example, a c5.18xlarge instance type with the default CNI configuration of WARM_ENI=1 would end up holding 100 IP addresses (50 IPs per ENI * 2 ENIs) when running a handful of pods.  For some workloads the CPU, Memory, or other resource will limit the number of Pods on that c5.18xlarge before we need more than 50 IPs. In this case you may want to be able to run 30-40 pods maximum on that instance.   [...] # EKS Addons cluster_addons = { vpc-cni = { configuration_values = jsonencode({ env = { MAX_ENI = &quot;1&quot; } }) } } [...]   Setting the MAX_ENI=1 option on the CNI and that this will limit the number of IP addresses each node is able to provision, but it does not limit the number of pod that kubernetes will try to schedule to the nodes. This can lead to a situation where pods are scheduled to nodes that are unable to provision more IP addresses.  To limit the IPs and stop k8s from scheduling too many pods you will need to:  Update the CNI configuration environment variables to set MAX_ENI=1Update the --max-pods option for the kubelet on the worker nodes.  To configure the --max-pods option you can update the userdata for your worker nodes to set this option via the --kubelet -extra-args in the bootstrap.sh script. By default this script configures the max-pods value for the kubelet, the --use-max-pods false` option disables this behavior when providing your own value:   eks_managed_node_groups = { system = { instance_types = [&quot;m5.xlarge&quot;] min_size = 0 max_size = 5 desired_size = 3 pre_bootstrap_user_data = &lt;&lt;-EOT EOT bootstrap_extra_args = &quot;--use-max-pods false --kubelet-extra-args '--max-pods=&lt;your_value&gt;'&quot; }   One problem is the number of IPs per ENI is different based on the Instance type (for example a m5d.2xlarge can have 15 IPs per ENI, where a m5d.4xlarge can hold 30 IPs per ENI). This means hard-coding a value for max-pods may cause problems if you change instance types or in mixed-instance environments.  In the EKS Optimized AMI releases there is a script included that can be used to help calculate the AWS Recommended max-pods value. If you‚Äôd like to automate this calculation for mixed instances you will also need to update the userdata for your instances to use the --instance-type-from-imds flag to autodiscover the instance type from instance metadata.   eks_managed_node_groups = { system = { instance_types = [&quot;m5.xlarge&quot;] min_size = 0 max_size = 5 desired_size = 3 pre_bootstrap_user_data = &lt;&lt;-EOT /etc/eks/max-pod-calc.sh --instance-type-from-imds ‚Äîcni-version 1.13.4 ‚Äîcni-max-eni 1 EOT bootstrap_extra_args = &quot;--use-max-pods false --kubelet-extra-args '--max-pods=&lt;your_value&gt;'&quot; }   Maxpods with Karpenter‚Äã  By default, Nodes provisioned by Karpenter will have the max pods on a node based on the node instance type. To configure the --max-pods option as mentioned above by defining at the Provisioner level by specifying maxPods within the .spec.kubeletConfiguration . This value will be used during Karpenter pod scheduling and passed through to --max-pods on kubelet startup.  Below is the example Provisioner spec:  apiVersion: karpenter.sh/v1alpha5 kind: Provisioner metadata: name: default spec: providerRef: name: default requirements: - key: &quot;karpenter.k8s.aws/instance-category&quot; operator: In values: [&quot;c&quot;, &quot;m&quot;, &quot;r&quot;] - key: &quot;karpenter.sh/capacity-type&quot; # If not included, the webhook for the AWS cloud provider will default to on-demand operator: In values: [&quot;spot&quot;, &quot;on-demand&quot;] # Karpenter provides the ability to specify a few additional Kubelet args. # These are all optional and provide support for additional customization and use cases. kubeletConfiguration: maxPods: 30   ","version":"Next","tagName":"h3"},{"title":"Application‚Äã","type":1,"pageTitle":"Networking for Data","url":"/data-on-eks/docs/bestpractices/networking#application","content":" ","version":"Next","tagName":"h2"},{"title":"DNS Lookups and ndots‚Äã","type":1,"pageTitle":"Networking for Data","url":"/data-on-eks/docs/bestpractices/networking#dns-lookups-and-ndots","content":" In Kubernetes Pods with the default DNS configuration have a resolv.conf file like so:  nameserver 10.100.0.10 search namespace.svc.cluster.local svc.cluster.local cluster.local ec2.internal options ndots:5   The domain names listed in the search line are appended to DNS names that are not fully qualified domain names (FQDN). For example, if a pod tries to connect to a Kubernetes service using servicename.namespace the domains would be appended in order until the DNS name matched the full kubernetes service name:  servicename.namespace.namespace.svc.cluster.local &lt;--- Fails with NXDOMAIN servicename.namespace.svc.cluster.local &lt;-- Succeed   Whether or not a domain is fully qualified is determined by the ndots option in the resolv.conf. This option defines the number of dots that must be in a domain name before the search domains are skipped. These additional searches can add latency to connections to external resources like S3 and RDS endpoints.  The default ndots setting in Kubernetes is five, if your application isn‚Äôt talking to other pods in the cluster, we can set the ndots to a low value like ‚Äú2‚Äù. This is a good starting point, because it still allows your application to do service discovery within the same namespace and in other namespaces within the cluster, but allows a domain like s3.us-east-2.amazonaws.com to be recognized as a FQDN (skipping the search domains).  Here‚Äôs an example pod manifest from the Kubernetes documentation with ndots set to ‚Äú2‚Äù:  apiVersion: v1 kind: Pod metadata: namespace: default name: dns-example spec: containers: - name: test image: nginx dnsConfig: options: - name: ndots value: &quot;2&quot;   info While setting ndots to ‚Äú2‚Äù in your pod deployment is a reasonable place to start, this will not universally work in all situations and shouldn‚Äôt be applied across the entire cluster. The ndots configuration needs to be configured at the Pod or Deployment level. Reducing this setting at the Cluster level CoreDNS configuration is not recommended.  ","version":"Next","tagName":"h3"},{"title":"Inter AZ Network Optimization‚Äã","type":1,"pageTitle":"Networking for Data","url":"/data-on-eks/docs/bestpractices/networking#inter-az-network-optimization","content":" Some workloads may need to exchange data between Pods in the cluster, like Spark executors during the shuffle stage. If the Pods are spread across multiple Availability Zones (AZs), this shuffle operation can turn out to be very expensive, especially on Network I/O front. Hence, for these workloads, it is recommended to colocate executors or worker pods in the same AZ. Colocating workloads in the same AZ serves two main purposes:  Reduce inter-AZ traffic costsReduce network latency between executors/Pods  To have pods co-located on the same AZ, we can use podAffinity based scheduling constraints. The scheduling constraint preferredDuringSchedulingIgnoredDuringExecution can be enforced in the Pod spec. For example, ins Spark we can use a custom template for our driver and executor pods:  spec: executor: affinity: podAffinity: preferredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: sparkoperator.k8s.io/app-name operator: In values: - &lt;&lt;spark-app-name&gt;&gt; topologyKey: topology.kubernetes.io/zone ...   You can also leverage Kubernetes Topology Aware Routing to have Kubernetes services route traffic in more efficient means once pods have been created: https://aws.amazon.com/blogs/containers/exploring-the-effect-of-topology-aware-hints-on-network-traffic-in-amazon-elastic-kubernetes-service/  info Having all executors located in a single AZ, means that AZ will be a single point of failure. This is a trade off you should consider between lowering network cost and latency, and the event of an AZ failure interrupting workloads. If your workload is running on instances with constrained capacity you may consider using multiple AZs to avoid Insufficient Capacity errors. ","version":"Next","tagName":"h3"},{"title":"AWS Trainium on EKS","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/ai-ml/trainium","content":"","keywords":"","version":"Next"},{"title":"Solution Architecture‚Äã","type":1,"pageTitle":"AWS Trainium on EKS","url":"/data-on-eks/docs/blueprints/ai-ml/trainium#solution-architecture","content":"   Deploying the Solution üëà  ","version":"Next","tagName":"h3"},{"title":"Distributed PyTorch Training on Trainium with TorchX and EKS‚Äã","type":1,"pageTitle":"AWS Trainium on EKS","url":"/data-on-eks/docs/blueprints/ai-ml/trainium#distributed-pytorch-training-on-trainium-with-torchx-and-eks","content":" In this example, we will perform DataParallel-based phase1 pretraining on the BERT-large model using the WikiCorpus dataset. To execute the task, we will use TorchX to initiate the job on two trn1.32xlarge instances, with 32 workers per instance. You can also run the same job on trn1n.32xlarge node group.  We have created three Shell scripts to automate the job execution as much as possible.  Step1: Create a Docker image for PyTorch Neuron container for BERT-large model pre-training‚Äã  This step creates a new Docker image and push this image to ECR repo. The Dockerfile handles the installation of necessary software packages, such as AWS Neuron repos, Python dependencies, and other essential tools for PyTorch and BERT pre-training. It configures various environment variables to ensure smooth execution and optimal performance. The image contains crucial components like a BERT pretraining script and requirements.txt file sourced from GitHub, both vital for the BERT pretraining process. Furthermore, it includes a basic environment test script for validation purposes. Together, this Docker image provides a comprehensive environment for efficient BERT pre-training with PyTorch while incorporating AWS Neuron optimizations.  caution This step generates an AMD64 (x86-64) Docker image with a size of 7GB or more. Therefore, it is strongly advised to utilize an AWS Cloud9/EC2 AMD64 (x86-64) instance with Docker client installed, ensuring sufficient storage capacity for this process.  caution If you are executing this script on a Cloud9 IDE/EC2 instance different from the one where the EKS Cluster is deployed, it is essential to ensure that the same IAM role is used or attached to the Cloud9 IDE/EC2 instance. Should you prefer a distinct IAM role for Cloud9 IDE/EC2, it must be added to the EKS Cluster's aws-auth config map to grant the role authorization for authenticating with the EKS Cluster. Taking these precautions will enable smooth communication between the instances and the EKS Cluster, ensuring the script functions as intended.  cd ai-ml/trainium-inferentia/examples/dp-bert-large-pretrain chomd +x 1-bert-pretrain-build-image.sh ./1-bert-pretrain-build-image.sh   Admin:~/environment/data-on-eks/ai-ml/trainium-inferentia/examples/dp-bert-large-pretrain (trainium-part2) $ ./1-bert-pretrain-build-image.sh Did you install docker on AMD64(x86-64) machine (y/n): y Enter the ECR region: us-west-2 ECR repository 'eks_torchx_test' already exists. Repository URL: &lt;YOUR_ACCOUNT_ID&gt;.dkr.ecr.us-west-2.amazonaws.com/eks_torchx_test Building and Tagging Docker image... &lt;YOUR_ACCOUNT_ID&gt;.dkr.ecr.us-west-2.amazonaws.com/eks_torchx_test:bert_pretrain [+] Building 2.4s (26/26) FINISHED =&gt; [internal] load build definition from Dockerfile.bert_pretrain 0.0s =&gt; =&gt; transferring dockerfile: 5.15kB 0.0s =&gt; [internal] load .dockerignore 0.0s =&gt; =&gt; transferring context: 2B 0.0s =&gt; [internal] load metadata for docker.io/library/ubuntu:20.04 0.7s =&gt; [ 1/22] FROM docker.io/library/ubuntu:20.04@sha256:c9820a44b950956a790c354700c1166a7ec648bc0d215fa438d3a339812f1d01 0.0s ... bert_pretrain: digest: sha256:1bacd5233d1a87ca1d88273c5a7cb131073c6f390f03198a91dc563158485941 size: 4729   Login to AWS Console and verify the ECR repo(&lt;YOUR_ACCOUNT_ID&gt;.dkr.ecr.&lt;REGION&gt;.amazonaws.com/eks_torchx_test) and the image tag(bert_pretrain) in ECR.  Step2: Copy WikiCorpus pre-training dataset for BERT model to FSx for Lustre filesystem‚Äã  In this step, we make it easy to transfer the WikiCorpus pre-training dataset, which is crucial for training the BERT model in distributed mode by multiple Trainium instances, to the FSx for Lustre filesystem. To achieve this, we will login to aws-cli-cmd-shell pod which includes an AWS CLI container, providing access to the filesystem.  Once you're inside the container, Copy the WikiCorpus dataset from S3 bucket (s3://neuron-s3/training_datasets/bert_pretrain_wikicorpus_tokenized_hdf5/bert_pretrain_wikicorpus_tokenized_hdf5_seqlen128.tar). The dataset is then unpacked, giving you access to its contents, ready for use in the subsequent BERT model pre-training process.  kubectl exec -i -t -n default aws-cli-cmd-shell -c app -- sh -c &quot;clear; (bash || ash || sh)&quot; # Once logged into the container yum install tar cd /data aws s3 cp s3://neuron-s3/training_datasets/bert_pretrain_wikicorpus_tokenized_hdf5/bert_pretrain_wikicorpus_tokenized_hdf5_seqlen128.tar . --no-sign-request chmod 744 bert_pretrain_wikicorpus_tokenized_hdf5_seqlen128.tar tar xvf bert_pretrain_wikicorpus_tokenized_hdf5_seqlen128.tar   Step3: Precompile the BERT graphs using neuron_parallel_compile‚Äã  PyTorch Neuron introduces a valuable tool known as neuron_parallel_compile, which significantly reduces graph compilation time by extracting model graphs and compiling them in parallel. This optimization technique expedites the process and results in faster model compilation. The compiled graphs are then stored on the Fsx for Lustre shared storage volume, accessible by worker nodes during model training. This efficient approach streamlines the training process and improves overall performance, making the most of PyTorch Neuron's capabilities.  Execute the following commands.This script prompts the user to configure their kubeconfig and verifies the presence of the lib folder with trn1_dist_ddp.py. It sets up Docker credentials, installs the TorchX client for Kubernetes. Using TorchX, the script runs a Kubernetes job to compile BERT graphs with optimized performance. Additionally, TorchX creates another Docker image and pushes it to the ECR repository within the same repo. This image is utilized in the subsequent pre-compiling pods, optimizing the overall BERT model training process.  cd ai-ml/trainium-inferentia/examples/dp-bert-large-pretrain chomd +x 2-bert-pretrain-precompile.sh ./2-bert-pretrain-precompile.sh   You can verify the pods status by running kubectl get pods or kubectl get vcjob. Successful output looks like below.    You can also verify the logs for the Pod once they are Succeeded. The precompilation job will run for ~15 minutes. Once complete, you will see the following in the output:  2023-07-29 09:42:42.000310: INFO ||PARALLEL_COMPILE||: Starting parallel compilations of the extracted graphs2023-07-29 09:42:42.000312: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.406_16969875447143373016.hlo.pb using following command: neuronx-cc compile ‚Äîtarget=trn1 ‚Äîframework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.406_16969875447143373016.hlo.pb ‚Äîmodel-type=transformer ‚Äîverbose=35 ‚Äîoutput /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.406_16969875447143373016.neff 2023-07-29 09:42:42.000313: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.22250_9219523464496887986.hlo.pb using following command: neuronx-cc compile ‚Äîtarget=trn1 ‚Äîframework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.22250_9219523464496887986.hlo.pb ‚Äîmodel-type=transformer ‚Äîverbose=35 ‚Äîoutput /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.22250_9219523464496887986.neff 2023-07-29 09:42:42.000314: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25434_3000743782456078279.hlo.pb using following command: neuronx-cc compile ‚Äîtarget=trn1 ‚Äîframework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25434_3000743782456078279.hlo.pb ‚Äîmodel-type=transformer ‚Äîverbose=35 ‚Äîoutput /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25434_3000743782456078279.neff 2023-07-29 09:42:42.000315: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25637_13822314547392343350.hlo.pb using following command: neuronx-cc compile ‚Äîtarget=trn1 ‚Äîframework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25637_13822314547392343350.hlo.pb ‚Äîmodel-type=transformer ‚Äîverbose=35 ‚Äîoutput /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.25637_13822314547392343350.neff 2023-07-29 09:42:42.000316: INFO ||PARALLEL_COMPILE||: Compiling /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21907_15179678551789598088.hlo.pb using following command: neuronx-cc compile ‚Äîtarget=trn1 ‚Äîframework XLA /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21907_15179678551789598088.hlo.pb ‚Äîmodel-type=transformer ‚Äîverbose=35 ‚Äîoutput /tmp/parallel_compile_workdir/MODULE_SyncTensorsGraph.21907_15179678551789598088.neff ..... Compiler status PASS   New pre-training cache files are stored under FSx for Lustre.    Step4: Launch BERT pretraining job using 64 Neuron cores with two trn1.32xlarge instances‚Äã  We are now in the final step of training the BERT-large model with WikiCorpus data.  cd ai-ml/trainium-inferentia/examples/dp-bert-large-pretrain chomd +x 3-bert-pretrain.sh ./3-bert-pretrain.sh   Monitor the job with the following commands. This job may take several hours as its training 30GB+ worth of the data.  kubectl get vcjob kubectl get pods # Two pods will be running in default namespace   To monitor Neuron usage, you can log in to one of the Trainium EC2 instances using SSM (Systems Manager) from the EC2 console. Once logged in, run the command neuron-ls, and you will receive an output similar to the following.  [root@ip-100-64-229-201 aws-efa-installer]# neuron-ls instance-type: trn1.32xlarge instance-id: i-04b476a6a0e686980 +--------+--------+--------+---------------+---------+--------+------------------------------------------+---------+ | NEURON | NEURON | NEURON | CONNECTED | PCI | PID | COMMAND | RUNTIME | | DEVICE | CORES | MEMORY | DEVICES | BDF | | | VERSION | +--------+--------+--------+---------------+---------+--------+------------------------------------------+---------+ | 0 | 2 | 32 GB | 12, 3, 4, 1 | 10:1c.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 | | 1 | 2 | 32 GB | 13, 0, 5, 2 | 10:1d.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 | | 2 | 2 | 32 GB | 14, 1, 6, 3 | a0:1c.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 | | 3 | 2 | 32 GB | 15, 2, 7, 0 | a0:1d.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 | | 4 | 2 | 32 GB | 0, 7, 8, 5 | 20:1b.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 | | 5 | 2 | 32 GB | 1, 4, 9, 6 | 20:1c.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 | | 6 | 2 | 32 GB | 2, 5, 10, 7 | 90:1b.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 | | 7 | 2 | 32 GB | 3, 6, 11, 4 | 90:1c.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 | | 8 | 2 | 32 GB | 4, 11, 12, 9 | 20:1d.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 | | 9 | 2 | 32 GB | 5, 8, 13, 10 | 20:1e.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 | | 10 | 2 | 32 GB | 6, 9, 14, 11 | 90:1d.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 | | 11 | 2 | 32 GB | 7, 10, 15, 8 | 90:1e.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 | | 12 | 2 | 32 GB | 8, 15, 0, 13 | 10:1e.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 | | 13 | 2 | 32 GB | 9, 12, 1, 14 | 10:1b.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 | | 14 | 2 | 32 GB | 10, 13, 2, 15 | a0:1e.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 | | 15 | 2 | 32 GB | 11, 14, 3, 12 | a0:1b.0 | 109459 | python3 -m torch_neuronx.distributed.... | 2.15.11 | +--------+--------+--------+---------------+---------+--------+------------------------------------------+---------+   You can also run neuron-top which provides the live usage of neuron cores. The below shows the usage of all 32 neuron cores.    If you wish to terminate the job, you can execute the following commands:  kubectl get vcjob # Get a job name kubectl delete &lt;ENTER_JOB_NAME&gt;   Cleanup üëà  caution To avoid unwanted charges to your AWS account, delete all the AWS resources created during this deployment ","version":"Next","tagName":"h3"},{"title":"EMR on EKS NVIDIA RAPIDS Accelerator for Apache Spark","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/ai-ml/emr-spark-rapids","content":"","keywords":"","version":"Next"},{"title":"EMR support for NVIDIA RAPIDS Accelerator for Apache Spark‚Äã","type":1,"pageTitle":"EMR on EKS NVIDIA RAPIDS Accelerator for Apache Spark","url":"/data-on-eks/docs/blueprints/ai-ml/emr-spark-rapids#emr-support-for-nvidia-rapids-accelerator-for-apache-spark","content":" Integration of Amazon EMR with NVIDIA RAPIDS Accelerator for Apache Spark‚Äã Amazon EMR on EKS now extends its support to include the use of GPU instance types with the NVIDIA RAPIDS Accelerator for Apache Spark. As the use of artificial intelligence (AI) and machine learning (ML) continues to expand in the realm of data analytics, there's an increasing demand for rapid and cost-efficient data processing, which GPUs can provide. The NVIDIA RAPIDS Accelerator for Apache Spark enables users to harness the superior performance of GPUs, leading to substantial infrastructure cost savings.  ","version":"Next","tagName":"h3"},{"title":"Features‚Äã","type":1,"pageTitle":"EMR on EKS NVIDIA RAPIDS Accelerator for Apache Spark","url":"/data-on-eks/docs/blueprints/ai-ml/emr-spark-rapids#features","content":" Highlighted Features‚Äã Experience a performance boost in data preparation tasks, allowing you to transition quickly to the subsequent stages of your pipeline. This not only accelerates model training but also liberates data scientists and engineers to concentrate on priority tasks. Spark 3 ensures seamless coordination of end-to-end pipelines - from data ingestion, through model training, to visualization. The same GPU-accelerated setup can serve both Spark and machine learning or deep learning frameworks. This obviates the need for discrete clusters and provides GPU acceleration to the entire pipeline. Spark 3 extends support for columnar processing in the Catalyst query optimizer. The RAPIDS Accelerator can plug into this system to speed up SQL and DataFrame operators. When the query plan is actioned, these operators can then utilize the GPUs within the Spark cluster for improved performance. NVIDIA has introduced an innovative Spark shuffle implementation designed to optimize data exchange between Spark tasks. This shuffle system is built on GPU-boosted communication libraries, including UCX, RDMA, and NCCL, which significantly enhance data transfer rates and overall performance.-  Deploying the Solution üëà  ","version":"Next","tagName":"h3"},{"title":"Launching XGBoost Spark Job‚Äã","type":1,"pageTitle":"EMR on EKS NVIDIA RAPIDS Accelerator for Apache Spark","url":"/data-on-eks/docs/blueprints/ai-ml/emr-spark-rapids#launching-xgboost-spark-job","content":" Training Dataset‚Äã  Fannie Mae‚Äôs Single-Family Loan Performance Data has a comprehensive dataset starting from 2013. It provides valuable insights into the credit performance of a portion of Fannie Mae‚Äôs single-family book of business. This dataset is designed to assist investors in better understanding the credit performance of single-family loans owned or guaranteed by Fannie Mae.  Step 1: Building a Custom Docker Image‚Äã  To pull the Spark Rapids base image from the EMR on EKS ECR repository located in us-west-2, log in:  aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 895885662937.dkr.ecr.us-west-2.amazonaws.com   If you're located in a different region, please refer to: this guide.  To build your Docker image locally, use the following command:  Build the custom Docker image using the provided Dockerfile. Choose a tag for the image, such as 0.10.  info Please note that the build process may take some time, depending on your network speed. Keep in mind that the resulting image size will be approximately 23.5GB.  cd ~/data-on-eks/ai-ml/emr-spark-rapids/examples/xgboost docker build -t emr-6.10.0-spark-rapids-custom:0.10 -f Dockerfile .   Replace &lt;ACCOUNTID&gt; with your AWS account ID. Log in to your ECR repository with the following command:  aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin &lt;ACCOUNTID&gt;.dkr.ecr.us-west-2.amazonaws.com   To push your Docker image to your ECR, use:  $ docker tag emr-6.10.0-spark-rapids-custom:0.10 &lt;ACCOUNT_ID&gt;.dkr.ecr.us-west-2.amazonaws.com/emr-6.10.0-spark-rapids-custom:0.10 $ docker push &lt;ACCOUNT_ID&gt;.dkr.ecr.us-west-2.amazonaws.com/emr-6.10.0-spark-rapids-custom:0.10   You can use this image during the job execution in Step3 .  ","version":"Next","tagName":"h3"},{"title":"Step2: Acquire the Input Data (Fannie Mae‚Äôs Single-Family Loan Performance Data)‚Äã","type":1,"pageTitle":"EMR on EKS NVIDIA RAPIDS Accelerator for Apache Spark","url":"/data-on-eks/docs/blueprints/ai-ml/emr-spark-rapids#step2-acquire-the-input-data-fannie-maes-single-family-loan-performance-data","content":" This dataset is sourced from Fannie Mae‚Äôs Single-Family Loan Performance Data. All rights are held by Fannie Mae.  Go to the Fannie Mae websiteClick on Single-Family Loan Performance Data Register as a new user if you are using the website for the first timeUse the credentials to login Select HPClick on Download Data and choose Single-Family Loan Performance DataYou will find a tabular list of Acquisition and Performance` files sorted based on year and quarter. Click on the file to download. You can download three years(2020, 2021 and 2022 - 4 files for each year and one for each quarter) worth of data that will be used in our example job. e.g.,: 2017Q1.zipUnzip the download file to extract the csv file to your local machine. e.g.,: 2017Q1.csvCopy only the CSV files to an S3 bucket under ${S3_BUCKET}/${EMR_VIRTUAL_CLUSTER_ID}/spark-rapids-emr/input/fannie-mae-single-family-loan-performance/. The example below uses three years of data (one file for each quarter, 12 files in total). Note: ${S3_BUCKET} and ${EMR_VIRTUAL_CLUSTER_ID} values can be extracted from Terraform outputs.   aws s3 ls s3://emr-spark-rapids-&lt;aws-account-id&gt;-us-west-2/949wt7zuphox1beiv0i30v65i/spark-rapids-emr/input/fannie-mae-single-family-loan-performance/ 2023-06-24 21:38:25 2301641519 2000Q1.csv 2023-06-24 21:38:25 9739847213 2020Q2.csv 2023-06-24 21:38:25 10985541111 2020Q3.csv 2023-06-24 21:38:25 11372073671 2020Q4.csv 2023-06-23 16:38:36 9603950656 2021Q1.csv 2023-06-23 16:38:36 7955614945 2021Q2.csv 2023-06-23 16:38:36 5365827884 2021Q3.csv 2023-06-23 16:38:36 4390166275 2021Q4.csv 2023-06-22 19:20:08 2723499898 2022Q1.csv 2023-06-22 19:20:08 1426204690 2022Q2.csv 2023-06-22 19:20:08 595639825 2022Q3.csv 2023-06-22 19:20:08 180159771 2022Q4.csv   ","version":"Next","tagName":"h3"},{"title":"Step3: Run the EMR Spark XGBoost Job‚Äã","type":1,"pageTitle":"EMR on EKS NVIDIA RAPIDS Accelerator for Apache Spark","url":"/data-on-eks/docs/blueprints/ai-ml/emr-spark-rapids#step3-run-the-emr-spark-xgboost-job","content":" Here, we will utilize a helper shell script to execute the job. This script requires user input.  This script will ask for certain inputs that you can obtain from Terraform outputs. See the example below.  cd ai-ml/emr-spark-rapids/examples/xgboost/ &amp;&amp; chmod +x execute_spark_rapids_xgboost.sh ./execute_spark_rapids_xgboost.sh # Example inputs shown below Did you copy the fannie-mae-single-family-loan-performance data to S3 bucket(y/n): y Enter the customized Docker image URI: public.ecr.aws/o7d8v7g9/emr-6.10.0-spark-rapids:0.11 Enter EMR Virtual Cluster AWS Region: us-west-2 Enter the EMR Virtual Cluster ID: 949wt7zuphox1beiv0i30v65i Enter the EMR Execution Role ARN: arn:aws:iam::&lt;ACCOUNTID&gt;:role/emr-spark-rapids-emr-eks-data-team-a Enter the CloudWatch Log Group name: /emr-on-eks-logs/emr-spark-rapids/emr-ml-team-a Enter the S3 Bucket for storing PySpark Scripts, Pod Templates, Input data and Output data.&lt;bucket-name&gt;: emr-spark-rapids-&lt;ACCOUNTID&gt;-us-west-2 Enter the number of executor instances (4 to 8): 8   Verify the pod status    info Note that the first execution might take longer as it needs to download the image for the EMR Job Pod, Driver, and Executor pods. Each pod may take up to 8 minutes to download the Docker image. Subsequent runs should be faster (usually under 30 seconds), thanks to image caching  ","version":"Next","tagName":"h3"},{"title":"Step4: Verify the Job results‚Äã","type":1,"pageTitle":"EMR on EKS NVIDIA RAPIDS Accelerator for Apache Spark","url":"/data-on-eks/docs/blueprints/ai-ml/emr-spark-rapids#step4-verify-the-job-results","content":" Log in to check the Spark driver pod logs from either CloudWatch logs or your S3 bucket.  Here's a sample output from the log file:  /emr-on-eks-logs/emr-spark-rapids/emr-ml-team-a spark-rapids-emr/949wt7zuphox1beiv0i30v65i/jobs/0000000327fe50tosa4/containers/spark-0000000327fe50tosa4/spark-0000000327fe50tosa4-driver/stdout   The following is a sample output from the above log file:  Raw Dataframe CSV Rows count : 215386024 Raw Dataframe Parquet Rows count : 215386024 ETL takes 222.34674382209778  Training takes 95.90932035446167 seconds If features_cols param set, then features_col param is ignored.  Transformation takes 63.999391317367554 seconds +--------------+--------------------+--------------------+----------+ |delinquency_12| rawPrediction| probability|prediction| +--------------+--------------------+--------------------+----------+ | 0|[10.4500541687011...|[0.99997103214263...| 0.0| | 0|[10.3076572418212...|[0.99996662139892...| 0.0| | 0|[9.81707763671875...|[0.99994546175003...| 0.0| | 0|[9.10498714447021...|[0.99988889694213...| 0.0| | 0|[8.81903457641601...|[0.99985212087631...| 0.0| +--------------+--------------------+--------------------+----------+ only showing top 5 rows  Evaluation takes 3.8372223377227783 seconds Accuracy is 0.996563056111921  ","version":"Next","tagName":"h3"},{"title":"ML Pipeline for Fannie Mae Single Loan Performance Dataset‚Äã","type":1,"pageTitle":"EMR on EKS NVIDIA RAPIDS Accelerator for Apache Spark","url":"/data-on-eks/docs/blueprints/ai-ml/emr-spark-rapids#ml-pipeline-for-fannie-mae-single-loan-performance-dataset","content":" Step1: Preprocess and clean the dataset to handle missing values, categorical variables, and other data inconsistencies.This may involve techniques like data imputation,one-hot encoding, and data normalization.  Step2: Create additional features from the existing ones that might provide more useful information for predicting loan performance. For example, you could extract features like loan-to-value ratio, borrower's credit score range, or loan origination year.  Step3: Divide the dataset into two parts: one for training the XGBoost model and one for evaluating its performance. This allows you to assess how well the model generalizes to unseen data.  Step4: Feed the training dataset into XGBoost to train the model. XGBoost will analyze the loan attributes and their corresponding loan performance labels to learn the patterns and relationships between them. The objective is to predict whether a loan is likely to default or perform well based on the given features.  Step5: Once the model is trained, use the evaluation dataset to assess its performance. This involves analyzing metrics such as accuracy, precision, recall, or area under the receiver operating characteristic curve (AUC-ROC) to measure how well the model predicts loan performance  Step6: If the performance is not satisfactory, you can tune the XGBoost hyperparameters, such as the learning rate, tree depth, or regularization parameters, to improve the model's accuracy or address issues like overfitting.  Step7: Finally, with a trained and validated XGBoost model, you can use it to make predictions on new, unseen loan data. These predictions can help in identifying potential risks associated with loan default or evaluating loan performance.    ","version":"Next","tagName":"h3"},{"title":"GPU Monitoring with DCGM Exporter, Prometheus and Grafana‚Äã","type":1,"pageTitle":"EMR on EKS NVIDIA RAPIDS Accelerator for Apache Spark","url":"/data-on-eks/docs/blueprints/ai-ml/emr-spark-rapids#gpu-monitoring-with-dcgm-exporter-prometheus-and-grafana","content":" Observability plays a crucial role in managing and optimizing hardware resources such as GPUs, particularly in machine learning workloads where the GPU utilization is high. The ability to monitor GPU usage in real-time, identify trends, and detect anomalies can significantly impact performance tuning, troubleshooting, and efficient resource utilization.  NVIDIA GPU Operator plays a key role in GPU observability. It automates the deployment of the necessary components to run GPU workloads on Kubernetes. One of its components, the DCGM (Data Center GPU Manager) Exporter, is an open-source project that exports GPU metrics in a format that can be ingested by Prometheus, a leading open-source monitoring solution. These metrics include GPU temperature, memory usage, GPU utilization, and more. The DCGM Exporter allows you to monitor these metrics on a per-GPU basis, providing granular visibility into your GPU resources.  The NVIDIA GPU Operator, in combination with the DCGM Exporter, exports GPU metrics to a Prometheus server. With its flexible query language, Prometheus allows you to slice and dice data to generate insights into resource usage patterns.  However, Prometheus is not designed for long-term data storage. This is where the Amazon Managed Service for Prometheus (AMP) comes into play. It provides a fully-managed, secure, and scalable service for Prometheus that makes it easy to analyze operational data at scale without having to manage the underlying infrastructure.  Visualizing these metrics and creating informative dashboards is where Grafana excels. Grafana is an open-source platform for monitoring and observability, offering rich visualizations to represent collected metrics intuitively. When combined with Prometheus, Grafana can display the GPU metrics collected by the DCGM Exporter in a user-friendly manner.  The NVIDIA GPU Operator is configured to export metrics to the Prometheus server, which then remote-writes these metrics to Amazon Managed Prometheus (AMP). As a user, you can log into the Grafana WebUI, deployed as part of the blueprint, and add AMP as a data source. Following this, you can import the open-source GPU monitoring dashboard that presents GPU metrics in an easily digestible format, facilitating real-time performance monitoring and resource optimization.  NVIDIA GPU Operator: Installed on your Kubernetes cluster, the NVIDIA GPU Operator is responsible for managing the lifecycle of GPU resources. It deploys NVIDIA drivers and the DCGM Exporter on each GPU-equipped node.DCGM Exporter: The DCGM Exporter runs on each node, collecting GPU metrics and exposing them to Prometheus.Prometheus: Prometheus is a time-series database that collects metrics from various sources, including the DCGM Exporter. It pulls metrics from the exporter at regular intervals and stores them. In this setup, you would configure Prometheus to remote-write the collected metrics to AMP.Amazon Managed Service for Prometheus (AMP): AMP is a fully-managed Prometheus service provided by AWS. It takes care of long-term storage, scalability, and security of your Prometheus data.Grafana: Grafana is a visualization tool that can query AMP for the collected metrics, and display them on informative dashboards.  In this blueprint, we leverage DCGM to write GPU metrics to both Prometheus and Amazon Managed Prometheus (AMP). To verify the GPU metrics, you can use Grafana by running the following command:  kubectl port-forward svc/grafana 3000:80 -n grafana `` Login to Grafana using `admin` as the username, and retrieve the password from Secrets Manager using the following AWS CLI command: ```bash aws secretsmanager get-secret-value --secret-id emr-spark-rapids-grafana --region us-west-2   Once logged in, add the AMP datasource to Grafana and import the Open Source GPU monitoring dashboard. You can then explore the metrics and visualize them using the Grafana dashboard, as shown in the screenshot below.    Cleanup üëà  caution To avoid unwanted charges to your AWS account, delete all the AWS resources created during this deployment ","version":"Next","tagName":"h3"},{"title":"EMR on EKS with CDK blueprint","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-cdk","content":"","keywords":"","version":"Next"},{"title":"Introduction‚Äã","type":1,"pageTitle":"EMR on EKS with CDK blueprint","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-cdk#introduction","content":" In this post, we will learn how to use EMR on EKS AddOn and Teams in the cdk-eks-blueprints to deploy a an infrasturcture on EKS to submit Spark Job. The cdk-eks-blueprints allows you deploy an EKS cluster and enable it to be used by EMR on EKS service with minimal setup. The architecture below shows a conceptual view of the infrastructure you will deploy through this blueprint.    ","version":"Next","tagName":"h2"},{"title":"Deploying the Solution‚Äã","type":1,"pageTitle":"EMR on EKS with CDK blueprint","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-cdk#deploying-the-solution","content":" In this example, you will provision the following:  Creates EKS Cluster Control plane with public endpoint (for demo purpose only)Two managed node groups Core Node group with 3 AZs for running system critical pods. e.g., Cluster Autoscaler, CoreDNS, Logging etc.Spark Node group with single AZ for running Spark jobs Enable EMR on EKS and create one Data teams (emr-data-team-a) Creates new namespace for each teamCreates Kubernetes role and role binding(emr-containers user) for the above namespaceNew IAM role for the team execution roleUpdate AWS_AUTH config map with emr-containers user and AWSServiceRoleForAmazonEMRContainers roleCreate a trust relationship between the job execution role and the identity of the EMR managed service account EMR Virtual Cluster for emr-data-team-aIAM policy for emr-data-team-aDeploys the following Kubernetes Add-ons Managed Add-ons VPC CNI, CoreDNS, KubeProxy, AWS EBS CSi Driver Self Managed Add-ons Metrics server with HA, Cluster Autoscaler, CertManager and AwsLoadBalancerController  This blueprint can also take an EKS cluster that you defined using the cdk-blueprints-library.  ","version":"Next","tagName":"h2"},{"title":"Prerequisites‚Äã","type":1,"pageTitle":"EMR on EKS with CDK blueprint","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-cdk#prerequisites","content":" Ensure that you have installed the following tools on your machine.  aws clikubectlCDK  NOTE: You need to have an AWS account and region that are bootstrapped by AWS CDK.  ","version":"Next","tagName":"h3"},{"title":"Customize‚Äã","type":1,"pageTitle":"EMR on EKS with CDK blueprint","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-cdk#customize","content":" The the entry point for this cdk blueprint is /bin/emr-eks.ts which instantiate a stack defined in lib/emr-eks-blueprint-stack.ts. This stack must be provided with a VPC and a list of EMR on EKS team definition and the role that will be admin of the EKS cluster. It can also take as options an EKS cluster defined through cdk-blueprints-library and the EKS cluster name.  The properties that are passed to the emr on eks blueprint stack are defined as such:  export interface EmrEksBlueprintProps extends StackProps { clusterVpc: IVpc, clusterAdminRoleArn: ArnPrincipal dataTeams: EmrEksTeamProps[], eksClusterName?: string, //Default eksBlueprintCluster eksCluster?: GenericClusterProvider, }   In this example we define a VPC in lib/vpc.ts and is instantiated in bin/emr-eks.ts. We also define a team called emr-data-team-a and which has an execution role called myBlueprintExecRole. The blueprint will deploy by default an EKS cluster with the managed nodegroups defined in the section Deploying the Solution.  ","version":"Next","tagName":"h3"},{"title":"Deploy‚Äã","type":1,"pageTitle":"EMR on EKS with CDK blueprint","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-cdk#deploy","content":" Before you run the solution, you MUST change the clusterAdminRoleArn of the props object in lib/emr-eks.ts. This role allows you to interact manage EKS cluster and should have be allowed at least the IAM action eks:AccessKubernetesApi.  Clone the repository  git clone https://github.com/awslabs/data-on-eks.git   Navigate into one of the example directories and run cdk synth  cd analytics/cdk/emr-eks npm install cdk synth --profile YOUR-AWS-PROFILE   Deploy the pattern  cdk deploy --all   Enter yes to deploy.  ","version":"Next","tagName":"h3"},{"title":"Verify the resources‚Äã","type":1,"pageTitle":"EMR on EKS with CDK blueprint","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-cdk#verify-the-resources","content":" Let‚Äôs verify the resources created by cdk deploy.  Verify the Amazon EKS Cluster  aws eks describe-cluster --name eksBlueprintCluster # Update the name cluster name if you supplied your own   Verify EMR on EKS Namespaces batchjob and Pod status for Metrics Server and Cluster Autoscaler.  aws eks --region &lt;ENTER_YOUR_REGION&gt; update-kubeconfig --name eksBlueprintCluster # Creates k8s config file to authenticate with EKS Cluster. Update the name cluster name if you supplied your own kubectl get nodes # Output shows the EKS Managed Node group nodes kubectl get ns | grep batchjob # Output shows batchjob kubectl get pods --namespace=kube-system | grep metrics-server # Output shows Metric Server pod kubectl get pods --namespace=kube-system | grep cluster-autoscaler # Output shows Cluster Autoscaler pod   ","version":"Next","tagName":"h2"},{"title":"Execute Sample Spark job on EMR Virtual Cluster‚Äã","type":1,"pageTitle":"EMR on EKS with CDK blueprint","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-cdk#execute-sample-spark-job-on-emr-virtual-cluster","content":" Execute the Spark job using the below shell script.  Once you deploy the blueprint you will have as output the Virtual Cluster id. You can use the id and the execution role for which you supplied a policy to submit jobs. Below you can find an example of a job you can submit with AWS CLI.   export EMR_ROLE_ARN=arn:aws:iam::&lt;YOUR-ACCOUNT-ID&gt;:role/myBlueprintExecRole aws emr-containers start-job-run \\ --virtual-cluster-id=&lt;VIRTUAL-CLUSTER-ID-IN-CDK-OUTPUT&gt; \\ --name=pi-2 \\ --execution-role-arn=$EMR_ROLE_ARN \\ --release-label=emr-6.8.0-latest \\ --job-driver='{ &quot;sparkSubmitJobDriver&quot;: { &quot;entryPoint&quot;: &quot;local:///usr/lib/spark/examples/src/main/python/pi.py&quot;, &quot;sparkSubmitParameters&quot;: &quot;--conf spark.executor.instances=1 --conf spark.executor.memory=2G --conf spark.executor.cores=1 --conf spark.driver.cores=1 --conf spark.kubernetes.node.selector.app=spark&quot; } }'   Verify the job execution  kubectl get pods --namespace=batchjob -w   ","version":"Next","tagName":"h2"},{"title":"Cleanup‚Äã","type":1,"pageTitle":"EMR on EKS with CDK blueprint","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-cdk#cleanup","content":" To clean up your environment, you call the command below. This will destroy the Kubernetes Add-ons, EKS cluster with Node groups and VPC  cdk destroy --all   caution To avoid unwanted charges to your AWS account, delete all the AWS resources created during this deployment ","version":"Next","tagName":"h2"},{"title":"EMR on EKS Observability","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-observability","content":"","keywords":"","version":"Next"},{"title":"Monitoring Amazon EMR on EKS with Amazon Managed Prometheus and Amazon Managed Grafana‚Äã","type":1,"pageTitle":"EMR on EKS Observability","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-observability#monitoring-amazon-emr-on-eks-with-amazon-managed-prometheus-and-amazon-managed-grafana","content":" In this post, we will learn to build end-to-end observability for EMR on EKS Spark workloads by leveraging Amazon Managed Service for Prometheus to collect and store the metrics generated by Spark Applications. We will then use Amazon Managed Grafana to build dashboards for monitoring use cases  Checkout the full blog here  ","version":"Next","tagName":"h2"},{"title":"Architecture‚Äã","type":1,"pageTitle":"EMR on EKS Observability","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-observability#architecture","content":" The following diagram illustrates the solution architecture for scraping Spark Driver and Executors‚Äô metrics, as well as writing to Amazon Managed Service for Prometheus.    ","version":"Next","tagName":"h3"},{"title":"Grafana Dashboard for Spark‚Äã","type":1,"pageTitle":"EMR on EKS Observability","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-observability#grafana-dashboard-for-spark","content":" The following Grafana dashboard displays the EMR on EKS Spark job metrics with Driver and Executor details.   ","version":"Next","tagName":"h3"},{"title":"EMR Virtual Cluster on EKS Fargate","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-fargate","content":"","keywords":"","version":"Next"},{"title":"Prerequisites:‚Äã","type":1,"pageTitle":"EMR Virtual Cluster on EKS Fargate","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-fargate#prerequisites","content":" Ensure that you have the following tools installed locally:  aws clikubectlterraform  ","version":"Next","tagName":"h2"},{"title":"Deploy‚Äã","type":1,"pageTitle":"EMR Virtual Cluster on EKS Fargate","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-fargate#deploy","content":" Clone the repository  git clone https://github.com/awslabs/data-on-eks.git   Navigate into one of the example directories and run terraform init  cd data-on-eks/analytics/emr-eks-fargate terraform init   Set AWS_REGION and Runterraform plan to verify the resources created by this execution.  export AWS_REGION=&quot;us-west-2&quot; # Change according to your need terraform plan   Deploy the pattern  terraform apply   Enter yes at command prompt to apply  ","version":"Next","tagName":"h3"},{"title":"Validate‚Äã","type":1,"pageTitle":"EMR Virtual Cluster on EKS Fargate","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-fargate#validate","content":" The following command will update the kubeconfig on your local machine and allow you to interact with your EKS Cluster using kubectl.  Run update-kubeconfig command:  aws eks --region &lt;REGION&gt; update-kubeconfig --name &lt;CLUSTER_NAME&gt;   Test by listing all the pods running currently. Note: the EMR on EKS virtual cluster(s) will create pods as needed to execute jobs and the pods shown will vary depending on how long after deploying the example you run the kubectl get pods -A command:  kubectl get pods -A # Output should look like below NAMESPACE NAME READY STATUS RESTARTS AGE kube-system cluster-proportional-autoscaler-coredns-6ccfb4d9b5-sjb8m 1/1 Running 0 8m27s kube-system coredns-7c8d74d658-9cmn2 1/1 Running 0 8m27s kube-system coredns-7c8d74d658-pmf5l 1/1 Running 0 7m38s   Execute the sample EMR on EKS job. This will calculate the value of Pi using sample PySpark job.  cd analytics/terraform/emr-eks-fargate/examples ./basic-pyspark-job '&lt;ENTER_EMR_EMR_VIRTUAL_CLUSTER_ID&gt;' '&lt;EMR_JOB_EXECUTION_ROLE_ARN&gt;'   Once the job is complete, navigate to the CloudWatch log console and find the log group created by this example /emr-on-eks-logs/emr-workload/emr-workload. Click Search Log Group and enter roughly into the search field. You should see a log entry that has the returned results from the job.  { &quot;message&quot;: &quot;Pi is roughly 3.146360&quot;, &quot;time&quot;: &quot;2022-11-20T16:46:59+00:00&quot; }   ","version":"Next","tagName":"h2"},{"title":"Destroy‚Äã","type":1,"pageTitle":"EMR Virtual Cluster on EKS Fargate","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-fargate#destroy","content":" To teardown and remove the resources created in this example:  kubectl delete all --all -n emr-workload -n emr-custom # ensure all jobs resources are cleaned up first terraform destroy -target=&quot;module.eks_blueprints_kubernetes_addons&quot; -auto-approve terraform destroy -target=&quot;module.eks&quot; -auto-approve terraform destroy -auto-approve   If the EMR virtual cluster fails to delete and the following error is shown:  Error: waiting for EMR Containers Virtual Cluster (xwbc22787q6g1wscfawttzzgb) delete: unexpected state 'ARRESTED', wanted target ''. last error: %!s(&lt;nil&gt;)   You can clean up any of the clusters in the ARRESTED state with the following:  aws emr-containers list-virtual-clusters --region us-west-2 --states ARRESTED \\ --query 'virtualClusters[0].id' --output text | xargs -I{} aws emr-containers delete-virtual-cluster \\ --region us-west-2 --id {}  ","version":"Next","tagName":"h2"},{"title":"Data Analytics on EKS","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/data-analytics","content":"Data Analytics on EKS Running data analytics tools on Kubernetes can provide a number of benefits for organizations looking to extract insights from large and complex data sets. Tools such as Apache Spark and DASK are designed to run on a cluster of machines, making them well-suited for deployment on Kubernetes. The Spark Operator for Kubernetes is a popular Kubernetes operator that simplifies the deployment and management of Apache Spark on Kubernetes. By using the Spark Operator, organizations can take advantage of features such as automatic scaling, rolling updates, and self-healing capabilities to ensure high availability and reliability of their data analytics pipelines. This can greatly simplify and automate the deployment, scaling, and management of these complex applications, freeing up data scientists and engineers to focus on the analysis and interpretation of the data. With its growing ecosystem of tools and support for a wide range of use cases, Kubernetes is becoming an increasingly popular choice for running data analytics platforms in production. Spark OperatorSpark SubmitKarpenterApache YuniKornVolcano","keywords":"","version":"Next"},{"title":"EMR Runtime with Spark Operator","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-spark-operator","content":"","keywords":"","version":"Next"},{"title":"Introduction‚Äã","type":1,"pageTitle":"EMR Runtime with Spark Operator","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-spark-operator#introduction","content":" In this post, we will learn to deploy EKS with EMR Spark Operator and execute sample Spark job with EMR runtime.  In this example, you will provision the following resources required to run Spark Applications using the Spark Operator and EMR runtime.  Creates EKS Cluster Control plane with public endpoint (for demo purpose only)Two managed node groups Core Node group with 3 AZs for running system critical pods. e.g., Cluster Autoscaler, CoreDNS, Observability, Logging etc.Spark Node group with single AZ for running Spark jobs Creates one Data team (emr-data-team-a) Creates new namespace for the teamNew IAM role for the team execution role IAM policy for emr-data-team-aSpark History Server Live UI is configured for monitoring running Spark jobs through an NLB and NGINX ingress controllerDeploys the following Kubernetes Add-ons Managed Add-ons VPC CNI, CoreDNS, KubeProxy, AWS EBS CSi Driver Self Managed Add-ons Metrics server with HA, CoreDNS Cluster proportional Autoscaler, Cluster Autoscaler, Prometheus Server and Node Exporter, AWS for FluentBit, CloudWatchMetrics for EKS  EMR Spark Operator üëà  Deploying the Solution üëà  Execute Sample Spark job with Karpenter üëà  Cleanup üëà  caution To avoid unwanted charges to your AWS account, delete all the AWS resources created during this deployment ","version":"Next","tagName":"h2"},{"title":"Observability Spark on EKS","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/data-analytics/observability-spark-on-eks","content":"","keywords":"","version":"Next"},{"title":"Introduction‚Äã","type":1,"pageTitle":"Observability Spark on EKS","url":"/data-on-eks/docs/blueprints/data-analytics/observability-spark-on-eks#introduction","content":" In this post, we will learn the Observability for Spark on EKS. We will use Spark History Server to watch Spark Applications logs and check the Spark job progress via the Spark Web UI. Amazon Managed Service for Prometheus is used to collect and store the metrics generated by Spark Applications and Grafana is used to build dashboards for monitoring use cases.  ","version":"Next","tagName":"h2"},{"title":"Deploying the Solution‚Äã","type":1,"pageTitle":"Observability Spark on EKS","url":"/data-on-eks/docs/blueprints/data-analytics/observability-spark-on-eks#deploying-the-solution","content":" We will reuse the previous Spark on Operator example. Please follow this link to provision resources  ","version":"Next","tagName":"h2"},{"title":"Set up data and py script‚Äã","type":1,"pageTitle":"Observability Spark on EKS","url":"/data-on-eks/docs/blueprints/data-analytics/observability-spark-on-eks#set-up-data-and-py-script","content":" let's navigate to one example folder under spark-k8s-operator and run the shell script to upload data and py script to the S3 bucket created by terraform above.  cd data-on-eks/analytics/terraform/spark-k8s-operator/examples/cluster-autoscaler/nvme-ephemeral-storage # replace \\&lt;S3_BUCKET\\&gt; with your S3 bucket and \\&lt;REGION\\&gt; with your region, then run ./taxi-trip-execute.sh   ","version":"Next","tagName":"h2"},{"title":"Spark Web UI‚Äã","type":1,"pageTitle":"Observability Spark on EKS","url":"/data-on-eks/docs/blueprints/data-analytics/observability-spark-on-eks#spark-web-ui","content":" When you submit a Spark application, Spark context is created which ideally gives you Spark Web UI to monitor the execution of the application. Monitoring includes the following.  Spark configurations usedSpark Jobs, stages, and tasks detailsDAG executionDriver and Executor resource utilizationApplication logs and many more   When your application is done with the processing, Spark context will be terminated so your Web UI as well. and if you wanted to see the monitoring for already finished application, we cannot do it.  To try Spark web UI, let's update &lt;S3_BUCKET&gt; with your bucket name and &lt;JOB_NAME&gt; with &quot;nvme-taxi-trip&quot; in nvme-ephemeral-storage.yaml   kubectl apply -f nvme-ephemeral-storage.yaml   Then run port forward command to expose spark web service.  kubectl port-forward po/taxi-trip 4040:4040 -nspark-team-a   Then open browser and enter localhost:4040. You can view your spark application like below.    ","version":"Next","tagName":"h2"},{"title":"Spark History Server‚Äã","type":1,"pageTitle":"Observability Spark on EKS","url":"/data-on-eks/docs/blueprints/data-analytics/observability-spark-on-eks#spark-history-server","content":" As mentioned above, spark web UI will be terminated once the spark job is done. This is where Spark history Server comes into the picture, where it keeps the history (event logs) of all completed applications and its runtime information which allows you to review metrics and monitor the application later in time.  In this example, we installed Spark history Server to read logs from S3 bucket. In your spark application yaml file, make sure you have the following setting:   sparkConf: &quot;spark.hadoop.fs.s3a.aws.credentials.provider&quot;: &quot;com.amazonaws.auth.InstanceProfileCredentialsProvider&quot; &quot;spark.hadoop.fs.s3a.impl&quot;: &quot;org.apache.hadoop.fs.s3a.S3AFileSystem&quot; &quot;spark.eventLog.enabled&quot;: &quot;true&quot; &quot;spark.eventLog.dir&quot;: &quot;s3a://&lt;your bucket&gt;/logs/&quot;   Run port forward command to expose spark-history-server service.  kubectl port-forward services/spark-history-server 18085:80 -n spark-history-server   Then open browser and enter localhost:18085. You can view your spark history server like below.  ","version":"Next","tagName":"h2"},{"title":"Prometheus‚Äã","type":1,"pageTitle":"Observability Spark on EKS","url":"/data-on-eks/docs/blueprints/data-analytics/observability-spark-on-eks#prometheus","content":" Spark users must add the following config to spark application yaml file to extract the metrics from Spark Driver and Executors. In the example, they are added into nvme-ephemeral-storage.yaml already.  &quot;spark.ui.prometheus.enabled&quot;: &quot;true&quot; &quot;spark.executor.processTreeMetrics.enabled&quot;: &quot;true&quot; &quot;spark.kubernetes.driver.annotation.prometheus.io/scrape&quot;: &quot;true&quot; &quot;spark.kubernetes.driver.annotation.prometheus.io/path&quot;: &quot;/metrics/executors/prometheus/&quot; &quot;spark.kubernetes.driver.annotation.prometheus.io/port&quot;: &quot;4040&quot; &quot;spark.kubernetes.driver.service.annotation.prometheus.io/scrape&quot;: &quot;true&quot; &quot;spark.kubernetes.driver.service.annotation.prometheus.io/path&quot;: &quot;/metrics/driver/prometheus/&quot; &quot;spark.kubernetes.driver.service.annotation.prometheus.io/port&quot;: &quot;4040&quot; &quot;spark.metrics.conf..sink.prometheusServlet.class&quot;: &quot;org.apache.spark.metrics.sink.PrometheusServlet&quot; &quot;spark.metrics.conf..sink.prometheusServlet.path&quot;: &quot;/metrics/driver/prometheus/&quot; &quot;spark.metrics.conf.master.sink.prometheusServlet.path&quot;: &quot;/metrics/master/prometheus/&quot; &quot;spark.metrics.conf.applications.sink.prometheusServlet.path&quot;: &quot;/metrics/applications/prometheus/&quot;  Run port forward command to expose prometheus service.  kubectl port-forward service/prometheus-server 8080:80 -n prometheus   Then open browser and enter localhost:8080. You can view your prometheus server like below.  ","version":"Next","tagName":"h2"},{"title":"Grafana‚Äã","type":1,"pageTitle":"Observability Spark on EKS","url":"/data-on-eks/docs/blueprints/data-analytics/observability-spark-on-eks#grafana","content":" Grafana has been installed. Use the command below to access with port forward.  get grafana password  kubectl port-forward service/grafana 8080:80 -n grafana   login username is admin and password can get from secrets manager. You can import dashboard with ID: 7890.   ","version":"Next","tagName":"h2"},{"title":"Spark Operator with YuniKorn","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/data-analytics/spark-operator-yunikorn","content":"","keywords":"","version":"Next"},{"title":"Introduction‚Äã","type":1,"pageTitle":"Spark Operator with YuniKorn","url":"/data-on-eks/docs/blueprints/data-analytics/spark-operator-yunikorn#introduction","content":" The EKS Cluster design for the Data on EKS blueprint is optimized for running Spark applications with Spark Operator and Apache YuniKorn as the batch scheduler. This blueprint shows both options of leveraging Cluster Autoscaler and Karpenter for Spark Workloads. AWS for FluentBit is employed for logging, and a combination of Prometheus, Amazon Managed Prometheus, and open source Grafana are used for observability. Additionally, the Spark History Server Live UI is configured for monitoring running Spark jobs through an NLB and NGINX ingress controller.  Spark workloads with Karpenter üëà  Spark workloads with ClusterAutoscaler and Managed NodeGroups üëà  NVMe SSD Instance Storage for Spark Shuffle data üëà  Spark Operator üëà  Deploying the Solution üëà  Execute Sample Spark job with Karpenter üëà  Execute Sample Spark job with Cluster Autoscaler and Managed Node groups üëà  Example for TPCDS Benchmark test üëà  Cleanup üëà  caution To avoid unwanted charges to your AWS account, delete all the AWS resources created during this deployment ","version":"Next","tagName":"h2"},{"title":"DataHub on EKS","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/data-analytics/datahub-on-eks","content":"","keywords":"","version":"Next"},{"title":"Introduction‚Äã","type":1,"pageTitle":"DataHub on EKS","url":"/data-on-eks/docs/blueprints/data-analytics/datahub-on-eks#introduction","content":" DataHub is an open source data catalog that enables end-to-end data discovery, data observability, and data governance. This extensive metadata platform allows users to collect, store, and explore metadata from various sources, such as databases, data lakes, streaming platforms, and ML feature stores. DataHub provides many features, a rich UI for searching and browsing metadata, as well as an API for integrating with other applications.  This blueprint deploys DataHub on an EKS cluster, using Amazon OpenSearch Service, Amazon Managed Streaming for Apache Kafka (Amazon MSK), and Amazon RDS for MySQL as the storage layer for the underlying data model and indexes.  ","version":"Next","tagName":"h2"},{"title":"DataHub on AWS‚Äã","type":1,"pageTitle":"DataHub on EKS","url":"/data-on-eks/docs/blueprints/data-analytics/datahub-on-eks#datahub-on-aws","content":" On AWS, DataHub can run on EKS cluster. By using EKS, you can leverage the power and flexibility of Kubernetes to deploy and scale DataHub components, and take advantage of other AWS services and features, such as IAM, VPC, and CloudWatch, to monitor and secure the DataHub cluster.  DataHub also depends on many underlying infrastructure and services to function, including a message broker, a search engine, graph database, and a relational database like MySQL or PostgreSQL. AWS offers a range of managed and serverless services that can meet the needs of DataHub and simplify its deployment and operation.  DataHub can use Amazon Managed Streaming for Apache Kafka (MSK) as the messaging layer for metadata ingestion and consumption. MSK is a fully managed Apache Kafka service, so you don't need to handles the provisioning, configuration, and maintenance of Kafka cluster.DataHub stores metadata in both relational database and a search engine. For the relational database, this blueprint uses Amazon RDS for MySQL, which is also a managed service that simplifies the setup and operation of MySQL databases. RDS for MySQL also provides the high availability, security, and other features DataHub needs to store the metadata.For search engine, this blueprint uses Amazon OpenSearch service to provide fast and scalable search capabilities for the metadata.This blueprint deployes a Schema Registry service on EKS for DataHub. You may also choose to use Glue Schema Registry (https://docs.aws.amazon.com/glue/latest/dg/schema-registry.html) instead. Support for Glue Schema Registry will be included in future release of this blueprint.    ","version":"Next","tagName":"h2"},{"title":"Deploying the Solution‚Äã","type":1,"pageTitle":"DataHub on EKS","url":"/data-on-eks/docs/blueprints/data-analytics/datahub-on-eks#deploying-the-solution","content":" This blueprint deploys an EKS Cluster into a new VPC.  Creates a new sample VPC, 2 Private Subnets and 2 Public SubnetsCreates Internet gateway for Public Subnets and NAT Gateway for Private SubnetsCreates EKS Cluster Control plane with public endpoint (for demo reasons only) with core managed node group, on-demand node group and Spot node group for Spark workloads.Deploys Metrics server, Cluster Autoscaler, Prometheus server and AMP workspace, and AWS LoadBalancer Controller.  It then provisions the storage services for DataHub.  Creates service-linked role, security group, and an OpenSearch domain with one data node in each of the private subnets / AZs that EKS cluster is deployed on.Creates security group, kms key, and configuration for MSK. Creates the MSK cluster with one broker in each of the private subnets.Creates an RDS MySQL db instance with multi-AZ enabled.  Finally it deployes the datahub-prerequisites and datahub helm charts to setup the datahub pods / services on the EKS cluster. Ingress is enabled (as configured in datahub_values.yaml) and AWS LoadBalancer Controller will provision an ALB to expose the DataHub frontend UI.  info You may customize the blueprint by changing values in variables.tf, to deploy to a different region (default to us-west-2 ), use different cluster name, number of subnets / AZs, or disable addons like fluentbit  info If you already have opensearch service in the account, the service-linked role for OpenSearch exists already. You will need to change default value for variable create_iam_service_linked_role_es to false to avoid error in deployment.  ","version":"Next","tagName":"h2"},{"title":"Prerequisites‚Äã","type":1,"pageTitle":"DataHub on EKS","url":"/data-on-eks/docs/blueprints/data-analytics/datahub-on-eks#prerequisites","content":" Ensure that you have installed the following tools on your machine.  aws clikubectlterraform  ","version":"Next","tagName":"h3"},{"title":"Deploy‚Äã","type":1,"pageTitle":"DataHub on EKS","url":"/data-on-eks/docs/blueprints/data-analytics/datahub-on-eks#deploy","content":" Clone the repository  git clone https://github.com/awslabs/data-on-eks.git   Navigate into one of the example directories and run install.sh script  cd data-on-eks/analytics/terraform/datahub-on-eks chmod +x install.sh ./install.sh   caution install.sh script runs terraform apply -target for each module in order. The module dependencies are configured so they will be applied in the right sequence when you just run terraform apply. However, provisioning addons and MSK, OpenSearch, and RDS instances often take longer than 15 minutes, causing error when provisioning kubernetes and helm resources/modules afterwards due to expired auth token. So if you use terraform apply instead running install.sh, you may need to run it multiple times and terraform will resume the failed resource with a new token each time and complete the deployment eventually.  ","version":"Next","tagName":"h3"},{"title":"Verify Deployment‚Äã","type":1,"pageTitle":"DataHub on EKS","url":"/data-on-eks/docs/blueprints/data-analytics/datahub-on-eks#verify-deployment","content":" After the deployment completes, we can access the DataHub UI and test importing metadata from sample datasources. For demo purpose, this blueprint creates the Ingress object for the datahub FrontEnd UI with public LoadBalancer(internal # Private Load Balancer can only be accessed within the VPC). For production workloads, you can modify datahub_values.yaml to use internal LB:  datahub-frontend: enabled: true image: repository: linkedin/datahub-frontend-react # Set up ingress to expose react front-end ingress: enabled: true annotations: kubernetes.io/ingress.class: alb alb.ingress.kubernetes.io/scheme: **internal # Private Load Balancer can only be accessed within the VPC** alb.ingress.kubernetes.io/target-type: instance   You may find the URL to the datahub frontend from the output frontend_url, or by running kubectl command below:  kubectl get ingress datahub-datahub-frontend -n datahub # OUTPUT should looks like below NAME CLASS HOSTS ADDRESS PORTS AGE datahub-datahub-frontend &lt;none&gt; * k8s-datahub-datahubd-xxxxxxxxxx-xxxxxxxxxx.&lt;region&gt;.elb.amazonaws.com 80 nn   Copy the ADDRESS field from the output, then open browser and enter the URL as http://&lt;address&gt;/. Enter datahub as both user name and password when prompted. We can view the DataHub UI like below.    ","version":"Next","tagName":"h3"},{"title":"Testing‚Äã","type":1,"pageTitle":"DataHub on EKS","url":"/data-on-eks/docs/blueprints/data-analytics/datahub-on-eks#testing","content":" Follow steps from this blog to populate metadata from AWS Glue Data Catalog and Amazon Redshift, and business glossary and data lineage, into DataHub.  ","version":"Next","tagName":"h2"},{"title":"Cleanup‚Äã","type":1,"pageTitle":"DataHub on EKS","url":"/data-on-eks/docs/blueprints/data-analytics/datahub-on-eks#cleanup","content":" To clean up your environment, run the cleanup.sh script.script  chmod +x cleanup.sh ./cleanup.sh  ","version":"Next","tagName":"h2"},{"title":"Distributed Databases on EKS","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/distributed-databases","content":"Distributed Databases on EKS info Note: The blueprints for distributed databases and query engines are currently in the process of development. Documentation will be updated once a deployment example has been added to the repository. Running distributed databases and query engines on Kubernetes can provide a number of benefits for organizations looking to manage and process large amounts of data in real-time. Kubernetes provides features such as automatic scaling, rolling updates, and self-healing capabilities to ensure high availability and reliability of these systems. There are a number of popular distributed databases and query engines that have emerged to support this use case, including Apache Cassandra, Amazon DynamoDB, and Apache Presto. These systems make it easy to manage and process large amounts of data in real-time, and provide features such as scalability, high availability, and real-time data processing. By leveraging the power of Kubernetes, organizations can simplify and automate the deployment, scaling, and management of these complex systems, freeing up resources to focus on other areas of the business. With its growing ecosystem of tools and support for a wide range of use cases, Kubernetes is becoming an increasingly popular choice for running distributed databases and query engines in production.","keywords":"","version":"Next"},{"title":"EMR on EKS Data Platform with AWS CDK","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-studio","content":"","keywords":"","version":"Next"},{"title":"Analytics Reference Architecture‚Äã","type":1,"pageTitle":"EMR on EKS Data Platform with AWS CDK","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-studio#analytics-reference-architecture","content":" AWS Analytics Reference Architecture (ARA) exposes set of reusable core components in an AWS CDK library, currently available in Typescript and Python. This library contains AWS CDK constructs (L3) that can be used to quickly provision analytics solutions in demos, prototypes, proofs of concept, and end-to-end reference architectures. The API of ARA Library is defined here.  In our case the library help you deploy an infrastructure optimised for Apache Spark running on EKS leveraging EMR on EKS. The infrastructure will out of the box provide you with pod collocation to reduce network traffic, deploy nodegroup in a single AZ to reduce cross AZ traffic during shuffle, use dedicated instances for EMR on EKS, use optimized instances for memory intensive jobs, use spot and on-demand instances for non-critical job and for critical jobs.  ","version":"Next","tagName":"h2"},{"title":"Prerequisites‚Äã","type":1,"pageTitle":"EMR on EKS Data Platform with AWS CDK","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-studio#prerequisites","content":" Ensure that you have installed the following tools on your machine.  aws clikubectlCDK  ","version":"Next","tagName":"h2"},{"title":"Solution‚Äã","type":1,"pageTitle":"EMR on EKS Data Platform with AWS CDK","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-studio#solution","content":" To deploy the data platform we will use an example in the Analytics Reference Architecture. The example is in the directory examples/emr-eks-app that you will find in the repository you will clone below.  Clone the repository  git clone https://github.com/aws-samples/aws-analytics-reference-architecture.git   This solution will deploy the following:  EKS cluster and a set of Nodegroups: Managed Nodegroup called tooling for running system critical pods. e.g., Cluster Autoscaler, CoreDNS, EBS CSI Driver.. Three Managed Nodegroup called critical for critical jobs, each in one AZ, this nodegroup use on-demand instances Three Managed Nodegroup called non-critical for non-critical jobs, each in one AZ, this nodegroup use spot instances Three Managed Nodegroup called notebook-driver for non-critical jobs, each in one AZ, this nodegroup use on-demand instances to have a stable driver. Three Managed Nodegroup called notebook-executor for non-critical jobs, each in one AZ, this nodegroup use spot instances instances for executors. Enable EKS Cluster to be with with EMR on EKS service EMR Virtual Cluster called batchjob, used to submitted jobs EMR Virtual Cluster called emrvcplatform, used to submitted jobs EMR Studio called platform A managed endpoint, called platform-myendpoint , to use with Jupyter notebooks you will create in the EMR Studio Execution role to use when submitting jobs with EMR on EKS start-job-run Execution role to use with managed endpoint. pod templates stored in an S3 bucket called &quot;EKS-CLUSTER-NAME-emr-eks-assets-ACCOUNT-ID-REGION&quot;  ","version":"Next","tagName":"h2"},{"title":"Customize‚Äã","type":1,"pageTitle":"EMR on EKS Data Platform with AWS CDK","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-studio#customize","content":" The infrastructure described above is defined in emr-eks-app/lib/emr-eks-app-stack.ts. If you want to customize it you can change the values in it. For example, you can chose not to create the default nodegroup to use for jobs, in this case you can set the defaultNodeGroups parameter to false in the EmrEksCluster. You can also call the addEmrEksNodegroup method to define your own nodegroups with specific labels, instances or taints. The addEmrEksNodegroup method is defined here.  You can also create your own execution role through the createExecutionRole method or create a managed endpoint to attach it to an EMR Studio you deployed outside of the ARA library.  In order to simplify this example we use IAM authentication with IAM user for EMR Studio. If you would like to use a user in the AWS IAM Identity Center you can change studioAuthMode in the NotebookPlatform construct. Below you will can see the code snippet that you need to change.  const notebookPlatform = new ara.NotebookPlatform(this, 'platform-notebook', { emrEks: emrEks, eksNamespace: 'dataanalysis', studioName: 'platform', studioAuthMode: ara.StudioAuthMode.IAM, });   ","version":"Next","tagName":"h3"},{"title":"Deploy‚Äã","type":1,"pageTitle":"EMR on EKS Data Platform with AWS CDK","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-studio#deploy","content":" Before you run the solution, you MUST change the eksAdminRoleArn of the props object of EmrEksCluster in lib/emr-eks-app-stack.ts. This role allows you to interact manage EKS cluster and should have be allowed at least the IAM action eks:AccessKubernetesApi. You need to also change the identityName in the addUser method of the NotebookPlatform construct. The identityName MUST BE a valid IAM username that you use. Below you will can see the code snippet that you need to change.  notebookPlatform.addUser([{ identityName:'', notebookManagedEndpoints: [{ emrOnEksVersion: 'emr-6.8.0-latest', executionPolicy: emrEksPolicy, managedEndpointName: 'myendpoint' }], }]);   Last you should also update the IAM policies passed to the createExecutionRole, if you want to process data that is in S3 buckets that you own.  Navigate into one of the example directories and run cdk synth --profile YOUR-AWS-PROFILE  cd examples/emr-eks-app npm install cdk synth --profile YOUR-AWS-PROFILE   Once the synth is completed you can deploy the infrastructrue with the following command:  cdk deploy   At the end of the deployment you will see output like follow:    In the output you will find job sample configurations with the best practices for Spark on Kubernetes like dynamicAllocation and pod collocation.  ","version":"Next","tagName":"h3"},{"title":"Job submission‚Äã","type":1,"pageTitle":"EMR on EKS Data Platform with AWS CDK","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-studio#job-submission","content":" In this example we will use the crittical-job job configuration to submit a job using that will compute pi using that is part of Spark distribution. To submit a job we will use Below you use start-job-run command with AWS CLI.  Before you run the command below, make sure to change update the following parameters with the on created by your own deployment.  &lt;CLUSTER-ID&gt; ‚Äì The EMR virtual cluster ID, which you get from the AWS CDK output&lt;SPARK-JOB-NAME&gt; ‚Äì The name of your Spark job&lt;ROLE-ARN&gt; ‚Äì The execution role you created, which you get from the AWS CDK output&lt;S3URI-CRITICAL-DRIVER&gt; ‚Äì The Amazon S3 URI of the driver pod template, which you get from the AWS CDK output&lt;S3URI-CRITICAL-EXECUTOR&gt; ‚Äì The Amazon S3 URI of the executor pod template, which you get from the AWS CDK output&lt;Log_Group_Name&gt; ‚Äì Your CloudWatch log group name&lt;Log_Stream_Prefix&gt; ‚Äì Your CloudWatch log stream prefix  AWS CLI for start-job-run command aws emr-containers start-job-run \\ --virtual-cluster-id CLUSTER-ID\\ --name=SPARK-JOB-NAME\\ --execution-role-arn ROLE-ARN \\ --release-label emr-6.8.0-latest \\ --job-driver '{ &quot;sparkSubmitJobDriver&quot;:{ &quot;entryPoint&quot;: &quot;local:///usr/lib/spark/examples/src/main/python/pi.py&quot; } }' \\ --configuration-overrides '{ &quot;applicationConfiguration&quot;: [ { &quot;classification&quot;: &quot;spark-defaults&quot;, &quot;properties&quot;: { &quot;spark.hadoop.hive.metastore.client.factory.class&quot;: &quot;com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory&quot;, &quot;spark.sql.catalogImplementation&quot;: &quot;hive&quot;, &quot;spark.dynamicAllocation.enabled&quot;:&quot;true&quot;, &quot;spark.dynamicAllocation.minExecutors&quot;: &quot;8&quot;, &quot;spark.dynamicAllocation.maxExecutors&quot;: &quot;40&quot;, &quot;spark.kubernetes.allocation.batch.size&quot;: &quot;8&quot;, &quot;spark.executor.cores&quot;: &quot;8&quot;, &quot;spark.kubernetes.executor.request.cores&quot;: &quot;7&quot;, &quot;spark.executor.memory&quot;: &quot;28G&quot;, &quot;spark.driver.cores&quot;: &quot;2&quot;, &quot;spark.kubernetes.driver.request.cores&quot;: &quot;2&quot;, &quot;spark.driver.memory&quot;: &quot;6G&quot;, &quot;spark.dynamicAllocation.executorAllocationRatio&quot;: &quot;1&quot;, &quot;spark.dynamicAllocation.shuffleTracking.enabled&quot;: &quot;true&quot;, &quot;spark.dynamicAllocation.shuffleTracking.timeout&quot;: &quot;300s&quot;, &quot;spark.kubernetes.driver.podTemplateFile&quot;: &quot;s3://EKS-CLUSTER-NAME-emr-eks-assets-ACCOUNT-ID-REGION/EKS-CLUSTER-NAME/pod-template/critical-driver.yaml&quot;, &quot;spark.kubernetes.executor.podTemplateFile&quot;: &quot;s3://EKS-CLUSTER-NAME-emr-eks-assets-ACCOUNT-ID-REGION/EKS-CLUSTER-NAME/pod-template/critical-executor.yaml&quot; } } ], &quot;monitoringConfiguration&quot;: { &quot;cloudWatchMonitoringConfiguration&quot;: { &quot;logGroupName&quot;: &quot;Log_Group_Name&quot;, &quot;logStreamNamePrefix&quot;: &quot;Log_Stream_Prefix&quot; } } }'   Verify the job execution  kubectl get pods --namespace=batchjob -w   ","version":"Next","tagName":"h3"},{"title":"Interactive session‚Äã","type":1,"pageTitle":"EMR on EKS Data Platform with AWS CDK","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-studio#interactive-session","content":" To use an interactive session, you should log in to the EMR Studio instance with the URL provided to you at the end of cdk deploy. This link will be in the form of https://es-xxxxx/emrstudio-prod-REGION.amazonaws.com. Once you click on the link you will be see a log in page where you MUST sign-in with the username provided to the addUser method. When you sign in you should follow these steps.  Create workspace, this will start for a Jupyter notebookConnect to the Jupter notebookAttach to a Virtual cluster, this would be have the following name &quot;emrvcplatform&quot; and chose an endpoint called &quot;platform-myendpoint&quot;Open a notebook and select the PySpark kernelYou are now ready to perform analyse your data with Spark running on EMR on EKS.  ","version":"Next","tagName":"h3"},{"title":"Cleanup‚Äã","type":1,"pageTitle":"EMR on EKS Data Platform with AWS CDK","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-studio#cleanup","content":" To clean up your environment, you call the command below. This will destroy the EKS cluster with Node groups and VPC  cdk destroy   caution To avoid unwanted charges to your AWS account, delete all the AWS resources created during this deployment ","version":"Next","tagName":"h2"},{"title":"Job Schedulers","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/job-schedulers","content":"Job Schedulers Job schedulers are an essential component of many organizations' infrastructure, helping to automate and manage complex workflows. When deployed on Kubernetes, job schedulers can take advantage of the platform's features such as automatic scaling, rolling updates, and self-healing capabilities to ensure high availability and reliability. Tools like Apache Airflow, Argo Workflow, and Amazon MWAA provide a simple and efficient way to manage and schedule jobs on a Kubernetes cluster. These tools are well-suited for a wide range of use cases, including data pipelines, machine learning workflows, and batch processing. By leveraging the power of Kubernetes, organizations can simplify and automate the management of their job schedulers, freeing up resources to focus on other areas of the business. With its growing ecosystem of tools and support for a wide range of use cases, Kubernetes is becoming an increasingly popular choice for running job schedulers in production. The following are the most popular job scheduling tools used with data workloads. This section provides deployment patterns for the following tools and examples to trigger Spark/ML jobs using these schedulers. Apache AirflowAmazon Managed Workflows for Apache Airflow (MWAA)Argo WorkflowPrefect","keywords":"","version":"Next"},{"title":"Deploying Apache Pinot (üç∑) on EKS (Experimental)","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/distributed-databases/pinot","content":"","keywords":"","version":"Next"},{"title":"Prerequisites üìù‚Äã","type":1,"pageTitle":"Deploying Apache Pinot (üç∑) on EKS (Experimental)","url":"/data-on-eks/docs/blueprints/distributed-databases/pinot#prerequisites-","content":" Ensure that you have following tools installed on your machine.  aws clikubectlterraform  ","version":"Next","tagName":"h2"},{"title":"Deployment ‚öôÔ∏è‚Äã","type":1,"pageTitle":"Deploying Apache Pinot (üç∑) on EKS (Experimental)","url":"/data-on-eks/docs/blueprints/distributed-databases/pinot#deployment-Ô∏è","content":" ","version":"Next","tagName":"h2"},{"title":"Deploy the EKS Cluster with Apache Pinot‚Äã","type":1,"pageTitle":"Deploying Apache Pinot (üç∑) on EKS (Experimental)","url":"/data-on-eks/docs/blueprints/distributed-databases/pinot#deploy-the-eks-cluster-with-apache-pinot","content":" First, clone the repository.  git clone https://github.com/awslabs/data-on-eks.git   Navigate to apache pinot folder and create terraform.tfvars to provide desired values for all the variables. This is also the time to update any other input variables or make any other changes to the terraform template.  cd data-on-eks/distributed-databases/pinot touch terraform.tfvars   Sample terraform.tfvars‚Äã  name = &quot;pinot-on-eks&quot; region = &quot;us-west-2&quot; eks_cluster_version = &quot;1.25&quot; ...   ","version":"Next","tagName":"h3"},{"title":"Verify Deployment‚Äã","type":1,"pageTitle":"Deploying Apache Pinot (üç∑) on EKS (Experimental)","url":"/data-on-eks/docs/blueprints/distributed-databases/pinot#verify-deployment","content":" Verify the Amazon EKS Cluster  aws eks describe-cluster --name pinot-on-eks   Update local kubeconfig so we can access kubernetes cluster.  aws eks update-kubeconfig --name pinot-on-eks --region us-west-2   First, lets verify that we have worker nodes running in the cluster.  kubectl get nodes   Output‚Äã  NAME STATUS ROLES AGE VERSION ip-10-1-189-200.us-west-2.compute.internal Ready &lt;none&gt; 12d v1.24.17-eks-43840fb ip-10-1-46-117.us-west-2.compute.internal Ready &lt;none&gt; 12d v1.24.17-eks-43840fb ip-10-1-84-80.us-west-2.compute.internal Ready &lt;none&gt; 12d v1.24.17-eks-43840fb   Next, lets verify all the pods are running.  kubectl get pods -n pinot   Output‚Äã  NAME READY STATUS RESTARTS AGE pinot-broker-0 1/1 Running 0 11d pinot-broker-1 1/1 Running 0 11d pinot-broker-2 1/1 Running 0 11d pinot-controller-0 1/1 Running 0 11d pinot-controller-1 1/1 Running 0 11d pinot-controller-2 1/1 Running 0 11d pinot-minion-stateless-86cf65f89-rlpwn 1/1 Running 0 12d pinot-minion-stateless-86cf65f89-tkbjf 1/1 Running 0 12d pinot-minion-stateless-86cf65f89-twp8n 1/1 Running 0 12d pinot-server-0 1/1 Running 0 11d pinot-server-1 1/1 Running 0 11d pinot-server-2 1/1 Running 0 11d pinot-zookeeper-0 1/1 Running 0 12d pinot-zookeeper-1 1/1 Running 0 12d pinot-zookeeper-2 1/1 Running 0 12d   We have also deployed prometheus and grafana under monitoring namespace. So also make sure all the pods for monitoring are also running.  kubectl get pods -n monitoring   Output‚Äã  prometheus-grafana-85b4584dbf-4l72l 3/3 Running 0 12d prometheus-kube-prometheus-operator-84dcddccfc-pv8nv 1/1 Running 0 12d prometheus-kube-state-metrics-57f6b6b4fd-txjtb 1/1 Running 0 12d prometheus-prometheus-kube-prometheus-prometheus-0 2/2 Running 0 4d3h prometheus-prometheus-node-exporter-4jh8q 1/1 Running 0 12d prometheus-prometheus-node-exporter-f5znb 1/1 Running 0 12d prometheus-prometheus-node-exporter-f9xrz 1/1 Running 0 12d   Now lets access Apache Pinot Console using the below command. Console consist of Cluster Manager, Query Explorer, Zookeeper Browser and Swagger REST API Explorer.  kubectl port-forward service/pinot-controller 9000:9000 -n pinot   This will allow you to access Apache Pinot Console like the one shown below using http://localhost:9000    Apache Pinot supports exporting metrics using Prometheus JMX exporter that is packaged within the Apache Pinot docker image. Lets ensure metrics from all Apache Pinot components are getting published to prometheus.  kubectl port-forward service/prometheus-kube-prometheus-prometheus 9090:9090 -n monitoring   Navigate to the prometheus UI at http://localhost:9090, type pinot in the search box and you should be able to see all the metrics.    Next, Let's use Grafana to visualize the Apache Pinot metrics. In order to access Grafana, we need to get the grafana password from AWS Secrets Manager.  aws secretsmanager get-secret-value --secret-id pinot-on-eks-grafana | jq '.SecretString' --raw-output   Now use the port-forwarding to access Grafana at port 8080  kubectl port-forward service/prometheus-grafana 8080:80 -n monitoring   Login to grafana dashboard using admin and password retrieved in the previous step and then navigate to Dashboard and click New and then Import. Use the file pinot.json under data-on-eks/distributed-database/pinot/dashboard to create a pinot dashboard.    To learn more about the monitoring of Apache Pinot using Prometheus and Grafana use the official guide.  ","version":"Next","tagName":"h3"},{"title":"Additional Deployment (Optional) üèÜ‚Äã","type":1,"pageTitle":"Deploying Apache Pinot (üç∑) on EKS (Experimental)","url":"/data-on-eks/docs/blueprints/distributed-databases/pinot#additional-deployment-optional-","content":" ","version":"Next","tagName":"h2"},{"title":"Deploy Apache Kafka for Streaming Data‚Äã","type":1,"pageTitle":"Deploying Apache Pinot (üç∑) on EKS (Experimental)","url":"/data-on-eks/docs/blueprints/distributed-databases/pinot#deploy-apache-kafka-for-streaming-data","content":" Apache Pinot can ingest data from streaming data sources (real-time) as well as batch data sources (offline). In this example, we will leverage Apache Kafka to push real-time data to a topic.  If you already have Apache Kafka running in your EKS cluster or you are leveraging Amazon Managed Streaming for Apache Kafka (MSK) you can skip this step. Otherwise, follow the steps below to install Kafka in your EKS cluster.  Note: Following deployment configure Kafka Brokers with PLAINTEXT listeners for simplified deployment. Modify the kafka-values.yaml file for production deployment  helm repo add bitnami https://charts.bitnami.com/bitnami helm install -n pinot pinot-kafka bitnami/kafka --values ./helm/kafka-values.yaml   Output‚Äã  NAME: pinot-kafka LAST DEPLOYED: Tue Oct 24 01:10:25 2023 NAMESPACE: pinot STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: CHART NAME: kafka CHART VERSION: 26.2.0 APP VERSION: 3.6.0 ** Please be patient while the chart is being deployed ** Kafka can be accessed by consumers via port 9092 on the following DNS name from within your cluster: pinot-kafka.pinot.svc.cluster.local Each Kafka broker can be accessed by producers via port 9092 on the following DNS name(s) from within your cluster: pinot-kafka-controller-0.pinot-kafka-controller-headless.pinot.svc.cluster.local:9092 pinot-kafka-controller-1.pinot-kafka-controller-headless.pinot.svc.cluster.local:9092 pinot-kafka-controller-2.pinot-kafka-controller-headless.pinot.svc.cluster.local:9092 To create a pod that you can use as a Kafka client run the following commands: kubectl run pinot-kafka-client --restart='Never' --image docker.io/bitnami/kafka:3.6.0-debian-11-r0 --namespace pinot --command -- sleep infinity kubectl exec --tty -i pinot-kafka-client --namespace pinot -- bash PRODUCER: kafka-console-producer.sh \\ --broker-list pinot-kafka-controller-0.pinot-kafka-controller-headless.pinot.svc.cluster.local:9092,pinot-kafka-controller-1.pinot-kafka-controller-headless.pinot.svc.cluster.local:9092,pinot-kafka-controller-2.pinot-kafka-controller-headless.pinot.svc.cluster.local:9092 \\ --topic test CONSUMER: kafka-console-consumer.sh \\ --bootstrap-server pinot-kafka.pinot.svc.cluster.local:9092 \\ --topic test \\ --from-beginning   Use the command mentioned above to create Kafka Client pod within your namespace.  kubectl run pinot-kafka-client --restart='Never' --image docker.io/bitnami/kafka:3.6.0-debian-11-r0 --namespace pinot --command -- sleep infinity kubectl exec --tty -i pinot-kafka-client --namespace pinot -- bash   Create Kafka topics using the below commands, which will then be used to publish messages.  kafka-topics.sh --bootstrap-server pinot-kafka-controller-0.pinot-kafka-controller-headless.pinot.svc.cluster.local:9092 --topic flights-realtime --create --partitions 1 --replication-factor 1 kafka-topics.sh --bootstrap-server pinot-kafka-controller-0.pinot-kafka-controller-headless.pinot.svc.cluster.local:9092 --topic flights-realtime-avro --create --partitions 1 --replication-factor 1   Use provided example/pinot-realtime-quickstart.yml to create tables and publish sample data to the above topics, which will then get ingested into tables.  kubectl apply -f example/pinot-realtime-quickstart.yml   Now, let navigate back to Query Console and then click one of the tables. You should be able to see the newly created tables and data coming into tables.  kubectl port-forward service/pinot-controller 9000:9000 -n pinot     ","version":"Next","tagName":"h3"},{"title":"Cleanup üßπ‚Äã","type":1,"pageTitle":"Deploying Apache Pinot (üç∑) on EKS (Experimental)","url":"/data-on-eks/docs/blueprints/distributed-databases/pinot#cleanup-","content":" To delete all the components provisioned as part of this blueprint, using the following command to destroy all the resources.  ./cleanup.sh   caution To avoid unwanted charges to your AWS account, delete all the AWS resources created during this deployment ex. Delete kafka-on-eks EBS volumes ","version":"Next","tagName":"h2"},{"title":"Deploying PostgreSQL Database on EKS using CloudNativePG Operator","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/distributed-databases/cloudnative-postgres","content":"","keywords":"","version":"Next"},{"title":"Introduction‚Äã","type":1,"pageTitle":"Deploying PostgreSQL Database on EKS using CloudNativePG Operator","url":"/data-on-eks/docs/blueprints/distributed-databases/cloudnative-postgres#introduction","content":" CloudNativePG is an open sourceoperatordesigned to manage PostgreSQL workloads Kubernetes.  It defines a new Kubernetes resource called Cluster representing a PostgreSQL cluster made up of a single primary and an optional number of replicas that co-exist in a chosen Kubernetes namespace for High Availability and offloading of read-only queries.  Applications that reside in the same Kubernetes cluster can access the PostgreSQL database using a service which is solely managed by the operator, without having to worry about changes of the primary role following a failover or a switchover. Applications that reside outside the Kubernetes cluster, need to configure a Service or Ingress object to expose the Postgres via TCP. Web applications can take advantage of the native connection pooler based on PgBouncer.  CloudNativePG was originally built by EDB, then released open source under Apache License 2.0 and submitted for CNCF Sandbox in April 2022. The source code repository is in Github.  More details about the project will be found on this link  ","version":"Next","tagName":"h2"},{"title":"Deploying the Solution‚Äã","type":1,"pageTitle":"Deploying PostgreSQL Database on EKS using CloudNativePG Operator","url":"/data-on-eks/docs/blueprints/distributed-databases/cloudnative-postgres#deploying-the-solution","content":" Let's go through the deployment steps  ","version":"Next","tagName":"h2"},{"title":"Prerequisites‚Äã","type":1,"pageTitle":"Deploying PostgreSQL Database on EKS using CloudNativePG Operator","url":"/data-on-eks/docs/blueprints/distributed-databases/cloudnative-postgres#prerequisites","content":" Ensure that you have installed the following tools on your machine.  aws clikubectlterraformpsql  ","version":"Next","tagName":"h3"},{"title":"Deploy the EKS Cluster with CloudNativePG Operator‚Äã","type":1,"pageTitle":"Deploying PostgreSQL Database on EKS using CloudNativePG Operator","url":"/data-on-eks/docs/blueprints/distributed-databases/cloudnative-postgres#deploy-the-eks-cluster-with-cloudnativepg-operator","content":" First, clone the repository  git clone https://github.com/awslabs/data-on-eks.git   Navigate into cloudnative-postgres folder and run install.sh script. By default the script deploys EKS cluster to us-west-2 region. Update variables.tf to change the region. This is also the time to update any other input variables or make any other changes to the terraform template.  cd data-on-eks/distributed-databases/cloudnative-postgres ./install.sh   ","version":"Next","tagName":"h3"},{"title":"Verify Deployment‚Äã","type":1,"pageTitle":"Deploying PostgreSQL Database on EKS using CloudNativePG Operator","url":"/data-on-eks/docs/blueprints/distributed-databases/cloudnative-postgres#verify-deployment","content":" Verify the Amazon EKS Cluster  aws eks describe-cluster --name cnpg-on-eks   Update local kubeconfig so we can access kubernetes cluster  aws eks update-kubeconfig --name cnpg-on-eks --region us-west-2   First, lets verify that we have worker nodes running in the cluster.  kubectl get nodes NAME STATUS ROLES AGE VERSION ip-10-1-10-192.us-west-2.compute.internal Ready &lt;none&gt; 4d17h v1.25.6-eks-48e63af ip-10-1-10-249.us-west-2.compute.internal Ready &lt;none&gt; 4d17h v1.25.6-eks-48e63af ip-10-1-11-38.us-west-2.compute.internal Ready &lt;none&gt; 4d17h v1.25.6-eks-48e63af ip-10-1-12-195.us-west-2.compute.internal Ready &lt;none&gt; 4d17h v1.25.6-eks-48e63af   Next, lets verify all the pods are running.  kubectl get pods --namespace=monitoring NAME READY STATUS RESTARTS AGE alertmanager-kube-prometheus-stack-alertmanager-0 2/2 Running 1 (4d17h ago) 4d17h kube-prometheus-stack-grafana-7f8b9dc64b-sb27n 3/3 Running 0 4d17h kube-prometheus-stack-kube-state-metrics-5979d9d98c-r9fxn 1/1 Running 0 60m kube-prometheus-stack-operator-554b6f9965-zqszr 1/1 Running 0 60m prometheus-kube-prometheus-stack-prometheus-0 2/2 Running 0 4d17h kubectl get pods --namespace=cnpg-system NAME READY STATUS RESTARTS AGE cnpg-on-eks-cloudnative-pg-587d5d8fc5-65z9j 1/1 Running 0 4d17h   ","version":"Next","tagName":"h3"},{"title":"Deploy a PostgreSQL cluster‚Äã","type":1,"pageTitle":"Deploying PostgreSQL Database on EKS using CloudNativePG Operator","url":"/data-on-eks/docs/blueprints/distributed-databases/cloudnative-postgres#deploy-a-postgresql-cluster","content":" First of all, we need to create a storageclass using the ebs-csi-driver, a demo namespace and kubernetes secrets for login/password for database authentication app-auth. Check examples folder for all kubernetes manifests.  Storage‚Äã  For running a highly scalable and durable self-managed PostgreSQL database on Kubernetes with Amazon EKS and EC2, it is recommended to use Amazon Elastic Block Store (EBS) volumes that provide high performance and fault tolerance. The preferred EBS volume types for this use case are:  1.Provisioned IOPS SSD (io2 or io1):  Designed for I/O-intensive workloads such as databases.Offers consistent and low-latency performance.Allows you to provision a specific number of IOPS (input/output operations per second) according to your requirements.Provides up to 64,000 IOPS per volume and 1,000 MB/s throughput, making it suitable for demanding database workloads.  2.General Purpose SSD (gp3 or gp2):  Suitable for most workloads and offers a balance between performance and cost.Provides a baseline performance of 3,000 IOPS and 125 MB/s throughput per volume, which can be increased if needed (up to 16,000 IOPS and 1,000 MB/s for gp3).Recommended for less I/O-intensive database workloads or when cost is a primary concern.  You can find both storageclass template in examples folder.  kubectl create -f examples/storageclass.yaml kubectl create -f examples/auth-prod.yaml   As with any other deployment in Kubernetes, to deploy a PostgreSQL cluster you need to apply a configuration file that defines your desired Cluster. CloudNativePG operator offers two type of Bootstrapping a new database:  Bootstrap an empty clusterBootstrap From another cluster.  In this first example, we are going to create a new empty database cluster using initdbflags. We are going to use the template below by modifying the IAM role for IRSA configuration 1 and S3 bucket for backup restore process and WAL archiving 2. The Terraform could already created this use terraform output to extract these parameters:  cd data-on-eks/distributed-databases/cloudnative-postgres terraform output barman_backup_irsa = &quot;arn:aws:iam::&lt;your_account_id&gt;:role/cnpg-on-eks-prod-irsa&quot; barman_s3_bucket = &quot;XXXX-cnpg-barman-bucket&quot; configure_kubectl = &quot;aws eks --region us-west-2 update-kubeconfig --name cnpg-on-eks&quot;   --- apiVersion: postgresql.cnpg.io/v1 kind: Cluster metadata: name: prod namespace: demo spec: description: &quot;Cluster Demo for DoEKS&quot; # Choose your PostGres Database Version imageName: ghcr.io/cloudnative-pg/postgresql:15.2 # Number of Replicas instances: 3 startDelay: 300 stopDelay: 300 replicationSlots: highAvailability: enabled: true updateInterval: 300 primaryUpdateStrategy: unsupervised serviceAccountTemplate: # For backup and restore, we use IRSA for barman tool. # You will find this IAM role on terraform outputs. metadata: annotations: eks.amazonaws.com/role-arn: arn:aws:iam::&lt;&lt;account_id&gt;&gt;:role/cnpg-on-eks-prod-irsa #1 postgresql: parameters: shared_buffers: 256MB pg_stat_statements.max: '10000' pg_stat_statements.track: all auto_explain.log_min_duration: '10s' pg_hba: # - hostssl app all all cert - host app app all password logLevel: debug storage: storageClass: ebs-sc size: 1Gi walStorage: storageClass: ebs-sc size: 1Gi monitoring: enablePodMonitor: true bootstrap: initdb: # Deploying a new cluster database: WorldDB owner: app secret: name: app-auth backup: barmanObjectStore: # For backup, we S3 bucket to store data. # On this Blueprint, we create an S3 check the terraform output for it. destinationPath: s3://&lt;your-s3-barman-bucket&gt; #2 s3Credentials: inheritFromIAMRole: true wal: compression: gzip maxParallel: 8 retentionPolicy: &quot;30d&quot; resources: # m5large: m5xlarge 2vCPU, 8GI RAM requests: memory: &quot;512Mi&quot; cpu: &quot;1&quot; limits: memory: &quot;1Gi&quot; cpu: &quot;2&quot; affinity: enablePodAntiAffinity: true topologyKey: failure-domain.beta.kubernetes.io/zone nodeMaintenanceWindow: inProgress: false reusePVC: false   Once updated, you can apply your template.  kubectl create -f examples/prod-cluster.yaml   Verify that CloudNatvicePG operator has created three pods: one primary and two standby.   kubectl get pods,svc -n demo NAME READY STATUS RESTARTS AGE pod/prod-1 1/1 Running 0 4m36s pod/prod-2 1/1 Running 0 3m45s pod/prod-3 1/1 Running 0 3m9s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/prod-any ClusterIP 172.20.230.153 &lt;none&gt; 5432/TCP 4m54s service/prod-r ClusterIP 172.20.33.61 &lt;none&gt; 5432/TCP 4m54s service/prod-ro ClusterIP 172.20.96.16 &lt;none&gt; 5432/TCP 4m53s service/prod-rw ClusterIP 172.20.236.1 &lt;none&gt; 5432/TCP 4m53s   The operator created also three services:  -rw: points only to the primary instances of cluster database-ropoints only to hot standby replicas for read-only-workloads-rpoints to any of the instances for read-only workloads  Note that -any points on all the instances.  Another way to check Cluster status is by using cloudnative-pg kubectl plugin offered by the CloudNativePG community,  kubectl cnpg status prod Cluster Summary Name: prod Namespace: demo System ID: 7214866198623563798 PostgreSQL Image: ghcr.io/cloudnative-pg/postgresql:15.2 Primary instance: prod-1 Status: Cluster in healthy state Instances: 3 Ready instances: 3 Current Write LSN: 0/6000000 (Timeline: 1 - WAL File: 000000010000000000000005) Certificates Status Certificate Name Expiration Date Days Left Until Expiration ---------------- --------------- -------------------------- prod-ca 2023-06-24 14:40:27 +0000 UTC 89.96 prod-replication 2023-06-24 14:40:27 +0000 UTC 89.96 prod-server 2023-06-24 14:40:27 +0000 UTC 89.96 Continuous Backup status First Point of Recoverability: Not Available Working WAL archiving: OK WALs waiting to be archived: 0 Last Archived WAL: 000000010000000000000005 @ 2023-03-26T14:52:09.24307Z Last Failed WAL: - Streaming Replication status Replication Slots Enabled Name Sent LSN Write LSN Flush LSN Replay LSN Write Lag Flush Lag Replay Lag State Sync State Sync Priority Replication Slot ---- -------- --------- --------- ---------- --------- --------- ---------- ----- ---------- ------------- ---------------- prod-2 0/6000000 0/6000000 0/6000000 0/6000000 00:00:00 00:00:00 00:00:00 streaming async 0 active prod-3 0/6000000 0/6000000 0/6000000 0/6000000 00:00:00 00:00:00 00:00:00 streaming async 0 active Unmanaged Replication Slot Status No unmanaged replication slots found Instances status Name Database Size Current LSN Replication role Status QoS Manager Version Node ---- ------------- ----------- ---------------- ------ --- --------------- ---- prod-1 29 MB 0/6000000 Primary OK BestEffort 1.19.0 ip-10-1-10-192.us-west-2.compute.internal prod-2 29 MB 0/6000000 Standby (async) OK BestEffort 1.19.0 ip-10-1-12-195.us-west-2.compute.internal prod-3 29 MB 0/6000000 Standby (async) OK BestEffort 1.19.0 ip-10-1-11-38.us-west-2.compute.internal   ","version":"Next","tagName":"h3"},{"title":"Monitoring‚Äã","type":1,"pageTitle":"Deploying PostgreSQL Database on EKS using CloudNativePG Operator","url":"/data-on-eks/docs/blueprints/distributed-databases/cloudnative-postgres#monitoring","content":" In this example, we deployed a Prometheus and Grafana addons to monitor all database clusters created by CloudNativePG. Let's check Grafana dashboard.  kubectl -n monitoring port-forward svc/kube-prometheus-stack-grafana 8080:80     ","version":"Next","tagName":"h3"},{"title":"Import database sample‚Äã","type":1,"pageTitle":"Deploying PostgreSQL Database on EKS using CloudNativePG Operator","url":"/data-on-eks/docs/blueprints/distributed-databases/cloudnative-postgres#import-database-sample","content":" You can expose your database outside the cluster using ingress-controller or kubernetes service type LoadBalancer. However, for internal usage inside your EKS cluster, you can use kubernetes service prod-rw and prod-ro. In this section, we are going to expose read-write service -rwusing kubectl port-forward.   kubectl port-forward svc/prod-rw 5432:5432 -n demo   Now, we use psql cli to import world.sql into our database instance WorldDB using credentials from app-auth secrets.   psql -h localhost --port 5432 -U app -d WorldDB &lt; world.sql # Quick check on db tables. psql -h localhost --port 5432 -U app -d WorldDB -c '\\dt' Password for user app: List of relations Schema | Name | Type | Owner --------+-----------------+-------+------- public | city | table | app public | country | table | app public | countrylanguage | table | app (3 rows)   ","version":"Next","tagName":"h3"},{"title":"Create Backup to S3‚Äã","type":1,"pageTitle":"Deploying PostgreSQL Database on EKS using CloudNativePG Operator","url":"/data-on-eks/docs/blueprints/distributed-databases/cloudnative-postgres#create-backup-to-s3","content":" Now that we had a running database with data, CloudNativePG operator offers backup-restore feature using barman tool. CloudNativePG allows database admin to create on-demand database or Scheduled backups and for more details on documentations.  In this example, we will create a Backup object to start a backup process immediately.  apiVersion: postgresql.cnpg.io/v1 kind: Backup metadata: name: ondemand spec: cluster: name: prod    kubectl create -f examples/backup-od.yaml   It will take couple minutes to run, then, check the backup process  kubectl describe backup ondemand Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Starting 60s cloudnative-pg-backup Starting backup for cluster prod Normal Starting 60s instance-manager Backup started Normal Completed 56s instance-manager Backup completed   ","version":"Next","tagName":"h3"},{"title":"Restore‚Äã","type":1,"pageTitle":"Deploying PostgreSQL Database on EKS using CloudNativePG Operator","url":"/data-on-eks/docs/blueprints/distributed-databases/cloudnative-postgres#restore","content":" For restore, we use bootstrap a new cluster using backup file on S3. The backup tool barman manages restore process, but, it doesn't support backup and restore for kubernetes secrets. This must be managed separately, like using csi-secrets-driver with AWS SecretsManager.  First let's delete prod database.  kubectl delete cluster prod -n demo   Then, update your template examples/cluster-restore.yaml with your S3 bucket and IAM role. Note that on restore template, CloudNativePG use externalClusters to point on the database.   kubectl create -f examples/cluster-restore.yaml Type Reason Age From Message ---- ------ ---- ---- ------- Normal CreatingPodDisruptionBudget 7m12s cloudnative-pg Creating PodDisruptionBudget prod-primary Normal CreatingPodDisruptionBudget 7m12s cloudnative-pg Creating PodDisruptionBudget prod Normal CreatingServiceAccount 7m12s cloudnative-pg Creating ServiceAccount Normal CreatingRole 7m12s cloudnative-pg Creating Cluster Role Normal CreatingInstance 7m12s cloudnative-pg Primary instance (from backup) Normal CreatingInstance 6m33s cloudnative-pg Creating instance prod-2 Normal CreatingInstance 5m51s cloudnative-pg Creating instance prod-3   When creating a new cluster, the operator will create a ServiceAccount with IRSA configuration as described on Cluster resources. Make sure the trust policy points the right ServiceAccount.  Let's check if the data were covered as expected.   psql -h localhost --port 5432 -U app -d WorldDB -c '\\dt' Password for user app: List of relations Schema | Name | Type | Owner --------+-----------------+-------+------- public | city | table | app public | country | table | app public | countrylanguage | table | app (3 rows) psql -h localhost --port 5432 -U app -d WorldDB -c 'SELECT CURRENT_TIME;'   ","version":"Next","tagName":"h3"},{"title":"Conclusion‚Äã","type":1,"pageTitle":"Deploying PostgreSQL Database on EKS using CloudNativePG Operator","url":"/data-on-eks/docs/blueprints/distributed-databases/cloudnative-postgres#conclusion","content":" CloudNativePG operator provides Level 5 from Operator Capability Levels. In this example, we share a blueprint that deploy the operator as an addon along with its monitoring stack (Prometheus and grafana). Among many features, we highlighted couple of examples on creating cluster, importing data and restoring database in case of disaster (or cluster deletion). More features are available on this documentation ","version":"Next","tagName":"h2"},{"title":"Amazon Managed Workflows for Apache Airflow (MWAA)","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/job-schedulers/aws-managed-airflow","content":"","keywords":"","version":"Next"},{"title":"Considerations‚Äã","type":1,"pageTitle":"Amazon Managed Workflows for Apache Airflow (MWAA)","url":"/data-on-eks/docs/blueprints/job-schedulers/aws-managed-airflow#considerations","content":" Ideally we recommend adding the steps to sync requirements/sync dags to the MWAA S3 Bucket as part of a CI/CD pipeline. Generally Dags development have a different lifecycle than the Terraform code to provision infrastructure. For simplicity, we are providing steps for that using Terraform running AWS CLI commands on null_resource.  ","version":"Next","tagName":"h3"},{"title":"Prerequisites:‚Äã","type":1,"pageTitle":"Amazon Managed Workflows for Apache Airflow (MWAA)","url":"/data-on-eks/docs/blueprints/job-schedulers/aws-managed-airflow#prerequisites","content":" Ensure that you have the following tools installed locally:  aws clikubectlterraform  ","version":"Next","tagName":"h2"},{"title":"Deploy‚Äã","type":1,"pageTitle":"Amazon Managed Workflows for Apache Airflow (MWAA)","url":"/data-on-eks/docs/blueprints/job-schedulers/aws-managed-airflow#deploy","content":" To provision this example:  git clone https://github.com/awslabs/data-on-eks.git cd data-on-eks/schedulers/terraform/managed-airflow-mwaa chmod +x install.sh ./install.sh   Enter region at command prompt to continue.  Once done, you will see terraform output like below.    The following components are provisioned in your environment:  A sample VPC, 3 Private Subnets and 3 Public SubnetsInternet gateway for Public Subnets and NAT Gateway for Private SubnetsEKS Cluster Control plane with one managed node groupEKS Managed Add-ons: VPC_CNI, CoreDNS, Kube_Proxy, EBS_CSI_DriverK8S metrics server and cluster autoscalerA MWAA environment in version 2.2.2An EMR virtual cluster registered with the newly created EKSA S3 bucket with DAG code  ","version":"Next","tagName":"h2"},{"title":"Validate‚Äã","type":1,"pageTitle":"Amazon Managed Workflows for Apache Airflow (MWAA)","url":"/data-on-eks/docs/blueprints/job-schedulers/aws-managed-airflow#validate","content":" The following command will update the kubeconfig on your local machine and allow you to interact with your EKS Cluster using kubectl to validate the deployment.  ","version":"Next","tagName":"h2"},{"title":"Run update-kubeconfig command‚Äã","type":1,"pageTitle":"Amazon Managed Workflows for Apache Airflow (MWAA)","url":"/data-on-eks/docs/blueprints/job-schedulers/aws-managed-airflow#run-update-kubeconfig-command","content":" Run the command below. You may also copy the command from the terraform output 'configure_kubectl'.  aws eks --region us-west-2 update-kubeconfig --name managed-airflow-mwaa   ","version":"Next","tagName":"h3"},{"title":"List the nodes‚Äã","type":1,"pageTitle":"Amazon Managed Workflows for Apache Airflow (MWAA)","url":"/data-on-eks/docs/blueprints/job-schedulers/aws-managed-airflow#list-the-nodes","content":" kubectl get nodes # Output should look like below NAME STATUS ROLES AGE VERSION ip-10-0-0-42.ec2.internal Ready &lt;none&gt; 5h15m v1.26.4-eks-0a21954 ip-10-0-22-71.ec2.internal Ready &lt;none&gt; 5h15m v1.26.4-eks-0a21954 ip-10-0-44-63.ec2.internal Ready &lt;none&gt; 5h15m v1.26.4-eks-0a21954   ","version":"Next","tagName":"h3"},{"title":"List the namespaces in EKS cluster‚Äã","type":1,"pageTitle":"Amazon Managed Workflows for Apache Airflow (MWAA)","url":"/data-on-eks/docs/blueprints/job-schedulers/aws-managed-airflow#list-the-namespaces-in-eks-cluster","content":" kubectl get ns # Output should look like below default Active 4h38m emr-mwaa Active 4h34m kube-node-lease Active 4h39m kube-public Active 4h39m kube-system Active 4h39m mwaa Active 4h30m   namespace emr-mwaa will be used by EMR for running spark jobs. namespace mwaa will be used by MWAA directly.  ","version":"Next","tagName":"h3"},{"title":"Trigger jobs from MWAA‚Äã","type":1,"pageTitle":"Amazon Managed Workflows for Apache Airflow (MWAA)","url":"/data-on-eks/docs/blueprints/job-schedulers/aws-managed-airflow#trigger-jobs-from-mwaa","content":" ","version":"Next","tagName":"h2"},{"title":"Log into Apache Airflow UI‚Äã","type":1,"pageTitle":"Amazon Managed Workflows for Apache Airflow (MWAA)","url":"/data-on-eks/docs/blueprints/job-schedulers/aws-managed-airflow#log-into-apache-airflow-ui","content":" Open the Environments page on the Amazon MWAA consoleChoose an environmentUnder the Details section, click the link for the Airflow UI   Note: You will see red error message once login. That is because the EMR connection has not been setup. The message will be gone after following the steps below to set up the connection and login again.  ","version":"Next","tagName":"h3"},{"title":"Trigger the DAG workflow to execute job in EMR on EKS‚Äã","type":1,"pageTitle":"Amazon Managed Workflows for Apache Airflow (MWAA)","url":"/data-on-eks/docs/blueprints/job-schedulers/aws-managed-airflow#trigger-the-dag-workflow-to-execute-job-in-emr-on-eks","content":" First, you need to set up the connection to EMR virtual cluster in MWAA    Click Add button, Make sure use emr_eks as Connection Id Amazon Web Services as Connection Type Replace the value in Extra based on your terraform output {&quot;virtual_cluster_id&quot;:&quot;&lt;emrcontainers_virtual_cluster_id in terraform output&gt;&quot;, &quot;job_role_arn&quot;:&quot;&lt;emr_on_eks_role_arn in terraform output&gt;&quot;}    Go back to Airflow UI main page, enable the example DAG emr_eks_pi_job and then trigger the job.    While it is running, use the following command to verify the spark jobs:  kubectl get all -n emr-mwaa   You should see output similar to the following:  NAME READY STATUS RESTARTS AGE pod/000000030tk2ihdmr8g-psstj 3/3 Running 0 90s pod/pythonpi-a8051f83b415c911-exec-1 2/2 Running 0 14s pod/pythonpi-a8051f83b415c911-exec-2 2/2 Running 0 14s pod/spark-000000030tk2ihdmr8g-driver 2/2 Running 0 56s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/spark-000000030tk2ihdmr8g-ee64be83b4151dd5-driver-svc ClusterIP None &lt;none&gt; 7078/TCP,7079/TCP,4040/TCP 57s NAME COMPLETIONS DURATION AGE job.batch/000000030tk2ihdmr8g 0/1 92s 92s   You can also check the job status in Amazon EMR console. Under the Virtual clusters section, click on Virtual cluster    ","version":"Next","tagName":"h3"},{"title":"Trigger the DAG workflow to execute job in EKS‚Äã","type":1,"pageTitle":"Amazon Managed Workflows for Apache Airflow (MWAA)","url":"/data-on-eks/docs/blueprints/job-schedulers/aws-managed-airflow#trigger-the-dag-workflow-to-execute-job-in-eks","content":" In the Airflow UI, enable the example DAG kubernetes_pod_example and then trigger it.      Verify that the pod was executed successfully  After it runs and completes successfully, use the following command to verify the pod:  kubectl get pods -n mwaa   You should see output similar to the following:  NAME READY STATUS RESTARTS AGE mwaa-pod-test.4bed823d645844bc8e6899fd858f119d 0/1 Completed 0 25s   ","version":"Next","tagName":"h3"},{"title":"Destroy‚Äã","type":1,"pageTitle":"Amazon Managed Workflows for Apache Airflow (MWAA)","url":"/data-on-eks/docs/blueprints/job-schedulers/aws-managed-airflow#destroy","content":" To clean up your environment, run the cleanup.sh script.script  chmod +x cleanup.sh ./cleanup.sh    ","version":"Next","tagName":"h2"},{"title":"Argo Workflows on EKS","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks","content":"","keywords":"","version":"Next"},{"title":"Prerequisites:‚Äã","type":1,"pageTitle":"Argo Workflows on EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks#prerequisites","content":" Ensure that you have the following tools installed locally:  aws clikubectlterraformArgo WorkflowCLI  ","version":"Next","tagName":"h2"},{"title":"Deploy‚Äã","type":1,"pageTitle":"Argo Workflows on EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks#deploy","content":" To provision this example:  git clone https://github.com/awslabs/data-on-eks.git cd data-on-eks/schedulers/terraform/argo-workflow region=&lt;your region&gt; # set region variable for following commands terraform init terraform apply -var region=$region #defaults to us-west-2   Enter yes at command prompt to apply  The following components are provisioned in your environment:  A sample VPC, 2 Private Subnets and 2 Public SubnetsInternet gateway for Public Subnets and NAT Gateway for Private SubnetsEKS Cluster Control plane with one managed node groupEKS Managed Add-ons: VPC_CNI, CoreDNS, Kube_Proxy, EBS_CSI_DriverK8S Metrics Server, CoreDNS Autoscaler, Cluster Autoscaler, AWS for FluentBit, Karpenter, Argo Workflows, Argo Events, Kube Prometheus Stack, Spark Operator and Yunikorn SchedulerK8s roles and rolebindings for Argo Workflows and Argo Events    ","version":"Next","tagName":"h2"},{"title":"Validate‚Äã","type":1,"pageTitle":"Argo Workflows on EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks#validate","content":" The following command will update the kubeconfig on your local machine and allow you to interact with your EKS Cluster using kubectl to validate the deployment.  ","version":"Next","tagName":"h2"},{"title":"Run update-kubeconfig command:‚Äã","type":1,"pageTitle":"Argo Workflows on EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks#run-update-kubeconfig-command","content":" aws eks --region eu-west-1 update-kubeconfig --name argoworkflows-eks   ","version":"Next","tagName":"h3"},{"title":"List the nodes‚Äã","type":1,"pageTitle":"Argo Workflows on EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks#list-the-nodes","content":" kubectl get nodes # Output should look like below NAME STATUS ROLES AGE VERSION ip-10-1-0-189.eu-west-1.compute.internal Ready &lt;none&gt; 10m v1.27.3-eks-a5565ad ip-10-1-0-240.eu-west-1.compute.internal Ready &lt;none&gt; 10m v1.27.3-eks-a5565ad ip-10-1-1-135.eu-west-1.compute.internal Ready &lt;none&gt; 10m v1.27.3-eks-a5565ad   ","version":"Next","tagName":"h3"},{"title":"List the namespaces in EKS cluster‚Äã","type":1,"pageTitle":"Argo Workflows on EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks#list-the-namespaces-in-eks-cluster","content":" kubectl get ns # Output should look like below NAME STATUS AGE argo-events Active 7m45s argo-workflows Active 8m25s spark-team-a Active 5m51s default Active 25m karpenter Active 21m kube-node-lease Active 25m kube-prometheus-stack Active 8m5s kube-public Active 25m kube-system Active 25m spark-operator Active 5m43s yunikorn Active 5m44s   ","version":"Next","tagName":"h3"},{"title":"Access Argo Workflow WebUI‚Äã","type":1,"pageTitle":"Argo Workflows on EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks#access-argo-workflow-webui","content":" Get the load balancer url:  kubectl -n argo-workflows get service argo-workflows-server -o jsonpath=&quot;{.status.loadBalancer.ingress[*].hostname}{'\\n'}&quot;   Copy and paste the result in your browser. The initial username is admin. The login token is autogenerated and you can get it by running the following command:  argo auth token # get login token # result: Bearer k8s-aws-v1.aHR0cHM6Ly9zdHMudXMtd2VzdC0yLmFtYXpvbmF3cy5jb20vP0FjdGlvbj1HZXRDYWxsZXJJZGVudGl0eSZWZXJzaW9uPTIwMTEtMDYtMTUmWC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNWNFhDV1dLUjZGVTRGMiUyRjIwMjIxMDEzJTJGdXMtd2VzdC0yJTJGc3RzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMjEwMTNUMDIyODAyWiZYLUFtei1FeHBpcmVzPTYwJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCUzQngtazhzLWF3cy1pZCZYLUFtei1TaWduYXR1cmU9NmZiNmMxYmQ0MDQyMWIwNTI3NjY4MzZhMGJiNmUzNjg1MTk1YmM0NDQzMjIyMTg5ZDNmZmE1YzJjZmRiMjc4OA     ","version":"Next","tagName":"h3"},{"title":"Submit Spark Job with Argo Workflow‚Äã","type":1,"pageTitle":"Argo Workflows on EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks#submit-spark-job-with-argo-workflow","content":" Export EKS API from terraform output  eks_api_url=https://ABCDEFG1234567890.yl4.eu-west-2.eks.amazonaws.com cat workflow-examples/argo-spark.yaml | sed &quot;s/&lt;your_eks_api_server_url&gt;/$eks_api_url/g&quot; | kubectl apply -f - kubectl get wf -n argo-workflows NAME STATUS AGE MESSAGE spark Running 8s   You can also check the workflow status from Web UI    ","version":"Next","tagName":"h3"},{"title":"Submit Spark Job with Spark Operator and Argo Workflow‚Äã","type":1,"pageTitle":"Argo Workflows on EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks#submit-spark-job-with-spark-operator-and-argo-workflow","content":" kubectl apply -f workflow-examples/argo-spark-operator.yaml kubectl get wf -n argo-workflows NAME STATUS AGE MESSAGE spark Succeeded 3m58s spark-operator Running 5s   The workflow status from web UI    ","version":"Next","tagName":"h3"},{"title":"Trigger a workflow to create a spark job based on SQS message‚Äã","type":1,"pageTitle":"Argo Workflows on EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks#trigger-a-workflow-to-create-a-spark-job-based-on-sqs-message","content":" ","version":"Next","tagName":"h2"},{"title":"Install eventbus which is for event transmission in argo events‚Äã","type":1,"pageTitle":"Argo Workflows on EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks#install-eventbus-which-is-for-event-transmission-in-argo-events","content":" kubectl apply -f argo-events-manifests/eventbus.yaml   ","version":"Next","tagName":"h3"},{"title":"Deploy eventsource-sqs.yaml to link with external SQS‚Äã","type":1,"pageTitle":"Argo Workflows on EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks#deploy-eventsource-sqsyaml-to-link-with-external-sqs","content":" In this case, we configure a EventSource to license to the queue test1 in region us-east-1. The eventsource is capable of monitoring events across regions, so the Amazon EKS cluster and Amazon SQS queue don‚Äôt need to be located in the same Region.  queue_name=test1 region_sqs=us-east-1 cat argo-events-manifests/eventsource-sqs.yaml | sed &quot;s/&lt;region_sqs&gt;/$region_sqs/g;s/&lt;queue_name&gt;/$queue_name/g&quot; | kubectl apply -f -   Let's create that queue in your account.  # create a queue queue_url=$(aws sqs create-queue --queue-name $queue_name --region $region_sqs --output text) # get your queue arn sqs_queue_arn=$(aws sqs get-queue-attributes --queue-url $queue_url --attribute-names QueueArn --region $region_sqs --query &quot;Attributes.QueueArn&quot; --output text) template=`cat argo-events-manifests/sqs-accesspolicy.json | sed -e &quot;s|&lt;sqs_queue_arn&gt;|$sqs_queue_arn|g;s|&lt;your_event_irsa_arn&gt;|$your_event_irsa_arn|g&quot;` aws sqs set-queue-attributes --queue-url $queue_url --attributes $template --region $region_sqs   ","version":"Next","tagName":"h3"},{"title":"Deploy sensor-rbac.yaml and sensor-sqs-spark-crossns.yaml for triggering workflow‚Äã","type":1,"pageTitle":"Argo Workflows on EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks#deploy-sensor-rbacyaml-and-sensor-sqs-spark-crossnsyaml-for-triggering-workflow","content":" kubectl apply -f argo-events-manifests/sensor-rbac.yaml   cd workflow-examples   Update the variables in Shell script and execute  ./taxi-trip-execute.sh   Update YAML file and run the below command  kubectl apply -f sensor-sqs-sparkjobs.yaml   ","version":"Next","tagName":"h3"},{"title":"Verify argo-events namespace‚Äã","type":1,"pageTitle":"Argo Workflows on EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks#verify-argo-events-namespace","content":" kubectl get all,eventbus,EventSource,sensor,sa,role,rolebinding -n argo-events # Output should look like below NAME READY STATUS RESTARTS AGE pod/argo-events-controller-manager-bfb894cdb-26qw7 1/1 Running 0 18m pod/aws-sqs-crossns-spark-sensor-zkgz5-6584787c47-zjm9p 1/1 Running 0 44s pod/aws-sqs-eventsource-544jd-8fccc6f8-w6ssd 1/1 Running 0 4m45s pod/eventbus-default-stan-0 2/2 Running 0 5m21s pod/eventbus-default-stan-1 2/2 Running 0 5m13s pod/eventbus-default-stan-2 2/2 Running 0 5m11s pod/events-webhook-6f8d9fdc79-l9q9w 1/1 Running 0 18m NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/eventbus-default-stan-svc ClusterIP None &lt;none&gt; 4222/TCP,6222/TCP,8222/TCP 5m21s service/events-webhook ClusterIP 172.20.4.211 &lt;none&gt; 443/TCP 18m NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/argo-events-controller-manager 1/1 1 1 18m deployment.apps/aws-sqs-crossns-spark-sensor-zkgz5 1/1 1 1 44s deployment.apps/aws-sqs-eventsource-544jd 1/1 1 1 4m45s deployment.apps/events-webhook 1/1 1 1 18m NAME DESIRED CURRENT READY AGE replicaset.apps/argo-events-controller-manager-bfb894cdb 1 1 1 18m replicaset.apps/aws-sqs-crossns-spark-sensor-zkgz5-6584787c47 1 1 1 44s replicaset.apps/aws-sqs-eventsource-544jd-8fccc6f8 1 1 1 4m45s replicaset.apps/events-webhook-6f8d9fdc79 1 1 1 18m NAME READY AGE statefulset.apps/eventbus-default-stan 3/3 5m21s NAME AGE eventbus.argoproj.io/default 5m22s NAME AGE eventsource.argoproj.io/aws-sqs 4m46s NAME AGE sensor.argoproj.io/aws-sqs-crossns-spark 45s NAME SECRETS AGE serviceaccount/argo-events-controller-manager 0 18m serviceaccount/argo-events-events-webhook 0 18m serviceaccount/default 0 18m serviceaccount/event-sa 0 16m serviceaccount/operate-workflow-sa 0 53s NAME CREATED AT role.rbac.authorization.k8s.io/operate-workflow-role 2023-07-24T18:52:30Z NAME ROLE AGE rolebinding.rbac.authorization.k8s.io/operate-workflow-role-binding Role/operate-workflow-role 52s   ","version":"Next","tagName":"h3"},{"title":"Test from SQS‚Äã","type":1,"pageTitle":"Argo Workflows on EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks#test-from-sqs","content":" Send a message from SQS: {&quot;message&quot;: &quot;hello&quot;}  aws sqs send-message --queue-url $queue_url --message-body '{&quot;message&quot;: &quot;hello&quot;}' --region $region_sqs   Argo Events would capture the message and trigger Argo Workflows to create a workflow for spark jobs.  kubectl get wf -A # Output should look like below NAMESPACE NAME STATUS AGE MESSAGE argo-workflows aws-sqs-spark-workflow-hh79p Running 11s   Run the command below to check spark application driver pods and executor pods under spark-team-a namespace.  kubectl get po -n spark-team-a # Output should look like below NAME READY STATUS RESTARTS AGE event-wf-sparkapp-tcxl8-driver 1/1 Running 0 45s pythonpi-a72f5f89894363d2-exec-1 1/1 Running 0 16s pythonpi-a72f5f89894363d2-exec-2 1/1 Running 0 16s   See the SQS workflow status in web UI      ","version":"Next","tagName":"h3"},{"title":"Destroy‚Äã","type":1,"pageTitle":"Argo Workflows on EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/argo-workflows-eks#destroy","content":" To teardown and remove the resources created in this example:  kubectl delete -f argo-events-manifests/. ./cleanup.sh  ","version":"Next","tagName":"h2"},{"title":"Streaming Platforms on EKS","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/streaming-platforms","content":"Streaming Platforms on EKS info Note: The blueprints for streaming platforms are currently in the process of development. Documentation will be updated once a deployment example has been added to the repository. Running streaming platforms on Kubernetes can provide a number of benefits for organizations looking to process and analyze real-time data streams. Kubernetes provides features such as automatic scaling, rolling updates, and self-healing capabilities to ensure high availability and reliability of streaming platforms. There are a number of popular streaming platforms that have emerged to support this use case, including Apache Kafka, Apache Flink, and Apache Pulsar. These platforms make it easy to process and analyze real-time data streams in a containerized environment, and provide features such as real-time data processing, event-driven architecture, and fault-tolerance. By leveraging the power of Kubernetes, organizations can focus on building and processing their streaming data pipelines, rather than worrying about the underlying infrastructure. With its robust ecosystem of tools and support for a wide range of use cases, Kubernetes is becoming an increasingly popular choice for running streaming platforms in production. KafkaFlink","keywords":"","version":"Next"},{"title":"Self-managed Apache Airflow deployment on Amazon EKS","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/job-schedulers/self-managed-airflow","content":"","keywords":"","version":"Next"},{"title":"Introduction‚Äã","type":1,"pageTitle":"Self-managed Apache Airflow deployment on Amazon EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/self-managed-airflow#introduction","content":" This pattern deploys self-managed Apache Airflow deployment on EKS. This blueprint deploys Airflow on Amazon EKS managed node groups and leverages Karpenter to run the workloads.  Architecture    This pattern uses opinionated defaults to keep the deployment experience simple but also keeps it flexible so that you can pick and choose necessary add-ons during deployment. We recommend keeping the defaults and only customize if you have viable alternative option available for replacement.  In terms of infrastructure, below are the resources that are created by this pattern:  EKS Cluster Control plane with public endpoint (recommended for demo/poc environment) One managed node group Core Node group with 3 instances spanning multi-AZs for running Apache Airflow and other system critical pods. e.g., Cluster Autoscaler, CoreDNS, Observability, Logging etc. Apache Airflow core components (with airflow-core.tf): Amazon RDS PostgreSQL instance and security group for Airflow meta database.Airflow namespaceKubernetes service accounts and AWS IAM roles for service account (IRSA) for Airflow Webserver, Airflow Scheduler, and Airflow Worker.Amazon Elastic File System (EFS), EFS mounts, Kubernetes Storage Class for EFS, and Kubernetes Persistent Volume Claim for mounting Airflow DAGs for Airflow pods.Amazon S3 log bucket for Airflow logs  AWS for FluentBit is employed for logging, and a combination of Prometheus, Amazon Managed Prometheus, and open source Grafana are used for observability. You can see the complete list of add-ons available below.  tip We recommend running all the default system add-ons on a dedicated EKS managed nodegroup such as core-node-group as provided by this pattern.  danger We don't recommend removing critical add-ons (Amazon VPC CNI, CoreDNS, Kube-proxy).  Add-on\tEnabled by default?\tBenefits\tLinkAmazon VPC CNI\tYes\tVPC CNI is available as an EKS add-on and is responsible for creating ENI's and IPv4 or IPv6 addresses for your spark application pods\tVPC CNI Documentation CoreDNS\tYes\tCoreDNS is available as an EKS add-on and is responsible for resolving DNS queries for spark application and for Kubernetes cluster\tEKS CoreDNS Documentation Kube-proxy\tYes\tKube-proxy is available as an EKS add-on and it maintains network rules on your nodes and enables network communication to your spark application pods\tEKS kube-proxy Documentation Amazon EBS CSI driver\tYes\tEBS CSI driver is available as an EKS add-on and it allows EKS clusters to manage the lifecycle of EBS volumes\tEBS CSI Driver Documentation Amazon EFS CSI driver\tYes\tThe Amazon EFS Container Storage Interface (CSI) driver provides a CSI interface that allows Kubernetes clusters running on AWS to manage the lifecycle of Amazon EFS file systems.\tEFS CSI Driver Documentation Karpenter\tYes\tKarpenter is nodegroup-less autoscaler that provides just-in-time compute capacity for spark applications on Kubernetes clusters\tKarpenter Documentation Cluster Autoscaler\tYes\tKubernetes Cluster Autoscaler automatically adjusts the size of Kubernetes cluster and is available for scaling nodegroups (such as core-node-group) in the cluster\tCluster Autoscaler Documentation Cluster proportional autoscaler\tYes\tThis is responsible for scaling CoreDNS pods in your Kubernetes cluster\tCluster Proportional Autoscaler Documentation Metrics server\tYes\tKubernetes metrics server is responsible for aggregating cpu, memory and other container resource usage within your cluster\tEKS Metrics Server Documentation Prometheus\tYes\tPrometheus is responsible for monitoring EKS cluster including spark applications in your EKS cluster. We use Prometheus deployment for scraping and ingesting metrics into Amazon Managed Prometheus and Kubecost\tPrometheus Documentation Amazon Managed Prometheus\tYes\tThis is responsible for storing and scaling of EKS cluster and spark application metrics\tAmazon Managed Prometheus Documentation Kubecost\tYes\tKubecost is responsible for providing cost break down by Spark application. You can monitor costs based on per job, namespace or labels\tEKS Kubecost Documentation CloudWatch metrics\tYes\tCloudWatch container insights metrics shows simple and standardized way to monitor not only AWS resources but also EKS resources on CloudWatch dashboard\tCloudWatch Container Insights Documentation AWS for Fluent-bit\tYes\tThis can be used to publish EKS cluster and worker node logs to CloudWatch Logs or 3rd party logging system\tAWS For Fluent-bit Documentation AWS Load Balancer Controller\tYes\tThe AWS Load Balancer Controller manages AWS Elastic Load Balancers for a Kubernetes cluster.\tAWS Load Balancer Controller Documentation  ","version":"Next","tagName":"h2"},{"title":"Prerequisites‚Äã","type":1,"pageTitle":"Self-managed Apache Airflow deployment on Amazon EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/self-managed-airflow#prerequisites","content":" Ensure that you have installed the following tools on your machine.  aws clikubectlterraform  ","version":"Next","tagName":"h2"},{"title":"Deploying the Solution‚Äã","type":1,"pageTitle":"Self-managed Apache Airflow deployment on Amazon EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/self-managed-airflow#deploying-the-solution","content":" Clone the repository  git clone https://github.com/awslabs/data-on-eks.git   Navigate into self-managed-airflow directory and run install.sh script  cd data-on-eks/schedulers/terraform/self-managed-airflow chmod +x install.sh ./install.sh   ","version":"Next","tagName":"h2"},{"title":"Verify the resources‚Äã","type":1,"pageTitle":"Self-managed Apache Airflow deployment on Amazon EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/self-managed-airflow#verify-the-resources","content":" ","version":"Next","tagName":"h2"},{"title":"Create kubectl config‚Äã","type":1,"pageTitle":"Self-managed Apache Airflow deployment on Amazon EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/self-managed-airflow#create-kubectl-config","content":" Update the placeholder for AWS region and run the below command.  mv ~/.kube/config ~/.kube/config.bk aws eks update-kubeconfig --region &lt;region&gt; --name self-managed-airflow   ","version":"Next","tagName":"h3"},{"title":"Describe the EKS Cluster‚Äã","type":1,"pageTitle":"Self-managed Apache Airflow deployment on Amazon EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/self-managed-airflow#describe-the-eks-cluster","content":" aws eks describe-cluster --name self-managed-airflow   ","version":"Next","tagName":"h3"},{"title":"Verify the EFS PV and PVC created by this deployment‚Äã","type":1,"pageTitle":"Self-managed Apache Airflow deployment on Amazon EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/self-managed-airflow#verify-the-efs-pv-and-pvc-created-by-this-deployment","content":" kubectl get pvc -n airflow NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE airflow-dags Bound pvc-157cc724-06d7-4171-a14d-something 10Gi RWX efs-sc 73m kubectl get pv -n airflow NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE pvc-157cc724-06d7-4171-a14d-something 10Gi RWX Delete Bound airflow/airflow-dags efs-sc 74m   ","version":"Next","tagName":"h3"},{"title":"Verify the EFS Filesystem‚Äã","type":1,"pageTitle":"Self-managed Apache Airflow deployment on Amazon EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/self-managed-airflow#verify-the-efs-filesystem","content":" aws efs describe-file-systems --query &quot;FileSystems[*].FileSystemId&quot; --output text   ","version":"Next","tagName":"h3"},{"title":"Verify S3 bucket created for Airflow logs‚Äã","type":1,"pageTitle":"Self-managed Apache Airflow deployment on Amazon EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/self-managed-airflow#verify-s3-bucket-created-for-airflow-logs","content":" aws s3 ls | grep airflow-logs-   ","version":"Next","tagName":"h3"},{"title":"Verify the Airflow deployment‚Äã","type":1,"pageTitle":"Self-managed Apache Airflow deployment on Amazon EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/self-managed-airflow#verify-the-airflow-deployment","content":" kubectl get deployment -n airflow NAME READY UP-TO-DATE AVAILABLE AGE airflow-pgbouncer 1/1 1 1 77m airflow-scheduler 2/2 2 2 77m airflow-statsd 1/1 1 1 77m airflow-triggerer 1/1 1 1 77m airflow-webserver 2/2 2 2 77m   ","version":"Next","tagName":"h3"},{"title":"Fetch Postgres RDS password‚Äã","type":1,"pageTitle":"Self-managed Apache Airflow deployment on Amazon EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/self-managed-airflow#fetch-postgres-rds-password","content":" Amazon Postgres RDS database password can be fetched from the Secrets manager  Login to AWS console and open secrets managerClick on postgres secret nameClick on Retrieve secret value button to verify the Postgres DB master password  ","version":"Next","tagName":"h3"},{"title":"Login to Airflow Web UI‚Äã","type":1,"pageTitle":"Self-managed Apache Airflow deployment on Amazon EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/self-managed-airflow#login-to-airflow-web-ui","content":" This deployment creates an Ingress object with public LoadBalancer(internal # Private Load Balancer can only be accessed within the VPC) for demo purpose For production workloads, you can modify airflow-values.yaml to choose internal LB. In addition, it's also recommended to use Route53 for Airflow domain and ACM for generating certificates to access Airflow on HTTPS port.  Execute the following command to get the ALB DNS name  kubectl get ingress -n airflow NAME CLASS HOSTS ADDRESS PORTS AGE airflow-airflow-ingress alb * k8s-dataengineering-c92bfeb177-randomnumber.us-west-2.elb.amazonaws.com 80 88m   The above ALB URL will be different for you deployment. So use your URL and open it in a browser  e.g., Open URL http://k8s-dataengineering-c92bfeb177-randomnumber.us-west-2.elb.amazonaws.com/ in a browser  By default, Airflow creates a default user with admin and password as admin  Login with Admin user and password and create new users for Admin and Viewer roles and delete the default admin user  ","version":"Next","tagName":"h3"},{"title":"Execute Sample Airflow Job‚Äã","type":1,"pageTitle":"Self-managed Apache Airflow deployment on Amazon EKS","url":"/data-on-eks/docs/blueprints/job-schedulers/self-managed-airflow#execute-sample-airflow-job","content":" Login to Airflow WebUIClick on DAGs link on the top of the page. This will show dags pre-created by the GitSync featureExecute the hello_world_scheduled_dag DAG by clicking on Play button (&gt;)Verify the DAG execution from Graph linkAll the Tasks will go green after few minutesClick on one of the green Task which opens a popup with log link where you can verify the logs pointing to S3  Airflow to run Spark workloads with Karpenter üëà  Cleanup üëà  caution To avoid unwanted charges to your AWS account, delete all the AWS resources created during this deployment ","version":"Next","tagName":"h3"},{"title":"Flink Operator on EKS","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/streaming-platforms/flink","content":"","keywords":"","version":"Next"},{"title":"Introduction to Apache Flink‚Äã","type":1,"pageTitle":"Flink Operator on EKS","url":"/data-on-eks/docs/blueprints/streaming-platforms/flink#introduction-to-apache-flink","content":" Apache Flink is an open-source, unified stream processing and batch processing framework that was designed to process large amounts of data. It provides fast, reliable, and scalable data processing with fault tolerance and exactly-once semantics. Some of the key features of Flink are:  Distributed Processing: Flink is designed to process large volumes of data in a distributed fashion, making it horizontally scalable and fault-tolerant.Stream Processing and Batch Processing: Flink provides APIs for both stream processing and batch processing. This means you can process data in real-time, as it's being generated, or process data in batches.Fault Tolerance: Flink has built-in mechanisms for handling node failures, network partitions, and other types of failures.Exactly-once Semantics: Flink supports exactly-once processing, which ensures that each record is processed exactly once, even in the presence of failures.Low Latency: Flink's streaming engine is optimized for low-latency processing, making it suitable for use cases that require real-time processing of data.Extensibility: Flink provides a rich set of APIs and libraries, making it easy to extend and customize to fit your specific use case.  ","version":"Next","tagName":"h2"},{"title":"Architecture‚Äã","type":1,"pageTitle":"Flink Operator on EKS","url":"/data-on-eks/docs/blueprints/streaming-platforms/flink#architecture","content":" Flink Architecture high level design with EKS.    ","version":"Next","tagName":"h2"},{"title":"Flink Kubernetes Operator‚Äã","type":1,"pageTitle":"Flink Operator on EKS","url":"/data-on-eks/docs/blueprints/streaming-platforms/flink#flink-kubernetes-operator","content":" Flink Kubernetes Operator is a powerful tool for managing Flink clusters on Kubernetes. Flink Kubernetes Operator (Operator) acts as a control plane to manage the complete deployment lifecycle of Apache Flink applications. The Operator can be installed on a Kubernetes cluster using Helm. The core responsibility of the Flink operator is to manage the full production lifecycle of Flink applications.  Running, suspending and deleting applicationsStateful and stateless application upgradesTriggering and managing savepointsHandling errors, rolling-back broken upgrades  Flink Operator defines two types of Custom Resources(CR) which are the extensions of the Kubernetes API.  FlinkDeploymentFlinkSessionJob FlinkDeployment FlinkDeployment CR defines Flink Application and Session Cluster deployments. Application deployments manage a single job deployment on a dedicated Flink cluster in Application mode. Session clusters allows you to run multiple Flink Jobs on an existing Session cluster. FlinkDeployment in Application modes, Click to toggle content! apiVersion: flink.apache.org/v1beta1 kind: FlinkDeployment metadata: namespace: default name: basic-example spec: image: flink:1.16 flinkVersion: v1_16 flinkConfiguration: taskmanager.numberOfTaskSlots: &quot;2&quot; serviceAccount: flink jobManager: resource: memory: &quot;2048m&quot; cpu: 1 taskManager: resource: memory: &quot;2048m&quot; cpu: 1 job: jarURI: local:///opt/flink/examples/streaming/StateMachineExample.jar parallelism: 2 upgradeMode: stateless state: running   info Session clusters use a similar spec to Application clusters with the only difference that job is not defined in the yaml spec.  info According to the Flink documentation, it is recommended to use FlinkDeployment in Application mode for production environments.  On top of the deployment types the Flink Kubernetes Operator also supports two modes of deployments: Native and Standalone.  NativeStandalone Native Native cluster deployment is the default deployment mode and uses Flink‚Äôs built in integration with Kubernetes when deploying the cluster.Flink cluster communicates directly with Kubernetes and allows it to manage Kubernetes resources, e.g. dynamically allocate and de-allocate TaskManager pods.Flink Native can be useful for advanced users who want to build their own cluster management system or integrate with existing management systems.Flink Native allows for more flexibility in terms of job scheduling and execution.For standard Operator use, running your own Flink Jobs in Native mode is recommended. apiVersion: flink.apache.org/v1beta1 kind: FlinkDeployment ... spec: ... mode: native   ","version":"Next","tagName":"h2"},{"title":"Best Practices for Running Flink Jobs on Kubernetes‚Äã","type":1,"pageTitle":"Flink Operator on EKS","url":"/data-on-eks/docs/blueprints/streaming-platforms/flink#best-practices-for-running-flink-jobs-on-kubernetes","content":" To get the most out of Flink on Kubernetes, here are some best practices to follow:  Use the Kubernetes Operator: Install and use the Flink Kubernetes Operator to automate the deployment and management of Flink clusters on Kubernetes.Deploy in dedicated namespaces: Create a separate namespace for the Flink Kubernetes Operator and another one for Flink jobs/workloads. This ensures that the Flink jobs are isolated and have their own resources.Use high-quality storage: Store Flink checkpoints and savepoints in high-quality storage such as Amazon S3 or another durable external storage. These storage options are reliable, scalable, and offer durability for large volumes of data.Optimize resource allocation: Allocate sufficient resources to Flink jobs to ensure optimal performance. This can be done by setting resource requests and limits for Flink containers.Proper network isolation: Use Kubernetes Network Policies to isolate Flink jobs from other workloads running on the same Kubernetes cluster. This ensures that Flink jobs have the required network access without being impacted by other workloads.Configure Flink optimally: Tune Flink settings according to your use case. For example, adjust Flink's parallelism settings to ensure that Flink jobs are scaled appropriately based on the size of the input data.Use checkpoints and savepoints: Use checkpoints for periodic snapshots of Flink application state and savepoints for more advanced use cases such as upgrading or downgrading the application.Store checkpoints and savepoints in the right places: Store checkpoints in distributed file systems or key-value stores like Amazon S3 or another durable external storage. Store savepoints in a durable external storage like Amazon S3.  ","version":"Next","tagName":"h2"},{"title":"Flink Upgrade‚Äã","type":1,"pageTitle":"Flink Operator on EKS","url":"/data-on-eks/docs/blueprints/streaming-platforms/flink#flink-upgrade","content":" Flink Operator provides three upgrade modes for Flink jobs. Checkout the Flink upgrade docs for up-to-date information.  stateless: Stateless application upgrades from empty statelast-state: Quick upgrades in any application state (even for failing jobs), does not require a healthy job as it always uses the latest checkpoint information. Manual recovery may be necessary if HA metadata is lost.savepoint: Use savepoint for upgrade, providing maximal safety and possibility to serve as backup/fork point. The savepoint will be created during the upgrade process. Note that the Flink job needs to be running to allow the savepoint to get created. If the job is in an unhealthy state, the last checkpoint will be used (unless kubernetes.operator.job.upgrade.last-state-fallback.enabled is set to false). If the last checkpoint is not available, the job upgrade will fail.  info last-state or savepoint are recommended modes for production  Deploying the Solution üëà  Execute Sample Flink job with Karpenter üëà  Execute Sample Flink job with Managed Node Groups and Cluster Autoscaler üëà  Cleanup üëà  caution To avoid unwanted charges to your AWS account, delete all the AWS resources created during this deployment ","version":"Next","tagName":"h2"},{"title":"EMR on EKS with Karpenter","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-karpenter","content":"","keywords":"","version":"Next"},{"title":"Introduction‚Äã","type":1,"pageTitle":"EMR on EKS with Karpenter","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-karpenter#introduction","content":" In this pattern, you will deploy an EMR on EKS cluster and use Karpenter provisioners for scaling Spark jobs.  Architecture  This pattern uses opinionated defaults to keep the deployment experience simple but also keeps it flexible so that you can pick and choose necessary add-ons during deployment. We recommend keeping the defaults if you are new to EMR on EKS and only customize if you have viable alternative option available for replacement.  In terms of infrastructure, here are the resources that are created by this pattern  Creates an EKS Cluster Control plane with public endpoint (recommended for demo/poc environment)One managed node group Core Node group with 3 instances spanning multi-AZs for running system critical pods. e.g., Cluster Autoscaler, CoreDNS, Observability, Logging etc. Enables EMR on EKS Creates two namespaces (emr-data-team-a, emr-data-team-b) for data teamsCreates Kubernetes role and role binding(emr-containers user) for both namespacesIAM roles for both teams needed for job executionUpdate AWS_AUTH config map with emr-containers user and AWSServiceRoleForAmazonEMRContainers roleCreate a trust relationship between the job execution role and the identity of the EMR managed service accountCreate EMR Virtual Cluster for emr-data-team-a &amp; emr-data-team-b and IAM policies for both  You can see the list of add-ons available below.  tip We recommend running all the default system add-ons on a dedicated EKS managed nodegroup such as core-node-group as provided by this pattern.  danger We don't recommend removing critical add-ons (Amazon VPC CNI, CoreDNS, Kube-proxy).  Add-on\tEnabled by default?\tBenefits\tLinkAmazon VPC CNI\tYes\tVPC CNI is available as an EKS add-on and is responsible for creating ENI's and IPv4 or IPv6 addresses for your spark application pods\tVPC CNI Documentation CoreDNS\tYes\tCoreDNS is available as an EKS add-on and is responsible for resolving DNS queries for spark application and for Kubernetes cluster\tEKS CoreDNS Documentation Kube-proxy\tYes\tKube-proxy is available as an EKS add-on and it maintains network rules on your nodes and enables network communication to your spark application pods\tEKS kube-proxy Documentation Amazon EBS CSI driver\tYes\tEBS CSI driver is available as an EKS add-on and it allows EKS clusters to manage the lifecycle of EBS volumes\tEBS CSI Driver Documentation Karpenter\tYes\tKarpenter is nodegroup-less autoscaler that provides just-in-time compute capacity for spark applications on Kubernetes clusters\tKarpenter Documentation Cluster Autoscaler\tYes\tKubernetes Cluster Autoscaler automatically adjusts the size of Kubernetes cluster and is available for scaling nodegroups (such as core-node-group) in the cluster\tCluster Autoscaler Documentation Cluster proportional autoscaler\tYes\tThis is responsible for scaling CoreDNS pods in your Kubernetes cluster\tCluster Proportional Autoscaler Documentation Metrics server\tYes\tKubernetes metrics server is responsible for aggregating cpu, memory and other container resource usage within your cluster\tEKS Metrics Server Documentation Prometheus\tYes\tPrometheus is responsible for monitoring EKS cluster including spark applications in your EKS cluster. We use Prometheus deployment for scraping and ingesting metrics into Amazon Managed Prometheus and Kubecost\tPrometheus Documentation Amazon Managed Prometheus\tYes\tThis is responsible for storing and scaling of EKS cluster and spark application metrics\tAmazon Managed Prometheus Documentation Kubecost\tYes\tKubecost is responsible for providing cost break down by Spark application. You can monitor costs based on per job, namespace or labels\tEKS Kubecost Documentation CloudWatch metrics\tNo\tCloudWatch container insights metrics shows simple and standardized way to monitor not only AWS resources but also EKS resources on CloudWatch dashboard\tCloudWatch Container Insights Documentation AWS for Fluent-bit\tNo\tThis can be used to publish EKS cluster and worker node logs to CloudWatch Logs or 3rd party logging system\tAWS For Fluent-bit Documentation FSx for Lustre CSI driver\tNo\tThis can be used for running Spark application using FSx for Lustre\tFSx for Lustre CSI Driver Documentation  Customizing Add-ons üëà  Deploying the Solution üëà  ","version":"Next","tagName":"h2"},{"title":"Run Sample Spark job‚Äã","type":1,"pageTitle":"EMR on EKS with Karpenter","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-karpenter#run-sample-spark-job","content":" The pattern shows how to run spark jobs in a multi-tenant EKS cluster. The examples showcases two data teams using namespaces emr-data-team-a and emr-data-team-b mapped to their EMR virtual clusters. You can use different Karpenter provisioners for each team so that they can submit jobs that are unique to their workload. Teams can also use different storage requirements to run their Spark jobs. For example, you can use compute optimized provisioner that has taints and specify tolerations using pod templates so that you can run spark on compute optimized EC2 instances. In terms of storage, you can decide whether to use EC2 instance-store or EBS or FSx for lustre volumes for data processing. The default storage that is used in these examples is EC2 instance store because of performance benefit  spark-compute-optimized provisioner to run spark jobs on c5d instances.spark-memory-optimized provisioner to run spark jobs on r5d instances.spark-graviton-memory-optimized provisioner to run spark jobs on r6gd Graviton instances(ARM64).  spark-compute-optimizedspark-memory-optimizedspark-graviton-memory-optimized In this tutorial, you will use Karpenter provisioner that uses compute optimized instances. This template leverages the Karpenter AWSNodeTemplates. To view Karpenter provisioner for compute optimized instances, Click to toggle content! apiVersion: karpenter.sh/v1alpha5 kind: Provisioner metadata: name: spark-compute-optimized namespace: karpenter # Same namespace as Karpenter add-on installed spec: kubeletConfiguration: containerRuntime: containerd # podsPerCore: 2 # maxPods: 20 requirements: - key: &quot;topology.kubernetes.io/zone&quot; operator: In values: [${azs}a] #Update the correct region and zones - key: &quot;karpenter.sh/capacity-type&quot; operator: In values: [&quot;spot&quot;, &quot;on-demand&quot;] - key: &quot;node.kubernetes.io/instance-type&quot; #If not included, all instance types are considered operator: In values: [&quot;c5d.xlarge&quot;,&quot;c5d.2xlarge&quot;,&quot;c5d.4xlarge&quot;,&quot;c5d.9xlarge&quot;] # 1 NVMe disk - key: &quot;kubernetes.io/arch&quot; operator: In values: [&quot;amd64&quot;] limits: resources: cpu: 2000 providerRef: name: spark-compute-optimized labels: type: karpenter provisioner: spark-compute-optimized NodeGroupType: SparkComputeOptimized taints: - key: spark-compute-optimized value: 'true' effect: NoSchedule ttlSecondsAfterEmpty: 120 # optional, but never scales down if not set --- apiVersion: karpenter.k8s.aws/v1alpha1 kind: AWSNodeTemplate metadata: name: spark-compute-optimized namespace: karpenter spec: blockDeviceMappings: - deviceName: /dev/xvda ebs: volumeSize: 100Gi volumeType: gp3 encrypted: true deleteOnTermination: true metadataOptions: httpEndpoint: enabled httpProtocolIPv6: disabled httpPutResponseHopLimit: 2 httpTokens: required subnetSelector: Name: &quot;${eks_cluster_id}-private*&quot; # Name of the Subnets to spin up the nodes securityGroupSelector: # required, when not using launchTemplate Name: &quot;${eks_cluster_id}-node*&quot; # name of the SecurityGroup to be used with Nodes # instanceProfile: &quot;&quot; # optional, if already set in controller args #RAID0 config example userData: | MIME-Version: 1.0 Content-Type: multipart/mixed; boundary=&quot;BOUNDARY&quot; --BOUNDARY Content-Type: text/x-shellscript; charset=&quot;us-ascii&quot; cat &lt;&lt;-EOF &gt; /etc/profile.d/bootstrap.sh #!/bin/sh # Configure the NVMe volumes in RAID0 configuration in the bootstrap.sh call. # https://github.com/awslabs/amazon-eks-ami/blob/master/files/bootstrap.sh#L35 # This will create a RAID volume and mount it at /mnt/k8s-disks/0 # then mount that volume to /var/lib/kubelet, /var/lib/containerd, and /var/log/pods # this allows the container daemons and pods to write to the RAID0 by default without needing PersistentVolumes export LOCAL_DISKS='raid0' EOF # Source extra environment variables in bootstrap script sed -i '/^set -o errexit/a\\\\nsource /etc/profile.d/bootstrap.sh' /etc/eks/bootstrap.sh --BOUNDARY-- tags: InstanceType: &quot;spark-compute-optimized&quot; # optional, add tags for your own use To run Spark Jobs that can use this provisioner, you need to submit your jobs by adding tolerations to your pod templates For example, spec: tolerations: - key: &quot;spark-compute-optimized&quot; operator: &quot;Exists&quot; effect: &quot;NoSchedule&quot; Execute the sample PySpark Job to trigger compute optimized Karpenter provisioner The following script requires four input parameters virtual_cluster_id, job_execution_role_arn, cloudwatch_log_group_name &amp; S3_Bucket to store PySpark scripts, Pod templates and Input data. You can get these values terraform apply output values or by running terraform output. For S3_BUCKET, Either create a new S3 bucket or use an existing S3 bucket. caution This shell script downloads the test data to your local machine and uploads to S3 bucket. Verify the shell script before running the job. cd data-on-eks/analytics/terraform/emr-eks-karpenter/examples/nvme-ssd/karpenter-compute-provisioner/ ./execute_emr_eks_job.sh Enter the EMR Virtual Cluster ID: 4ucrncg6z4nd19vh1lidna2b3 Enter the EMR Execution Role ARN: arn:aws:iam::123456789102:role/emr-eks-karpenter-emr-eks-data-team-a Enter the CloudWatch Log Group name: /emr-on-eks-logs/emr-eks-karpenter/emr-data-team-a Enter the S3 Bucket for storing PySpark Scripts, Pod Templates and Input data. For e.g., s3://&lt;bucket-name&gt;: s3://example-bucket Karpenter may take between 1 and 2 minutes to spin up a new compute node as specified in the provisioner templates before running the Spark Jobs. Nodes will be drained with once the job is completed Verify the job execution kubectl get pods --namespace=emr-data-team-a -w   ","version":"Next","tagName":"h2"},{"title":"Execute the sample PySpark job that uses EBS volumes and compute optimized Karpenter provisioner‚Äã","type":1,"pageTitle":"EMR on EKS with Karpenter","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-karpenter#execute-the-sample-pyspark-job-that-uses-ebs-volumes-and-compute-optimized-karpenter-provisioner","content":" This pattern uses EBS volumes for data processing and compute optimized provisioner. You can modify the provisioner by changing nodeselector in driver and executor pod templates. In order to change provisioners, simply update your pod templates to desired provisioner   nodeSelector: NodeGroupType: &quot;SparkComputeOptimized&quot;   You can also update EC2 instances that doesn't include instance store volumes (for example c5.xlarge) and remove c5d's if needed for this exercise  We will create Storageclass that will be used by drivers and executors. We'll create static Persistent Volume Claim (PVC) for the driver pod but we'll use dynamically created ebs volumes for executors.  Create StorageClass and PVC using example provided  cd data-on-eks/analytics/terraform/emr-eks-karpenter/examples/ebs-pvc/karpenter-compute-provisioner-ebs/ kubectl apply -f ebs-storageclass-pvc.yaml   Let's run the job  cd data-on-eks/analytics/terraform/emr-eks-karpenter/examples/ebs-pvc/karpenter-compute-provisioner-ebs/ ./execute_emr_eks_job.sh Enter the EMR Virtual Cluster ID: 4ucrncg6z4nd19vh1lidna2b3 Enter the EMR Execution Role ARN: arn:aws:iam::123456789102:role/emr-eks-karpenter-emr-eks-data-team-a Enter the CloudWatch Log Group name: /emr-on-eks-logs/emr-eks-karpenter/emr-data-team-a Enter the S3 Bucket for storing PySpark Scripts, Pod Templates and Input data. For e.g., s3://&lt;bucket-name&gt;: s3://example-bucket   You'll notice the PVC spark-driver-pvc will be used by driver pod but Spark will create multiple ebs volumes for executors mapped to Storageclass emr-eks-karpenter-ebs-sc. All dynamically created ebs volumes will be deleted once the job completes  ","version":"Next","tagName":"h3"},{"title":"Running Sample Spark job using FSx for Lustre‚Äã","type":1,"pageTitle":"EMR on EKS with Karpenter","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-karpenter#running-sample-spark-job-using-fsx-for-lustre","content":" Amazon FSx for Lustre is a fully managed shared storage option built on the world‚Äôs most popular high-performance file system. You can use FSx to store shuffle files and also to store intermediate data processing tasks in a data pipeline. You can read more about FSX for Lustre in documentation and learn how to use this storage with EMR on EKS in our best practices guide  In this example, you will learn how to deploy, configure and use FSx for Lustre as a shuffle storage. There are two ways to use FSx for Lustre  using static FSx for Lustre volumesusing dynamically created FSx for Lustre volumes  fsx-staticfsx-dynamic Execute Spark Job by using FSx for Lustre with statically provisioned volume and compute optimized Karpenter provisioner. Fsx for Lustre Terraform module is disabled by default. Follow the customizing add-ons steps before running Spark jobs. Execute the Spark job using the below shell script. This script requires input parameters which can be extracted from terraform apply output values. caution This shell script downloads the test data to your local machine and uploads to S3 bucket. Verify the shell script before running the job. cd analytics/terraform/emr-eks-karpenter/examples/fsx-for-lustre/fsx-static-pvc-shuffle-storage ./fsx-static-spark.sh Karpetner may take between 1 and 2 minutes to spin up a new compute node as specified in the provisioner templates before running the Spark Jobs. Nodes will be drained with once the job is completed Verify the job execution events kubectl get pods --namespace=emr-data-team-a -w This will show the mounted /data directory with FSx DNS name kubectl exec -ti taxidata-exec-1 -c spark-kubernetes-executor -n emr-data-team-a -- df -h kubectl exec -ti taxidata-exec-1 -c spark-kubernetes-executor -n emr-data-team-a -- ls -lah /static   ","version":"Next","tagName":"h3"},{"title":"Running Sample Spark job using Apache YuniKorn Batch Scheduler‚Äã","type":1,"pageTitle":"EMR on EKS with Karpenter","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-karpenter#running-sample-spark-job-using-apache-yunikorn-batch-scheduler","content":" Apache YuniKorn is an open-source, universal resource scheduler for managing distributed big data processing workloads such as Spark, Flink, and Storm. It is designed to efficiently manage resources across multiple tenants in a shared, multi-tenant cluster environment. Some of the key features of Apache YuniKorn include:  Flexibility: YuniKorn provides a flexible and scalable architecture that can handle a wide variety of workloads, from long-running services to batch jobs.Dynamic Resource Allocation: YuniKorn uses a dynamic resource allocation mechanism to allocate resources to workloads on an as-needed basis, which helps to minimize resource wastage and improve overall cluster utilization.Priority-based Scheduling: YuniKorn supports priority-based scheduling, which allows users to assign different levels of priority to their workloads based on business requirements.Multi-tenancy: YuniKorn supports multi-tenancy, which enables multiple users to share the same cluster while ensuring resource isolation and fairness.Pluggable Architecture: YuniKorn has a pluggable architecture that allows users to extend its functionality with custom scheduling policies and pluggable components.  Apache YuniKorn is a powerful and versatile resource scheduler that can help organizations efficiently manage their big data workloads while ensuring high resource utilization and workload performance.  Apache YuniKorn Architecture  Apache YuniKorn Gang Scheduling with Karpenter  Apache YuniKorn Scheduler add-on is disabled by default. Follow the steps to deploy the Apache YuniKorn add-on and execute the Spark job.  Update the analytics/terraform/emr-eks-karpenter/variables.tf file with the following  variable &quot;enable_yunikorn&quot; { default = true description = &quot;Enable Apache YuniKorn Scheduler&quot; type = bool }   Execute terrafrom apply again. This will deploy FSx for Lustre add-on and all the necessary resources.  terraform apply -auto-approve   This example demonstrates the Apache YuniKorn Gang Scheduling with Karpenter Autoscaler.  cd analytics/terraform/emr-eks-karpenter/examples/nvme-ssd/karpenter-yunikorn-gangscheduling ./execute_emr_eks_job.sh   Verify the job executionApache YuniKorn Gang Scheduling will create pause pods for total number of executors requested.  kubectl get pods --namespace=emr-data-team-a -w   Verify the driver and executor pods prefix with tg- indicates the pause pods. These pods will be replaced with the actual Spark Driver and Executor pods once the Nodes are scaled and ready by the Karpenter.    Delta Lake Table Format üëà  ","version":"Next","tagName":"h3"},{"title":"Run Interactive Workload with Managed Endpoint‚Äã","type":1,"pageTitle":"EMR on EKS with Karpenter","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-karpenter#run-interactive-workload-with-managed-endpoint","content":" Managed endpoint is a gateway that provides connectivity from EMR Studio to EMR on EKS so that you can run interactive workloads. You can find out more information about it here.  ","version":"Next","tagName":"h2"},{"title":"Creating a managed endpoint‚Äã","type":1,"pageTitle":"EMR on EKS with Karpenter","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-karpenter#creating-a-managed-endpoint","content":" In this example, we will create a managed endpoint under one of the data teams.  Navigate to folder and execute script: cd analytics/terraform/emr-eks-karpenter/examples/managed-endpoints ./create-managed-endpoint.sh   Enter the EMR Virtual Cluster Id: 4ucrncg6z4nd19vh1lidna2b3 Provide your EMR on EKS team (emr-data-team-a or emr-data-team-b): emr-eks-data-team-a Enter your AWS Region: us-west-2 Enter a name for your endpoint: emr-eks-team-a-endpoint Provide an S3 bucket location for logging (i.e. s3://my-bucket/logging/): s3://&lt;bucket-name&gt;/logs Enter the EMR Execution Role ARN (i.e. arn:aws:00000000000000000:role/EMR-Execution-Role): arn:aws:iam::181460066119:role/emr-eks-karpenter-emr-data-team-a   The script will provide the following:  JSON configuration file for the Managed EndpointConfiguration settings: Default 8G Spark DriverCloudWatch monitoring, with logs stored in the S3 bucket provided Proper endpoint creation with appropriate security group to allow using KarpenterOutputs: Managed Endpoint ID and Load Balancer ARN.  Once you have created a managed endpoint, you can follow the instructions here to configure EMR Studio and associate the Managed endpoint to a workspace.  ","version":"Next","tagName":"h3"},{"title":"Cleanup of Endpoint resources‚Äã","type":1,"pageTitle":"EMR on EKS with Karpenter","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-karpenter#cleanup-of-endpoint-resources","content":" To delete the managed endpoint, simply run the following command:  aws emr-containers delete-managed-endpoint --id &lt;Managed Endpoint ID&gt; --virtual-cluster-id &lt;Virtual Cluster ID&gt;   ","version":"Next","tagName":"h3"},{"title":"Cleanup‚Äã","type":1,"pageTitle":"EMR on EKS with Karpenter","url":"/data-on-eks/docs/blueprints/amazon-emr-on-eks/emr-eks-karpenter#cleanup","content":" Cleanup üëà  caution To avoid unwanted charges to your AWS account, delete all the AWS resources created during this deployment ","version":"Next","tagName":"h2"},{"title":"Apache Kafka","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka","content":"","keywords":"","version":"Next"},{"title":"Strimzi for Apache Kafka‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#strimzi-for-apache-kafka","content":" Strimzi provides a way to run an Apache Kafka cluster on Kubernetes in various deployment configurations. Strimzi combines security and simple configuration to deploy and manage Kafka on Kubernetes using kubectl and/or GitOps based on the Operator Pattern.  ","version":"Next","tagName":"h2"},{"title":"Architecture‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#architecture","content":" info Architecture diagram work in progress  ","version":"Next","tagName":"h2"},{"title":"Managed Alternatives‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#managed-alternatives","content":" ","version":"Next","tagName":"h2"},{"title":"Amazon Managed Streaming for Apache Kafka (MSK)‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#amazon-managed-streaming-for-apache-kafka-msk","content":" Amazon Managed Streaming for Apache Kafka (Amazon MSK) is a fully managed service that enables you to build and run applications that use Apache Kafka to process streaming data. Amazon MSK provides the control-plane operations, such as those for creating, updating, and deleting clusters. It lets you use Apache Kafka data-plane operations, such as those for producing and consuming data. It runs open-source versions of Apache Kafka. This means existing applications, tooling, and plugins from partners and the Apache Kafka community are supported. You can use Amazon MSK to create clusters that use any of the Apache Kafka versions listed under Supported Apache Kafka versions. Amazon MSK offers cluster-based or serverless deployment types.  ","version":"Next","tagName":"h3"},{"title":"Amazon Kinesis Data Streams (KDS)‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#amazon-kinesis-data-streams-kds","content":" Amazon Kinesis Data Streams (KDS) allows users to collect and process large streams of data records in real time. You can create data-processing applications, known as Kinesis Data Streams applications. A typical Kinesis Data Streams application reads data from a data stream as data records. You can send the processed records to dashboards, use them to generate alerts, dynamically change pricing and advertising strategies, or send data to a variety of other AWS services. Kinesis Data Streams support your choice of stream processing framework including Kinesis Client Library (KCL), Apache Flink, and Apache Spark Streaming. It is serverless, and scales automatically.  ","version":"Next","tagName":"h3"},{"title":"Storage considerations when self-managing Kafka‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#storage-considerations-when-self-managing-kafka","content":" The most common resource bottlenecks for Kafka clusters are network throughput, storage throughput, and network throughput between brokers and the storage backend for brokers using network attached storage such as Amazon Elastic Block Store (EBS).  ","version":"Next","tagName":"h2"},{"title":"Advantages to using EBS as persistent storage backend‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#advantages-to-using-ebs-as-persistent-storage-backend","content":" Improved flexibility and faster recovery: Fault tolerance is commonly achieved via broker (server) replication within the cluster and/or maintaining cross-AZ or region replicas. Since the lifecycle of EBS volumes is independent of Kafka brokers, if a broker fails and needs to be replaced, the EBS volume attached to the failed broker can be reattached to a replacement broker. Most of the replicated data for the replacement broker is already available in the EBS volume, and does not need to be copied over the network from another broker. This avoids most of the replication traffic required to bring the replacement broker up to speed with current operations.Just in time scale up: The characteristics of EBS volumes can be modified while they‚Äôre in use. Broker storage can be automatically scaled over time rather than provisioning storage for peak or adding additional brokers.Optimized for frequently-accessed-throughput-intensive workloads: Volume types such as st1 can be a good fit since these volumes are offered at a relatively low cost, support a large 1 MiB I/O block size, max IOPS of 500/volume, and includes the ability to burst up to 250 MB/s per TB, with a baseline throughput of 40 MB/s per TB, and a maximum throughput of 500 MB/s per volume.  ","version":"Next","tagName":"h3"},{"title":"What EBS volumes should I use when self-managing Kafka on AWS?‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#what-ebs-volumes-should-i-use-when-self-managing-kafka-on-aws","content":" General purpose SSD volume gp3 with a balanced price and performance are widely used, and you can independently provision storage (up to 16TiB), IOPS (up to 16,000) and throughput (up to 1,000MiB/s)st1 is a low-cost HDD option for frequently accessed and throughput intensive workloads with up to 500 IOPS and 500 MiB/sFor critical applications such as Zookeeper, provisioned IOPS volumes (io2 Block Express, io2) provide higher durability  ","version":"Next","tagName":"h3"},{"title":"Deploying the Solution‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#deploying-the-solution","content":" In this example, you will provision the following resources to run Kafka Cluster on EKS.  This example deploys an EKS Cluster with Kafka into a new VPC.  Creates a new sample VPC, 3 Private Subnets and 3 Public Subnets.Creates Internet gateway for Public Subnets and NAT Gateway for Private Subnets.Creates EKS Cluster Control plane with public endpoint (for demo reasons only) with two managed node groups.Deploys Metrics server, Cluster Autoscaler, self-managed ebs-csi-driver, Strimzi Kafka Operator, Grafana Operator.Strimzi Kafka Operator is a Kubernetes Operator for Apache Kafka deployed to strimzi-kafka-operator namespace. The operator by default watches and handles kafka in all namespaces.  ","version":"Next","tagName":"h2"},{"title":"Prerequisites‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#prerequisites","content":" Ensure that you have installed the following tools on your machine.  aws clikubectlterraform  ","version":"Next","tagName":"h3"},{"title":"Deploy‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#deploy","content":" Clone the repository  git clone https://github.com/awslabs/data-on-eks.git   Navigate into one of the example directories and run terraform init  cd data-on-eks/streaming/kafka terraform init   Run Terraform plan to verify the resources created by this execution.  export AWS_REGION=&quot;us-west-2&quot; # Select your own region terraform plan -var=&quot;region=$AWS_REGION&quot;   Deploy the pattern  terraform apply -var=&quot;region=$AWS_REGION&quot;   Enter yes to apply.  info This deployment may take between 20 to 30mins.  ","version":"Next","tagName":"h3"},{"title":"Verify the deployment‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#verify-the-deployment","content":" ","version":"Next","tagName":"h2"},{"title":"Create kube config‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#create-kube-config","content":" Create kube config file.  aws eks --region $AWS_REGION update-kubeconfig --name kafka-on-eks   ","version":"Next","tagName":"h3"},{"title":"Get nodes‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#get-nodes","content":" Check if the deployment has created 6 nodes. 3 nodes for Core Node group and 3 for Kafka brokers across 3 AZs.  kubectl get nodes   Output  NAME STATUS ROLES AGE VERSION ip-10-0-10-36.us-west-2.compute.internal Ready &lt;none&gt; 5h28m v1.24.7-eks-fb459a0 ip-10-0-10-47.us-west-2.compute.internal Ready &lt;none&gt; 5h20m v1.24.7-eks-fb459a0 ip-10-0-11-218.us-west-2.compute.internal Ready &lt;none&gt; 5h20m v1.24.7-eks-fb459a0 ip-10-0-11-223.us-west-2.compute.internal Ready &lt;none&gt; 5h20m v1.24.7-eks-fb459a0 ip-10-0-12-202.us-west-2.compute.internal Ready &lt;none&gt; 5h20m v1.24.7-eks-fb459a0 ip-10-0-12-50.us-west-2.compute.internal Ready &lt;none&gt; 5h20m v1.24.7-eks-fb459a0   ","version":"Next","tagName":"h3"},{"title":"Verify Kafka Brokers and Zookeeper‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#verify-kafka-brokers-and-zookeeper","content":" Verify the Kafka Broker and Zookeeper pods and the status created by the Strimzi Operator.  kubectl get strimzipodsets.core.strimzi.io -n kafka   Output  NAME PODS READY PODS CURRENT PODS AGE cluster-kafka 3 3 3 4h35m cluster-zookeeper 3 3 3 4h36m  kubectl get kafka.kafka.strimzi.io -n kafka   Output  NAME DESIRED KAFKA REPLICAS DESIRED ZK REPLICAS READY WARNINGS cluster 3 3 True  kubectl get kafkatopic.kafka.strimzi.io -n kafka   Output  NAME CLUSTER PARTITIONS REPLICATION FACTOR READY consumer-offsets---84e7a678d08f4bd226872e5cdd4eb527fadc1c6a cluster 50 3 True strimzi-store-topic---effb8e3e057afce1ecf67c3f5d8e4e3ff177fc55 cluster 1 3 True strimzi-topic-operator-kstreams-topic-store-changelog---b75e702040b99be8a9263134de3507fc0cc4017b cluster 1 3 True strimzi.cruisecontrol.metrics cluster 1 3 True strimzi.cruisecontrol.modeltrainingsamples cluster 32 2 True strimzi.cruisecontrol.partitionmetricsamples cluster 32 2 True  ","version":"Next","tagName":"h3"},{"title":"Verify the running Kafka pods‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#verify-the-running-kafka-pods","content":" kubectl get pods -n kafka   Output  NAME READY STATUS RESTARTS AGE cluster-cruise-control-79f6457f8d-sm8c2 1/1 Running 0 4h40m cluster-entity-operator-5594c965ff-t9nl4 3/3 Running 0 4h40m cluster-kafka-0 1/1 Running 0 4h41m cluster-kafka-1 1/1 Running 0 4h41m cluster-kafka-2 1/1 Running 0 4h41m cluster-kafka-exporter-9dbfdff54-wx8vq 1/1 Running 0 4h39m cluster-zookeeper-0 1/1 Running 0 4h42m cluster-zookeeper-1 1/1 Running 0 4h42m cluster-zookeeper-2 1/1 Running 0 4h42m  ","version":"Next","tagName":"h3"},{"title":"Create Kafka Topic and run Sample test‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#create-kafka-topic-and-run-sample-test","content":" We will create one kafka topic and run sample producer script to produce new messages to the kafka topic. We can then verify the data in the topic using sample consumer script.  ","version":"Next","tagName":"h2"},{"title":"Create a kafka Topic‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#create-a-kafka-topic","content":" Run this command to create a new topic called test-topic under kafka namespace  cd streaming/kafka/examples/ kubectl apply -f kafka-topics.yaml   Verify the status of the test-topic topic.  kubectl exec -it cluster-kafka-0 -c kafka -n kafka -- /bin/bash -c &quot;/opt/kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092&quot;   Output  __consumer_offsets __strimzi-topic-operator-kstreams-topic-store-changelog __strimzi_store_topic strimzi.cruisecontrol.metrics strimzi.cruisecontrol.modeltrainingsamples strimzi.cruisecontrol.partitionmetricsamples test-topic  ","version":"Next","tagName":"h3"},{"title":"Execute sample Kafka Producer‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#execute-sample-kafka-producer","content":" Open two terminals one for Kafka producer and one for Kafka Consumer.  Execute the following command and press enter twice until you see the &gt; prompt. Start typing some random content. This data will be written to the test-topic.  kubectl -n kafka run kafka-producer -ti --image=strimzi/kafka:0.14.0-kafka-2.3.0 --rm=true --restart=Never -- bin/kafka-console-producer.sh --broker-list cluster-kafka-bootstrap:9092 --topic test-topic   ","version":"Next","tagName":"h3"},{"title":"Execute sample Kafka Consumer‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#execute-sample-kafka-consumer","content":" Now, you can verify the data written to test-topic by running Kafka consumer pod in another terminal  kubectl -n kafka run kafka-consumer -ti --image=strimzi/kafka:0.14.0-kafka-2.3.0 --rm=true --restart=Never -- bin/kafka-console-consumer.sh --bootstrap-server cluster-kafka-bootstrap:9092 --topic test-topic   ","version":"Next","tagName":"h3"},{"title":"Kafka Producer and Consumer output‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#kafka-producer-and-consumer-output","content":"   ","version":"Next","tagName":"h3"},{"title":"Grafana Dashboard for Kafka‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#grafana-dashboard-for-kafka","content":" ","version":"Next","tagName":"h2"},{"title":"Login to Grafana‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#login-to-grafana","content":" Login to Grafana dashboard by running the following command.  kubectl port-forward svc/kube-prometheus-stack-grafana 8080:80 -n kube-prometheus-stack   Open browser with local Grafana Web UI  Enter username as admin and password can be extracted from AWS Secrets Manager with the below command.  aws secretsmanager get-secret-value \\ --secret-id kafka-on-eks-grafana --region $AWS_REGION --query &quot;SecretString&quot; --output text   ","version":"Next","tagName":"h3"},{"title":"Open Strimzi Kafka Dashboard‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#open-strimzi-kafka-dashboard","content":" The below are builtin Kafka dashboards which created during the deployment.    ","version":"Next","tagName":"h3"},{"title":"Open Strimzi Zookeeper Dashboard‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#open-strimzi-zookeeper-dashboard","content":"   ","version":"Next","tagName":"h3"},{"title":"Open Strimzi Kafka Exporter‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#open-strimzi-kafka-exporter","content":" You can verify the test-topic with three partitions below.    ","version":"Next","tagName":"h3"},{"title":"Cleanup‚Äã","type":1,"pageTitle":"Apache Kafka","url":"/data-on-eks/docs/blueprints/streaming-platforms/kafka#cleanup","content":" To clean up your environment, destroy the Terraform modules in reverse order with --target option to avoid destroy failures.  Destroy the Kubernetes Add-ons, EKS cluster with Node groups and VPC  terraform destroy -target=&quot;module.eks_blueprints_kubernetes_addons&quot; -auto-approve terraform destroy -target=&quot;module.eks_blueprints&quot; -auto-approve terraform destroy -target=&quot;module.vpc&quot; -auto-approve   Finally, destroy any additional resources that are not in the above modules  terraform destroy -auto-approve   caution To avoid unwanted charges to your AWS account, delete all the AWS resources created during this deployment ex. Delete kafka-on-eks EBS volumes ","version":"Next","tagName":"h2"},{"title":"Troubleshooting","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/troubleshooting","content":"","keywords":"","version":"Next"},{"title":"Error: local-exec provisioner error‚Äã","type":1,"pageTitle":"Troubleshooting","url":"/data-on-eks/docs/blueprints/troubleshooting#error-local-exec-provisioner-error","content":" If you encounter the following error during the execution of the local-exec provisioner:  Error: local-exec provisioner error \\ with module.eks-blueprints.module.emr_on_eks[&quot;data_team_b&quot;].null_resource.update_trust_policy,\\ on .terraform/modules/eks-blueprints/modules/emr-on-eks/main.tf line 105, in resource &quot;null_resource&quot; \\ &quot;update_trust_policy&quot;:‚îÇ 105: provisioner &quot;local-exec&quot; {‚îÇ ‚îÇ Error running command 'set -e‚îÇ ‚îÇ aws emr-containers update-role-trust-policy \\ ‚îÇ --cluster-name emr-on-eks \\‚îÇ --namespace emr-data-team-b \\‚îÇ --role-name emr-on-eks-emr-eks-data-team-b   ","version":"Next","tagName":"h2"},{"title":"Issue Description:‚Äã","type":1,"pageTitle":"Troubleshooting","url":"/data-on-eks/docs/blueprints/troubleshooting#issue-description","content":" The error message indicates that the emr-containers command is not present in the AWS CLI version being used. This issue has been addressed and fixed in AWS CLI version 2.0.54.  ","version":"Next","tagName":"h3"},{"title":"Solution‚Äã","type":1,"pageTitle":"Troubleshooting","url":"/data-on-eks/docs/blueprints/troubleshooting#solution","content":" To resolve the issue, update your AWS CLI version to 2.0.54 or a later version by executing the following command:  pip install --upgrade awscliv2   By updating the AWS CLI version, you will ensure that the necessary emr-containers command is available and can be executed successfully during the provisioning process.  If you continue to experience any issues or require further assistance, please consult the AWS CLI GitHub issue for more details or contact our support team for additional guidance.  ","version":"Next","tagName":"h3"},{"title":"Timeouts during Terraform Destroy‚Äã","type":1,"pageTitle":"Troubleshooting","url":"/data-on-eks/docs/blueprints/troubleshooting#timeouts-during-terraform-destroy","content":" ","version":"Next","tagName":"h2"},{"title":"Issue Description:‚Äã","type":1,"pageTitle":"Troubleshooting","url":"/data-on-eks/docs/blueprints/troubleshooting#issue-description-1","content":" Customers may experience timeouts during the deletion of their environments, specifically when VPCs are being deleted. This is a known issue related to the vpc-cni component.  ","version":"Next","tagName":"h3"},{"title":"Symptoms:‚Äã","type":1,"pageTitle":"Troubleshooting","url":"/data-on-eks/docs/blueprints/troubleshooting#symptoms","content":" ENIs (Elastic Network Interfaces) remain attached to subnets even after the environment is destroyed. The EKS managed security group associated with the ENI cannot be deleted by EKS.  ","version":"Next","tagName":"h3"},{"title":"Solution:‚Äã","type":1,"pageTitle":"Troubleshooting","url":"/data-on-eks/docs/blueprints/troubleshooting#solution-1","content":" To overcome this issue, follow the recommended solution below:  Utilize the provided cleanup.sh scripts to ensure a proper cleanup of resources. Run the `cleanup.sh`` script, which is included in the blueprint. This script will handle the removal of any lingering ENIs and associated security groups.  ","version":"Next","tagName":"h3"},{"title":"Error: could not download chart‚Äã","type":1,"pageTitle":"Troubleshooting","url":"/data-on-eks/docs/blueprints/troubleshooting#error-could-not-download-chart","content":" If you encounter the following error while attempting to download a chart:  ‚îÇ Error: could not download chart: failed to download &quot;oci://public.ecr.aws/karpenter/karpenter&quot; at version &quot;v0.18.1&quot; ‚îÇ ‚îÇ with module.eks_blueprints_kubernetes_addons.module.karpenter[0].module.helm_addon.helm_release.addon[0], ‚îÇ on .terraform/modules/eks_blueprints_kubernetes_addons/modules/kubernetes-addons/helm-addon/main.tf line 1, in resource &quot;helm_release&quot; &quot;addon&quot;: ‚îÇ 1: resource &quot;helm_release&quot; &quot;addon&quot; { ‚îÇ   Follow the steps below to resolve the issue:  ","version":"Next","tagName":"h2"},{"title":"Issue Description:‚Äã","type":1,"pageTitle":"Troubleshooting","url":"/data-on-eks/docs/blueprints/troubleshooting#issue-description-2","content":" The error message indicates that there was a failure in downloading the specified chart. This issue can occur due to a bug in Terraform during the installation of Karpenter.  ","version":"Next","tagName":"h3"},{"title":"Solution:‚Äã","type":1,"pageTitle":"Troubleshooting","url":"/data-on-eks/docs/blueprints/troubleshooting#solution-2","content":" To resolve the issue, you can try the following steps:  Authenticate with ECR: Run the following command to authenticate with the ECR (Elastic Container Registry) where the chart is located:  aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws   Re-run terraform apply: Execute the terraform apply command again with the --auto-approve flag to reapply the Terraform configuration:  terraform apply --auto-approve   By authenticating with ECR and re-running the terraform apply command, you will ensure that the necessary chart can be downloaded successfully during the installation process.  ","version":"Next","tagName":"h3"},{"title":"Terraform apply/destroy error to authenticate with EKS Cluster‚Äã","type":1,"pageTitle":"Troubleshooting","url":"/data-on-eks/docs/blueprints/troubleshooting#terraform-applydestroy-error-to-authenticate-with-eks-cluster","content":" ERROR: ‚ï∑ ‚îÇ Error: Get &quot;http://localhost/api/v1/namespaces/kube-system/configmaps/aws-auth&quot;: dial tcp [::1]:80: connect: connection refused ‚îÇ ‚îÇ with module.eks.kubernetes_config_map_v1_data.aws_auth[0], ‚îÇ on .terraform/modules/eks/main.tf line 550, in resource &quot;kubernetes_config_map_v1_data&quot; &quot;aws_auth&quot;: ‚îÇ 550: resource &quot;kubernetes_config_map_v1_data&quot; &quot;aws_auth&quot; { ‚îÇ ‚ïµ   Solution:In this situation Terraform is unable to refresh the data resources and authenticate with EKS Cluster. See the discussion here  Try this approach first by using exec plugin.  provider &quot;kubernetes&quot; { host = module.eks_blueprints.eks_cluster_endpoint cluster_ca_certificate = base64decode(module.eks_blueprints.eks_cluster_certificate_authority_data) exec { api_version = &quot;client.authentication.k8s.io/v1beta1&quot; command = &quot;aws&quot; args = [&quot;eks&quot;, &quot;get-token&quot;, &quot;--cluster-name&quot;, module.eks_blueprints.eks_cluster_id] } }   If the issue still persists even after the above change then you can use alternative approach of using local kube config file. NOTE: This approach might not be ideal for production. It helps you to apply/destroy clusters with your local kube config.  Create a local kubeconfig for your cluster  aws eks update-kubeconfig --name &lt;EKS_CLUSTER_NAME&gt; --region &lt;CLUSTER_REGION&gt;   Update the providers.tf file with the below config by just using the config_path.  provider &quot;kubernetes&quot; { config_path = &quot;&lt;HOME_PATH&gt;/.kube/config&quot; } provider &quot;helm&quot; { kubernetes { config_path = &quot;&lt;HOME_PATH&gt;/.kube/config&quot; } } provider &quot;kubectl&quot; { config_path = &quot;&lt;HOME_PATH&gt;/.kube/config&quot; }   ","version":"Next","tagName":"h2"},{"title":"EMR Containers Virtual Cluster (dhwtlq9yx34duzq5q3akjac00) delete: unexpected state 'ARRESTED'‚Äã","type":1,"pageTitle":"Troubleshooting","url":"/data-on-eks/docs/blueprints/troubleshooting#emr-containers-virtual-cluster-dhwtlq9yx34duzq5q3akjac00-delete-unexpected-state-arrested","content":" If you encounter an error message stating &quot;waiting for EMR Containers Virtual Cluster (xwbc22787q6g1wscfawttzzgb) delete: unexpected state 'ARRESTED', wanted target ''. last error: %!s(nil)&quot;, you can follow the steps below to resolve the issue:  Note: Replace &lt;REGION&gt; with the appropriate AWS region where the virtual cluster is located.  Open a terminal or command prompt.Run the following command to list the virtual clusters in the &quot;ARRESTED&quot; state:  aws emr-containers list-virtual-clusters --region &lt;REGION&gt; --states ARRESTED \\ --query 'virtualClusters[0].id' --output text   This command retrieves the ID of the virtual cluster in the &quot;ARRESTED&quot; state.  Run the following command to delete the virtual cluster:  aws emr-containers list-virtual-clusters --region &lt;REGION&gt; --states ARRESTED \\ --query 'virtualClusters[0].id' --output text | xargs -I{} aws emr-containers delete-virtual-cluster \\ --region &lt;REGION&gt; --id {}   Replace &lt;VIRTUAL_CLUSTER_ID&gt; with the ID of the virtual cluster obtained from the previous step.  By executing these commands, you will be able to delete the virtual cluster that is in the &quot;ARRESTED&quot; state. This should resolve the unexpected state issue and allow you to proceed with further operations.  ","version":"Next","tagName":"h2"},{"title":"Terminating namespace issue‚Äã","type":1,"pageTitle":"Troubleshooting","url":"/data-on-eks/docs/blueprints/troubleshooting#terminating-namespace-issue","content":" If you encounter the issue where a namespace is stuck in the &quot;Terminating&quot; state and cannot be deleted, you can use the following command to remove the finalizers on the namespace:  Note: Replace &lt;namespace&gt; with the name of the namespace you want to delete.  NAMESPACE=&lt;namespace&gt; kubectl get namespace $NAMESPACE -o json | sed 's/&quot;kubernetes&quot;//' | kubectl replace --raw &quot;/api/v1/namespaces/$NAMESPACE/finalize&quot; -f -   This command retrieves the namespace details in JSON format, removes the &quot;kubernetes&quot; finalizer, and performs a replace operation to remove the finalizer from the namespace. This should allow the namespace to complete the termination process and be successfully deleted.  Please ensure that you have the necessary permissions to perform this operation. If you continue to experience issues or require further assistance, please reach out to our support team for additional guidance and troubleshooting steps. ","version":"Next","tagName":"h2"},{"title":"Apache NiFi on EKS","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/streaming-platforms/nifi","content":"","keywords":"","version":"Next"},{"title":"Introduction‚Äã","type":1,"pageTitle":"Apache NiFi on EKS","url":"/data-on-eks/docs/blueprints/streaming-platforms/nifi#introduction","content":" Apache NiFi is an open-source data integration and management system designed to automate and manage the flow of data between systems. It provides a web-based user interface for creating, monitoring, and managing data flows in real-time.  With its powerful and flexible architecture, Apache NiFi can handle a wide range of data sources, cloud platforms, and formats, including structured and unstructured data, and can be used for a variety of data integration scenarios, such as data ingest, data processing (low to medium level), data routing, data transformation, and data dissemination.  Apache NiFi provides a GUI based interface for building and managing data flows, making it easier for non-technical users. It also offers robust security features, including SSL, SSH, and fine-grained access control, to ensure the safe and secure transfer of sensitive data. Whether you are a data analyst, a data engineer, or a data scientist, Apache NiFi provides a comprehensive solution for managing and integrating your data on AWS and other platforms.  caution This blueprint should be considered as experimental and should only be used for proof of concept.  This example deploys an EKS Cluster running the Apache NiFi cluster. In the example, Apache NIfi is streaming data from the AWS Kinesis Data Stream to an Amazon DynamoDB table after some format transformation.  Creates a new sample VPC, 3 Private Subnets and 3 Public SubnetsCreates Internet gateway for Public Subnets and NAT Gateway for Private SubnetsCreates EKS Cluster Control plane with public endpoint (for demo reasons only) with one managed node groupDeploys Apache NiFi, AWS Load Balancer Controller, Cert Manager and External DNS (optional) add-onsDeploys Apache NiFi cluster in the nifi namespace  ","version":"Next","tagName":"h2"},{"title":"Prerequisites‚Äã","type":1,"pageTitle":"Apache NiFi on EKS","url":"/data-on-eks/docs/blueprints/streaming-platforms/nifi#prerequisites","content":" Ensure that you have installed the following tools on your machine.  aws clikubectlterraformjq  Additionally, for end-to-end configuration of Ingress, you will need to provide the following:  A Route53 Public Hosted Zone configured in the account where you are deploying this example. E.g. &quot;example.com&quot;An ACM Certificate in the account + region where you are deploying this example. A wildcard certificate is preferred, e.g. &quot;*.example.com&quot;  ","version":"Next","tagName":"h2"},{"title":"Deploy the EKS Cluster with Apache NiFi‚Äã","type":1,"pageTitle":"Apache NiFi on EKS","url":"/data-on-eks/docs/blueprints/streaming-platforms/nifi#deploy-the-eks-cluster-with-apache-nifi","content":" ","version":"Next","tagName":"h2"},{"title":"Clone the repository‚Äã","type":1,"pageTitle":"Apache NiFi on EKS","url":"/data-on-eks/docs/blueprints/streaming-platforms/nifi#clone-the-repository","content":" git clone https://github.com/awslabs/data-on-eks.git   ","version":"Next","tagName":"h3"},{"title":"Initialize Terraform‚Äã","type":1,"pageTitle":"Apache NiFi on EKS","url":"/data-on-eks/docs/blueprints/streaming-platforms/nifi#initialize-terraform","content":" Navigate into the example directory and run terraform init  cd data-on-eks/streaming/nifi/ terraform init   ","version":"Next","tagName":"h3"},{"title":"Terraform Plan‚Äã","type":1,"pageTitle":"Apache NiFi on EKS","url":"/data-on-eks/docs/blueprints/streaming-platforms/nifi#terraform-plan","content":" Run Terraform plan to verify the resources created by this execution.  Provide a Route53 Hosted Zone hostname and a corresponding ACM Certificate;  export TF_VAR_eks_cluster_domain=&quot;&lt;CHANGEME - example.com&gt;&quot; export TF_VAR_acm_certificate_domain=&quot;&lt;CHANGEME - *.example.com&gt;&quot; export TF_VAR_nifi_sub_domain=&quot;nifi&quot; export TF_VAR_nifi_username=&quot;admin&quot;   ","version":"Next","tagName":"h3"},{"title":"Deploy the pattern‚Äã","type":1,"pageTitle":"Apache NiFi on EKS","url":"/data-on-eks/docs/blueprints/streaming-platforms/nifi#deploy-the-pattern","content":" terraform plan terraform apply   Enter yes to apply.  Outputs: configure_kubectl = &quot;aws eks --region us-west-2 update-kubeconfig --name nifi-on-eks&quot;   ","version":"Next","tagName":"h3"},{"title":"Verify Deployment‚Äã","type":1,"pageTitle":"Apache NiFi on EKS","url":"/data-on-eks/docs/blueprints/streaming-platforms/nifi#verify-deployment","content":" Update kubeconfig  aws eks --region us-west-2 update-kubeconfig --name nifi-on-eks   Verify all pods are running.  NAMESPACE NAME READY STATUS RESTARTS AGE amazon-cloudwatch aws-cloudwatch-metrics-7fbcq 1/1 Running 1 (43h ago) 2d amazon-cloudwatch aws-cloudwatch-metrics-82c9v 1/1 Running 1 (43h ago) 2d amazon-cloudwatch aws-cloudwatch-metrics-blrmt 1/1 Running 1 (43h ago) 2d amazon-cloudwatch aws-cloudwatch-metrics-dhpl7 1/1 Running 0 19h amazon-cloudwatch aws-cloudwatch-metrics-hpw5k 1/1 Running 1 (43h ago) 2d cert-manager cert-manager-7d57b6576b-c52dw 1/1 Running 1 (43h ago) 2d cert-manager cert-manager-cainjector-86f7f4749-hs7d9 1/1 Running 1 (43h ago) 2d cert-manager cert-manager-webhook-66c85f8577-rxms8 1/1 Running 1 (43h ago) 2d external-dns external-dns-57bb948d75-g8kbs 1/1 Running 0 41h grafana grafana-7f5b7f5d4c-znrqk 1/1 Running 1 (43h ago) 2d kube-system aws-load-balancer-controller-7ff998fc9b-86gql 1/1 Running 1 (43h ago) 2d kube-system aws-load-balancer-controller-7ff998fc9b-hct9k 1/1 Running 1 (43h ago) 2d kube-system aws-node-4gcqk 1/1 Running 1 (43h ago) 2d kube-system aws-node-4sssk 1/1 Running 0 19h kube-system aws-node-4t62f 1/1 Running 1 (43h ago) 2d kube-system aws-node-g4ndt 1/1 Running 1 (43h ago) 2d kube-system aws-node-hlxmq 1/1 Running 1 (43h ago) 2d kube-system cluster-autoscaler-aws-cluster-autoscaler-7bd6f7b94b-j7td5 1/1 Running 1 (43h ago) 2d kube-system cluster-proportional-autoscaler-coredns-6ccfb4d9b5-27xsd 1/1 Running 1 (43h ago) 2d kube-system coredns-5c5677bc78-rhzkx 1/1 Running 1 (43h ago) 2d kube-system coredns-5c5677bc78-t7m5z 1/1 Running 1 (43h ago) 2d kube-system ebs-csi-controller-87c4ff9d4-ffmwh 6/6 Running 6 (43h ago) 2d kube-system ebs-csi-controller-87c4ff9d4-nfw28 6/6 Running 6 (43h ago) 2d kube-system ebs-csi-node-4mkc8 3/3 Running 0 19h kube-system ebs-csi-node-74xqs 3/3 Running 3 (43h ago) 2d kube-system ebs-csi-node-8cw8t 3/3 Running 3 (43h ago) 2d kube-system ebs-csi-node-cs9wp 3/3 Running 3 (43h ago) 2d kube-system ebs-csi-node-ktdb7 3/3 Running 3 (43h ago) 2d kube-system kube-proxy-4s72m 1/1 Running 0 19h kube-system kube-proxy-95ptn 1/1 Running 1 (43h ago) 2d kube-system kube-proxy-bhrdk 1/1 Running 1 (43h ago) 2d kube-system kube-proxy-nzvb6 1/1 Running 1 (43h ago) 2d kube-system kube-proxy-q9xkc 1/1 Running 1 (43h ago) 2d kube-system metrics-server-fc87d766-dd647 1/1 Running 1 (43h ago) 2d kube-system metrics-server-fc87d766-vv8z9 1/1 Running 1 (43h ago) 2d logging aws-for-fluent-bit-b5vqg 1/1 Running 1 (43h ago) 2d logging aws-for-fluent-bit-pklhr 1/1 Running 0 19h logging aws-for-fluent-bit-rq2nc 1/1 Running 1 (43h ago) 2d logging aws-for-fluent-bit-tnmtl 1/1 Running 1 (43h ago) 2d logging aws-for-fluent-bit-zzhfc 1/1 Running 1 (43h ago) 2d nifi nifi-0 5/5 Running 0 41h nifi nifi-1 5/5 Running 0 41h nifi nifi-2 5/5 Running 0 41h nifi nifi-registry-0 1/1 Running 0 41h nifi nifi-zookeeper-0 1/1 Running 0 41h nifi nifi-zookeeper-1 1/1 Running 0 41h nifi nifi-zookeeper-2 1/1 Running 0 18h prometheus prometheus-alertmanager-655fcb46df-2qh8h 2/2 Running 2 (43h ago) 2d prometheus prometheus-kube-state-metrics-549f6d74dd-wwhtr 1/1 Running 1 (43h ago) 2d prometheus prometheus-node-exporter-5cpzk 1/1 Running 0 19h prometheus prometheus-node-exporter-8jhbk 1/1 Running 1 (43h ago) 2d prometheus prometheus-node-exporter-nbd42 1/1 Running 1 (43h ago) 2d prometheus prometheus-node-exporter-str6t 1/1 Running 1 (43h ago) 2d prometheus prometheus-node-exporter-zkf5s 1/1 Running 1 (43h ago) 2d prometheus prometheus-pushgateway-677c6fdd5-9tqkl 1/1 Running 1 (43h ago) 2d prometheus prometheus-server-7bf9cbb9cf-b2zgl 2/2 Running 2 (43h ago) 2d vpa vpa-recommender-7c6bbb4f9b-rjhr7 1/1 Running 1 (43h ago) 2d vpa vpa-updater-7975b9dc55-g6zf6 1/1 Running 1 (43h ago) 2d   Apache NiFi UI‚Äã  The Apache NiFi Dashboard can be opened at the following url &quot;https://nifi.example.com/nifi&quot;    Run the command below to retrieve NiFi user's password and default username as admin  aws secretsmanager get-secret-value --secret-id &lt;nifi_login_password_secret_name from terraform outputs&gt; --region &lt;region&gt; | jq '.SecretString' --raw-output     ","version":"Next","tagName":"h3"},{"title":"Monitoring‚Äã","type":1,"pageTitle":"Apache NiFi on EKS","url":"/data-on-eks/docs/blueprints/streaming-platforms/nifi#monitoring","content":" Apache Nifi can be monitored using metrics reported by PrometheusReportingTask. JVM metrics are disabled by default, let's enable the JVM metrics by navigating to Controller Settings by the clicking on the hamburger icon (three horizontal bars) in the top right corner.    Next click on the REPORTING TASK tab and then click the + icon and search for PrometheusReportingTask in the filter. Select the PrometheusReportingTask and click ADD button.    The prometheus reporting task is stopped by default.    Click on the pencil icon to edit the task and click on the PROPERTIES tab. Set the Send JVM metrics to true and click on Apply. Start the task by clicking on the play icon and ensure it's in running state.    This blueprint uses the prometheus and grafana to create a monitoring stack for getting visibility into your Apache NiFi cluster.  aws secretsmanager get-secret-value --secret-id &lt;grafana_secret_name from terraform outputs&gt; --region &lt;region&gt; | jq '.SecretString' --raw-output   Run the command below and open the Grafana dashboard using the url &quot;http://localhost:8080&quot;.  kubectl port-forward svc/grafana -n grafana 8080:80   Import Apache NiFi Grafana dashboard    ","version":"Next","tagName":"h3"},{"title":"Example‚Äã","type":1,"pageTitle":"Apache NiFi on EKS","url":"/data-on-eks/docs/blueprints/streaming-platforms/nifi#example","content":" Create IAM policies for accessing Amazon DynamoDB and AWS Kinesis‚Äã  Create an AWS IAM role: Create an AWS IAM role with permissions to access the AWS Kinesis data stream and assign this role to the AWS EKS cluster hosting Apache NiFi. Attach the IAM policy: Attach a policy to the IAM role that limits access to the Kinesis data stream to read-only and IAM policy to enable EKS role to write Amazon DynamoDB table. Here's an example policy:  { &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Statement&quot;: [ { &quot;Sid&quot;: &quot;Nifi-access-to-Kinesis&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;kinesis:DescribeStream&quot;, &quot;kinesis:GetRecords&quot;, &quot;kinesis:GetShardIterator&quot;, &quot;kinesis:ListStreams&quot; ], &quot;Resource&quot;: &quot;arn:aws:kinesis:&lt;REGION&gt;:&lt;ACCOUNT-ID&gt;:stream/kds-stream-nifi-on-EKS&quot; } ] }   { &quot;Sid&quot;: &quot;DynamoDBTableAccess&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Action&quot;: [ &quot;dynamodb:BatchGetItem&quot;, &quot;dynamodb:BatchWriteItem&quot;, &quot;dynamodb:ConditionCheckItem&quot;, &quot;dynamodb:PutItem&quot;, &quot;dynamodb:DescribeTable&quot;, &quot;dynamodb:DeleteItem&quot;, &quot;dynamodb:GetItem&quot;, &quot;dynamodb:Scan&quot;, &quot;dynamodb:Query&quot;, &quot;dynamodb:UpdateItem&quot; ], &quot;Resource&quot;: &quot;arn:aws:dynamodb:&lt;REGION&gt;:&lt;ACCOUNT-ID&gt;:table/NifiStreamingTable&quot; }   Create AWS Kinesis Data Stream‚Äã  Create an AWS Kinesis data stream: Log in to the AWS Management Console, and create a Kinesis data stream in the region where you want to collect your data or use the below command line to create one.  aws kinesis create-stream --stream-name kds-stream-nifi-on-EKS   Create Amazon DynamoDB table‚Äã  Create a Amazon DynamoDB in the same AWS Account using the AWS console or the command line. Create a JSON file with Amazon DynamoDb table information called JSONSchemaDynamoDBTABLE.json   &quot;TableName&quot;: &quot;NifiStreamingTable&quot;, &quot;KeySchema&quot;: [ { &quot;AttributeName&quot;: &quot;Name&quot;, &quot;KeyType&quot;: &quot;HASH&quot; }, { &quot;AttributeName&quot;: &quot;Age&quot;, &quot;KeyType&quot;: &quot;RANGE&quot; }}, { &quot;AttributeName&quot;: &quot;Location&quot;, &quot;KeyType&quot;: &quot;RANGE&quot; } ], &quot;AttributeDefinitions&quot;: [ { &quot;AttributeName&quot;: &quot;Name&quot;, &quot;KeyType&quot;: &quot;S&quot; }, { &quot;AttributeName&quot;: &quot;Age&quot;, &quot;KeyType&quot;: &quot;S&quot; }}, { &quot;AttributeName&quot;: &quot;Location&quot;, &quot;KeyType&quot;: &quot;S&quot; } ], &quot;ProvisionedThroughput&quot;: { &quot;ReadCapacityUnits&quot;: 5, &quot;WriteCapacityUnits&quot;: 5 } }   Execute the command line to create the Amazon DynamoDB table from the JSON file.  aws dynamodb create-table --cli-input-json JSONSchemaDynamoDBTABLE.json   Open the Apache Nifi on the EKS UI using the endpoint, create a process group, and name it NifiStreamingExample.      Double-click on the Nifi-on-EKS-process-group and enter the process to create the data flow. Drag the processor icon from the top left, type Kinesis into the search window, and select the ConsumeKinesisStream processor. To create a Kinesis Consumer, click ADD.¬†    Double click on the Kinesis processor, select the properties tab, and fill in the information for the configuration below. a. Amazon Kinesis Stream Name b. Application Name c. Region d. AWS Credentials Provider Service - Select AWSCredentialsProviderControllerService and create one.    Create AWS credential setup‚Äã  Setup the AWS credentials to access the AWS resource in the account using the AWS Credentials Provider Service. In this example, we are using the access key and secret key. Note : Other options are IAM role-based, assumed role options to authenticate an AWS resources.      Drag the processor icon from the top left, type &quot;dynamoDB&quot; into the search window, and select the &quot;PutDynamoDBRecord processor. Click on ADD to create an Amazon DynamoDB writer. Configure the processor using the fields below.  a. Record Reader - Change it to JSONTreeReader b. AWS Credentials Provider Service - select the previously created configuration c. Region b. Table Name d. Partition Key Field - select the partition field    Hover over the Kinesis consumer and drag it to the DynamoDB writer. The connection will be made, and the success queue will be created.    For the Kinesis Consumer and DynamoDB, create an error route to a funnel. This is to route the unprocessed, failed, and successful records for further processing. Note: Under the Relationship tab, you can see all the options for each processor. For the DynamoDB writer, success should always point to a funnel.    Check that none of the processors have any Hazard symbols. Right-click on the grid and click &quot;run the data flow.&quot; You can start seeing the data flowing in.  ","version":"Next","tagName":"h3"},{"title":"Cleanup‚Äã","type":1,"pageTitle":"Apache NiFi on EKS","url":"/data-on-eks/docs/blueprints/streaming-platforms/nifi#cleanup","content":" To clean up your environment, destroy the Terraform modules in reverse order.  Destroy the Kubernetes Add-ons, EKS cluster with Node groups and VPC  terraform destroy -target=&quot;module.eks_blueprints_kubernetes_addons&quot; --auto-approve terraform destroy -target=&quot;module.eks&quot; --auto-approve terraform destroy -target=&quot;module.vpc&quot; --auto-approve   Finally, destroy any additional resources that are not in the above modules  terraform destroy --auto-approve  ","version":"Next","tagName":"h2"},{"title":"EMR on EKS with Spark Streaming","type":0,"sectionRef":"#","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream","content":"","keywords":"","version":"Next"},{"title":"Spark examples - read stream from MSK‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#spark-examples---read-stream-from-msk","content":" Spark consumer applications reading from Amazon MSK:  1. Run a job with EMR on EKS2. Same job with Fargate on EMR on EKS3. Same job with EMR on EC2  ","version":"Next","tagName":"h2"},{"title":"Spark examples - read stream from Kinesis‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#spark-examples---read-stream-from-kinesis","content":" 1. (Optional) Build a custom docker image2. Run a job with kinesis-sql connector3. Run a job with Spark's DStream  ","version":"Next","tagName":"h2"},{"title":"Deploy Infrastructure‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#deploy-infrastructure","content":" The provisioning takes about 30 minutes to complete. Two ways to deploy:  AWS CloudFormation template (CFN)AWS Cloud Development Kit (AWS CDK).  ","version":"Next","tagName":"h2"},{"title":"CloudFormation Deployment‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#cloudformation-deployment","content":" Region\tLaunch Template---------------------------\t----------------------- US East (N. Virginia)\t  To launch in a different AWS Region, check out the following customization section, or use the CDK deployment option.  ","version":"Next","tagName":"h3"},{"title":"Customization‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#customization","content":" You can customize the solution, such as set to a different region, then generate the CFN templates in your required region:  export BUCKET_NAME_PREFIX=&lt;my-bucket-name&gt; # bucket where customized code will reside export AWS_REGION=&lt;your-region&gt; export SOLUTION_NAME=emr-stream-demo export VERSION=v2.0.0 # version number for the customized code cd data-on-eks/analytics/cdk/stream-emr-on-eks ./deployment/build-s3-dist.sh $BUCKET_NAME_PREFIX $SOLUTION_NAME $VERSION # create the bucket where customized code will reside aws s3 mb s3://$BUCKET_NAME_PREFIX-$AWS_REGION --region $AWS_REGION # Upload deployment assets to the S3 bucket aws s3 cp ./deployment/global-s3-assets/ s3://$BUCKET_NAME_PREFIX-$AWS_REGION/$SOLUTION_NAME/$VERSION/ --recursive --acl bucket-owner-full-control aws s3 cp ./deployment/regional-s3-assets/ s3://$BUCKET_NAME_PREFIX-$AWS_REGION/$SOLUTION_NAME/$VERSION/ --recursive --acl bucket-owner-full-control echo -e &quot;\\nIn web browser, paste the URL to launch the template: https://console.aws.amazon.com/cloudformation/home?region=$AWS_REGION#/stacks/quickcreate?stackName=emr-stream-demo&amp;templateURL=https://$BUCKET_NAME_PREFIX-$AWS_REGION.s3.amazonaws.com/$SOLUTION_NAME/$VERSION/emr-stream-demo.template\\n&quot;   ","version":"Next","tagName":"h3"},{"title":"CDK Deployment‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#cdk-deployment","content":" Prerequisites‚Äã  Install the following tools:  Python 3.6 +.Node.js 10.3.0 +AWS CLI. Configure the CLI by aws configure.CDK toolkitOne-off CDK bootstrap for the first time deployment.  Deploy‚Äã  python3 -m venv .env source .env/bin/activate pip install -r requirements.txt cdk deploy   ","version":"Next","tagName":"h3"},{"title":"Post-deployment‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#post-deployment","content":" The following post-deployment.sh is executable in Linux, not for Mac OSX. Modify the script if needed.  Open the &quot;Kafka Client&quot; IDE in Cloud9 console. Create one if the Cloud9 IDE doesn't exist.  VPC prefix: 'emr-stream-demo' Instance Type: 't3.small'   Attach the IAM role that contains Cloud9Admin to your IDE. Turn off AWS managed temporary credentials in Cloud9:  curl &quot;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip&quot; -o &quot;awscliv2.zip&quot; unzip awscliv2.zip sudo ./aws/install --update /usr/local/bin/aws cloud9 update-environment --environment-id $C9_PID --managed-credentials-action DISABLE rm -vf ${HOME}/.aws/credentials   Run the script to configure the cloud9 IDE environment:  curl https://raw.githubusercontent.com/aws-samples/stream-emr-on-eks/main/deployment/app_code/post-deployment.sh | bash   Wait for 5 mins, then check the MSK cluster status. Make sure it is active before sending data to the cluster.Launching a new terminal window in Cloud9, send the sample data to MSK:  wget https://github.com/xuite627/workshop_flink1015-1/raw/master/dataset/nycTaxiRides.gz zcat nycTaxiRides.gz | split -l 10000 --filter=&quot;kafka_2.12-2.8.1/bin/kafka-console-producer.sh --broker-list ${MSK_SERVER} --topic taxirides ; sleep 0.2&quot; &gt; /dev/null   Launching the 3rd terminal window and monitor the source MSK topic:  kafka_2.12-2.8.1/bin/kafka-console-consumer.sh \\ --bootstrap-server ${MSK_SERVER} \\ --topic taxirides \\ --from-beginning   ","version":"Next","tagName":"h2"},{"title":"MSK integration‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#msk-integration","content":" ","version":"Next","tagName":"h2"},{"title":"1. Submit a job with EMR on EKS‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#1-submit-a-job-with-emr-on-eks","content":" Sample job to consume data stream in MSKSubmit the job:  aws emr-containers start-job-run \\ --virtual-cluster-id $VIRTUAL_CLUSTER_ID \\ --name msk_consumer \\ --execution-role-arn $EMR_ROLE_ARN \\ --release-label emr-5.33.0-latest \\ --job-driver '{ &quot;sparkSubmitJobDriver&quot;:{ &quot;entryPoint&quot;: &quot;s3://'$S3BUCKET'/app_code/job/msk_consumer.py&quot;, &quot;entryPointArguments&quot;:[&quot;'$MSK_SERVER'&quot;,&quot;s3://'$S3BUCKET'/stream/checkpoint/emreks&quot;,&quot;emreks_output&quot;], &quot;sparkSubmitParameters&quot;: &quot;--conf spark.jars.packages=org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.7 --conf spark.cleaner.referenceTracking.cleanCheckpoints=true --conf spark.executor.instances=2 --conf spark.executor.memory=2G --conf spark.driver.memory=2G --conf spark.executor.cores=2&quot;}}' \\ --configuration-overrides '{ &quot;applicationConfiguration&quot;: [ { &quot;classification&quot;: &quot;spark-defaults&quot;, &quot;properties&quot;: { &quot;spark.kubernetes.driver.podTemplateFile&quot;:&quot;s3://'$S3BUCKET'/app_code/job/driver_template.yaml&quot;,&quot;spark.kubernetes.executor.podTemplateFile&quot;:&quot;s3://'$S3BUCKET'/app_code/job/executor_template.yaml&quot; } } ], &quot;monitoringConfiguration&quot;: { &quot;s3MonitoringConfiguration&quot;: {&quot;logUri&quot;: &quot;s3://'${S3BUCKET}'/elasticmapreduce/emreks-log/&quot;}} }'   ","version":"Next","tagName":"h3"},{"title":"Verify the job is running:‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#verify-the-job-is-running","content":" # can see the job pod in EKS kubectl get po -n emr # verify in EMR console # in Cloud9, run the consumer tool to check if any data comeing through in the target Kafka topic kafka_2.12-2.8.1/bin/kafka-console-consumer.sh --bootstrap-server ${MSK_SERVER} --topic emreks_output --from-beginning   ","version":"Next","tagName":"h3"},{"title":"Cancel the long-running job (can get job id from the job submission output or in EMR console)‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#cancel-the-long-running-job-can-get-job-id-from-the-job-submission-output-or-in-emr-console","content":" aws emr-containers cancel-job-run --virtual-cluster-id $VIRTUAL_CLUSTER_ID --id &lt;YOUR_JOB_ID&gt;   ","version":"Next","tagName":"h3"},{"title":"2. EMR on EKS with Fargate‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#2-emr-on-eks-with-fargate","content":" Run the same job on the same EKS cluster, but with the serverless option - Fargate compute choice.  To ensure it is picked up by Fargate not by the managed nodegroup on EC2, we will tag the Spark job by a serverless label, which has setup in a Fargate profile previously:  --conf spark.kubernetes.driver.label.type=serverless --conf spark.kubernetes.executor.label.type=serverless   Submit the job to Fargate:  aws emr-containers start-job-run \\ --virtual-cluster-id $VIRTUAL_CLUSTER_ID \\ --name msk_consumer_fg \\ --execution-role-arn $EMR_ROLE_ARN \\ --release-label emr-5.33.0-latest \\ --job-driver '{ &quot;sparkSubmitJobDriver&quot;:{ &quot;entryPoint&quot;: &quot;s3://'$S3BUCKET'/app_code/job/msk_consumer.py&quot;, &quot;entryPointArguments&quot;:[&quot;'$MSK_SERVER'&quot;,&quot;s3://'$S3BUCKET'/stream/checkpoint/emreksfg&quot;,&quot;emreksfg_output&quot;], &quot;sparkSubmitParameters&quot;: &quot;--conf spark.jars.packages=org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.7 --conf spark.cleaner.referenceTracking.cleanCheckpoints=true --conf spark.executor.instances=2 --conf spark.executor.memory=2G --conf spark.driver.memory=2G --conf spark.executor.cores=2 --conf spark.kubernetes.driver.label.type=serverless --conf spark.kubernetes.executor.label.type=serverless&quot;}}' \\ --configuration-overrides '{ &quot;monitoringConfiguration&quot;: { &quot;s3MonitoringConfiguration&quot;: {&quot;logUri&quot;: &quot;s3://'${S3BUCKET}'/elasticmapreduce/emreksfg-log/&quot;}}}'   ","version":"Next","tagName":"h3"},{"title":"Verify the job is running on EKS Fargate‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#verify-the-job-is-running-on-eks-fargate","content":" kubectl get po -n emr # verify in EMR console # in Cloud9, run the consumer tool to check if any data comeing through in the target Kafka topic kafka_2.12-2.8.1/bin/kafka-console-consumer.sh \\ --bootstrap-server ${MSK_SERVER} \\ --topic emreksfg_output \\ --from-beginning   ","version":"Next","tagName":"h3"},{"title":"3. (Optional) Submit step to EMR on EC2‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#3-optional-submit-step-to-emr-on-ec2","content":" cluster_id=$(aws emr list-clusters --cluster-states WAITING --query 'Clusters[?Name==`emr-stream-demo`].Id' --output text) MSK_SERVER=$(echo $MSK_SERVER | cut -d',' -f 2) aws emr add-steps \\ --cluster-id $cluster_id \\ --steps Type=spark,Name=emrec2_stream,Args=[--deploy-mode,cluster,--conf,spark.cleaner.referenceTracking.cleanCheckpoints=true,--conf,spark.executor.instances=2,--conf,spark.executor.memory=2G,--conf,spark.driver.memory=2G,--conf,spark.executor.cores=2,--packages,org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1,s3://$S3BUCKET/app_code/job/msk_consumer.py,$MSK_SERVER,s3://$S3BUCKET/stream/checkpoint/emrec2,emrec2_output],ActionOnFailure=CONTINUE   ","version":"Next","tagName":"h3"},{"title":"Verify‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#verify","content":" # verify in EMR console # in Cloud9, run the consumer tool to check if any data comeing through in the target Kafka topic kafka_2.12-2.8.1/bin/kafka-console-consumer.sh \\ --bootstrap-server ${MSK_SERVER} \\ --topic emrec2_output \\ --from-beginning   ","version":"Next","tagName":"h3"},{"title":"Kinesis integration‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#kinesis-integration","content":" ","version":"Next","tagName":"h2"},{"title":"1. (Optional) Build custom docker image‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#1-optional-build-custom-docker-image","content":" We will create &amp; delete a kinesis test stream on the fly via boto3, so a custom EMR on EKS docker image to include the Python library is needed. The custom docker image is not compulsory, if you don't need the boto3 and kinesis-sql connector.  Build a image based on EMR on EKS 6.5:  export AWS_REGION=$(aws configure list | grep region | awk '{print $2}') export ACCOUNT_ID=$(aws sts get-caller-identity --output text --query Account) export ECR_URL=$ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 895885662937.dkr.ecr.us-west-2.amazonaws.com docker build -t emr6.5_custom . # create ECR repo in current account aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $ECR_URL aws ecr create-repository --repository-name emr6.5_custom_boto3 --image-scanning-configuration scanOnPush=true --region $AWS_REGION # push to ECR docker tag emr6.5_custom $ECR_URL/emr6.5_custom_boto3 docker push $ECR_URL/emr6.5_custom_boto3   ","version":"Next","tagName":"h3"},{"title":"2. Use kinesis-sql connector‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#2-use-kinesis-sql-connector","content":" This demo uses the com.qubole.spark/spark-sql-kinesis_2.12/1.2.0-spark_3.0 connector to interact with Kinesis.  To enable the job-level access control, ie. the IRSA feature, we have forked the kinesis-sql git repo and recompiled a new jar after upgraded the AWS java SDK. The custom docker build above will pick up the upgraded connector automatically.  Sample job to consume data stream in KinesisSubmit the job:  export AWS_REGION=$(aws configure list | grep region | awk '{print $2}') export ACCOUNT_ID=$(aws sts get-caller-identity --output text --query Account) export ECR_URL=$ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com aws emr-containers start-job-run \\ --virtual-cluster-id $VIRTUAL_CLUSTER_ID \\ --name kinesis-demo \\ --execution-role-arn $EMR_ROLE_ARN \\ --release-label emr-6.5.0-latest \\ --job-driver '{ &quot;sparkSubmitJobDriver&quot;:{ &quot;entryPoint&quot;: &quot;s3://'$S3BUCKET'/app_code/job/qubole-kinesis.py&quot;, &quot;entryPointArguments&quot;:[&quot;'${AWS_REGION}'&quot;,&quot;s3://'${S3BUCKET}'/qubolecheckpoint&quot;,&quot;s3://'${S3BUCKET}'/qubole-kinesis-output&quot;], &quot;sparkSubmitParameters&quot;: &quot;--conf spark.cleaner.referenceTracking.cleanCheckpoints=true&quot;}}' \\ --configuration-overrides '{ &quot;applicationConfiguration&quot;: [ { &quot;classification&quot;: &quot;spark-defaults&quot;, &quot;properties&quot;: { &quot;spark.kubernetes.container.image&quot;: &quot;'${ECR_URL}'/emr6.5_custom_boto3:latest&quot; } } ], &quot;monitoringConfiguration&quot;: { &quot;s3MonitoringConfiguration&quot;: {&quot;logUri&quot;: &quot;s3://'${S3BUCKET}'/elasticmapreduce/kinesis-fargate-log/&quot;} } }'   ","version":"Next","tagName":"h3"},{"title":"3. Use Spark's DStream‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#3-use-sparks-dstream","content":" This demo uses the spark-streaming-kinesis-asl_2.12 library to read from Kinesis. Check out the Spark's official document. The Spark syntax is slightly different from the spark-sql-kinesis approach. It operates at RDD level.  Sample job to consume data stream from KinesisSubmit the job:  export AWS_REGION=$(aws configure list | grep region | awk '{print $2}') export ACCOUNT_ID=$(aws sts get-caller-identity --output text --query Account) export ECR_URL=$ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com aws emr-containers start-job-run \\ --virtual-cluster-id $VIRTUAL_CLUSTER_ID \\ --name kinesis-demo \\ --execution-role-arn $EMR_ROLE_ARN \\ --release-label emr-6.5.0-latest \\ --job-driver '{ &quot;sparkSubmitJobDriver&quot;:{ &quot;entryPoint&quot;: &quot;s3://'$S3BUCKET'/app_code/job/pyspark-kinesis.py&quot;, &quot;entryPointArguments&quot;:[&quot;'${AWS_REGION}'&quot;,&quot;s3://'$S3BUCKET'/asloutput/&quot;], &quot;sparkSubmitParameters&quot;: &quot;--jars https://repo1.maven.org/maven2/org/apache/spark/spark-streaming-kinesis-asl_2.12/3.1.2/spark-streaming-kinesis-asl_2.12-3.1.2.jar,https://repo1.maven.org/maven2/com/amazonaws/amazon-kinesis-client/1.12.0/amazon-kinesis-client-1.12.0.jar&quot;}}' \\ --configuration-overrides '{ &quot;applicationConfiguration&quot;: [ { &quot;classification&quot;: &quot;spark-defaults&quot;, &quot;properties&quot;: { &quot;spark.kubernetes.container.image&quot;: &quot;'${ECR_URL}'/emr6.5_custom_boto3:latest&quot; } } ], &quot;monitoringConfiguration&quot;: { &quot;s3MonitoringConfiguration&quot;: {&quot;logUri&quot;: &quot;s3://'${S3BUCKET}'/elasticmapreduce/kinesis-fargate-log/&quot;} } }'   ","version":"Next","tagName":"h3"},{"title":"Useful commands‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#useful-commands","content":" kubectl get pod -n emr list running Spark jobskubectl delete pod --all -n emr delete all Spark jobskubectl logs &lt;pod name&gt; -n emr check logs against a pod in the emr namespacekubectl get node --label-columns=eks.amazonaws.com/capacityType,topology.kubernetes.io/zone check EKS compute capacity types and AZ distribution.  ","version":"Next","tagName":"h2"},{"title":"Clean up‚Äã","type":1,"pageTitle":"EMR on EKS with Spark Streaming","url":"/data-on-eks/docs/blueprints/streaming-platforms/emr-eks-stream#clean-up","content":" Run the clean-up script with:  curl https://raw.githubusercontent.com/aws-samples/stream-emr-on-eks/main/deployment/app_code/delete_all.sh | bash   Go to the CloudFormation console, manually delete the remaining resources if needed. ","version":"Next","tagName":"h2"},{"title":"Gen AI on EKS","type":0,"sectionRef":"#","url":"/data-on-eks/docs/gen-ai","content":"","keywords":"","version":"Next"},{"title":"Training‚Äã","type":1,"pageTitle":"Gen AI on EKS","url":"/data-on-eks/docs/gen-ai#training","content":" Are you ready to dive into the world of LLMs and train models for your specific needs? Discover our comprehensive Training resources to get started.  ","version":"Next","tagName":"h2"},{"title":"Fine-tuning‚Äã","type":1,"pageTitle":"Gen AI on EKS","url":"/data-on-eks/docs/gen-ai#fine-tuning","content":" Fine-tuning LLMs is crucial for tailoring them to your specific tasks. Explore our Fine-tuning section to learn how to adapt LLMs to your unique requirements.  ","version":"Next","tagName":"h2"},{"title":"Inference‚Äã","type":1,"pageTitle":"Gen AI on EKS","url":"/data-on-eks/docs/gen-ai#inference","content":" Unlock the potential of LLMs for powerful inference tasks. Our Inference resources will guide you through deploying LLMs effectively.  Whether you're an experienced practitioner or new to the field, our Gen AI on EKS capabilities empower you to harness the latest advancements in language modeling. Dive into each section to begin your journey. ","version":"Next","tagName":"h2"},{"title":"BERT-Large on Trainium","type":0,"sectionRef":"#","url":"/data-on-eks/docs/gen-ai/training/BERT-Large","content":"BERT-Large on Trainium info COMING SOON Please note that this section is currently a work in progress and will serve as a comprehensive collection of resources for running data and ML workloads on EKS.","keywords":"","version":"Next"},{"title":"Stable Diffusion on GPUs","type":0,"sectionRef":"#","url":"/data-on-eks/docs/gen-ai/inference/StableDiffusion","content":"Stable Diffusion on GPUs info COMING SOON Please note that this section is currently a work in progress and will serve as a comprehensive collection of resources for running data and ML workloads on EKS.","keywords":"","version":"Next"},{"title":"intro","type":0,"sectionRef":"#","url":"/data-on-eks/docs/intro","content":"intro","keywords":"","version":"Next"},{"title":"Introduction","type":0,"sectionRef":"#","url":"/data-on-eks/docs/resources/intro","content":"Introduction info COMING SOON Please note that this section is currently a work in progress and will serve as a comprehensive collection of resources for running data and ML workloads on EKS. It will include useful links and videos to assist you in your journey.","keywords":"","version":"Next"},{"title":"Introduction","type":0,"sectionRef":"#","url":"/data-on-eks/docs/introduction/intro","content":"Introduction Data on Amazon EKS(DoEKS) - A tool for building aws managed and self-managed scalable data platforms on Amazon EKS. With DoEKS, You have access to: Robust Deployment Infrastructure as Code (IaC) Templates using Terraform and AWS CDK, among otherBest Practices for Deploying Data Solutions on Amazon EKSDetailed Performance Benchmark ReportsHands-on Samples of Apache Spark/ML Jobs and various other frameworksIn-depth Reference Architectures and Data Blogs to keep you ahead of the curve Architecture The diagram displays the open source data tools, k8s operators and frameworks that runs on Kubernetes covered in DoEKS. AWS Data Analytics managed services integration with Data on EKS OSS tools. Main Features üöÄ EMR on EKS üöÄ Open Source Spark on EKS üöÄ Custom Kubernetes Schedulers (e.g., Apache YuniKorn, Volcano) üöÄ Job Schedulers (e.g., Apache Airflow, Argo Workflows) üöÄ AI/ML on Kubernetes (e.g., KubeFlow, MLFlow, Tensorflow, PyTorch etc.) üöÄ Distributed Databases (e.g., Cassandra, CockroachDB, MongoDB etc.) üöÄ Streaming Platforms (e.g., Apache Kafka, Apache Flink, Apache Beam etc.) Getting Started Checkout the documentation for each section to deploy infrastructure and run sample Spark/ML jobs.","keywords":"","version":"Next"},{"title":"Deploying Llama-2-13b Chat Model with Inferentia, Ray Serve and Gradio","type":0,"sectionRef":"#","url":"/data-on-eks/docs/gen-ai/inference/Llama2","content":"","keywords":"","version":"Next"},{"title":"What is Llama-2?‚Äã","type":1,"pageTitle":"Deploying Llama-2-13b Chat Model with Inferentia, Ray Serve and Gradio","url":"/data-on-eks/docs/gen-ai/inference/Llama2#what-is-llama-2","content":" Llama-2 is a pretrained large language model (LLM) trained on 2 trillion tokens of text and code. It is one of the largest and most powerful LLMs available today. Llama-2 can be used for a variety of tasks, including natural language processing, text generation, and translation.  Llama-2-chat‚Äã  Llama-2 is a remarkable language model that has undergone a rigorous training process. It starts with pretraining using publicly available online data. An initial version of Llama-2-chat is then created through supervised fine-tuning. Following that, Llama-2-chat undergoes iterative refinement using Reinforcement Learning from Human Feedback (RLHF), which includes techniques like rejection sampling and proximal policy optimization (PPO). This process results in a highly capable and fine-tuned language model that we will guide you to deploy and utilize effectively on Amazon EKS with Ray Serve.  Llama-2 is available in three different model sizes:  Llama-2-70b: This is the largest Llama-2 model, with 70 billion parameters. It is the most powerful Llama-2 model and can be used for the most demanding tasks.Llama-2-13b: This is a medium-sized Llama-2 model, with 13 billion parameters. It is a good balance between performance and efficiency, and can be used for a variety of tasks.Llama-2-7b: This is the smallest Llama-2 model, with 7 billion parameters. It is the most efficient Llama-2 model and can be used for tasks that do not require the highest level of performance.  ","version":"Next","tagName":"h3"},{"title":"Which Llama-2 model size should I use?‚Äã","type":1,"pageTitle":"Deploying Llama-2-13b Chat Model with Inferentia, Ray Serve and Gradio","url":"/data-on-eks/docs/gen-ai/inference/Llama2#which-llama-2-model-size-should-i-use","content":" The best Llama-2 model size for you will depend on your specific needs. and it may not always be the largest model for achieving the highest performance. It's advisable to evaluate your needs and consider factors such as computational resources, response time, and cost-efficiency when selecting the appropriate Llama-2 model size. The decision should be based on a comprehensive assessment of your application's goals and constraints.  ","version":"Next","tagName":"h3"},{"title":"Inference on Trn1/Inf2 Instances: Unlocking the Full Potential of Llama-2‚Äã","type":1,"pageTitle":"Deploying Llama-2-13b Chat Model with Inferentia, Ray Serve and Gradio","url":"/data-on-eks/docs/gen-ai/inference/Llama2#inference-on-trn1inf2-instances-unlocking-the-full-potential-of-llama-2","content":" Llama-2 can be deployed on a variety of hardware platforms, each with its own set of advantages. However, when it comes to maximizing the efficiency, scalability, and cost-effectiveness of Llama-2, AWS Trn1/Inf2 instances shine as the optimal choice.  Scalability and AvailabilityOne of the key challenges in deploying large language models (LLMs) like Llama-2 is the scalability and availability of suitable hardware. Traditional GPU instances often face scarcity due to high demand, making it challenging to provision and scale resources effectively. In contrast, Trn1/Inf2 instances, such as trn1.32xlarge, trn1n.32xlarge, inf2.24xlarge and inf2.48xlarge, are purpose built for high-performance deep learning (DL) training and inference of generative AI models, including LLMs. They offer both scalability and availability, ensuring that you can deploy and scale your Llama-2 models as needed, without resource bottlenecks or delays.  Cost Optimization:Running LLMs on traditional GPU instances can be cost-prohibitive, especially given the scarcity of GPUs and their competitive pricing.Trn1/Inf2 instances provide a cost-effective alternative. By offering dedicated hardware optimized for AI and machine learning tasks, Trn1/Inf2 instances allow you to achieve top-notch performance at a fraction of the cost. This cost optimization enables you to allocate your budget efficiently, making LLM deployment accessible and sustainable.  Performance BoostWhile Llama-2 can achieve high-performance inference on GPUs, Neuron accelerators take performance to the next level. Neuron accelerators are purpose-built for machine learning workloads, providing hardware acceleration that significantly enhances Llama-2's inference speeds. This translates to faster response times and improved user experiences when deploying Llama-2 on Trn1/Inf2 instances.  ","version":"Next","tagName":"h2"},{"title":"Model Specification‚Äã","type":1,"pageTitle":"Deploying Llama-2-13b Chat Model with Inferentia, Ray Serve and Gradio","url":"/data-on-eks/docs/gen-ai/inference/Llama2#model-specification","content":" The table provides information about the different sizes of Llama-2 models, their weights, and the hardware requirements for deploying them. This information can be used to design the infrastructure required to deploy any size of Llama-2 model. For example, if you want to deploy the Llama-2-13b-chat model, you will need to use an instance type with at least 26 GB of total accelerator memory.  Model\tWeights\tBytes\tParameter Size (Billions)\tTotal Accelerator Memory (GB)\tAccelerator Memory Size for NeuronCore (GB)\tRequired Neuron Cores\tRequired Neuron Accelerators\tInstance Type\ttp_degreeMeta/Llama-2-70b\tfloat16\t2\t70\t140\t16\t9\t5\tinf2.48x\t24 Meta/Llama-2-13b\tfloat16\t2\t13\t26\t16\t2\t1\tinf2.24x\t12 Meta/Llama-2-7b\tfloat16\t2\t7\t14\t16\t1\t1\tinf2.24x\t12  ","version":"Next","tagName":"h3"},{"title":"Example usecase‚Äã","type":1,"pageTitle":"Deploying Llama-2-13b Chat Model with Inferentia, Ray Serve and Gradio","url":"/data-on-eks/docs/gen-ai/inference/Llama2#example-usecase","content":" A company wants to deploy a Llama-2 chatbot to provide customer support. The company has a large customer base and expects to receive a high volume of chat requests at peak times. The company needs to design an infrastructure that can handle the high volume of requests and provide a fast response time.  The company can use Inferentia2 instances to scale its Llama-2 chatbot efficiently. Inferentia2 instances are specialized hardware accelerators for machine learning tasks. They can provide up to 20x better performance and up to 7x lower cost than GPUs for machine learning workloads.  The company can also use Ray Serve to horizontally scale its Llama-2 chatbot. Ray Serve is a distributed framework for serving machine learning models. It can automatically scale your models up or down based on demand.  To scale its Llama-2 chatbot, the company can deploy multiple Inferentia2 instances and use Ray Serve to distribute the traffic across the instances. This will allow the company to handle a high volume of requests and provide a fast response time.  ","version":"Next","tagName":"h3"},{"title":"Solution Architecture‚Äã","type":1,"pageTitle":"Deploying Llama-2-13b Chat Model with Inferentia, Ray Serve and Gradio","url":"/data-on-eks/docs/gen-ai/inference/Llama2#solution-architecture","content":" In this section, we will delve into the architecture of our solution, which combines Llama-2 model, Ray Serve and Inferentia2 on Amazon EKS.    ","version":"Next","tagName":"h2"},{"title":"Deploying the Solution‚Äã","type":1,"pageTitle":"Deploying Llama-2-13b Chat Model with Inferentia, Ray Serve and Gradio","url":"/data-on-eks/docs/gen-ai/inference/Llama2#deploying-the-solution","content":" To get started with deploying Llama-2-13b chat on Amazon EKS, we will cover the necessary prerequisites and guide you through the deployment process step by step. This includes setting up the infrastructure, deploying the Ray cluster, and creating the Gradio WebUI app.  Prerequisites üëà  ","version":"Next","tagName":"h2"},{"title":"Deploying the Ray Cluster with Llama-2-Chat Model‚Äã","type":1,"pageTitle":"Deploying Llama-2-13b Chat Model with Inferentia, Ray Serve and Gradio","url":"/data-on-eks/docs/gen-ai/inference/Llama2#deploying-the-ray-cluster-with-llama-2-chat-model","content":" Once the Trainium on EKS Cluster is deployed, you can proceed to use kubectl to deploy the ray-service-Llama-2.yaml.  In this step, we will deploy the Ray Serve cluster, which comprises one Head Pod on x86 CPU instances using Karpenter autoscaling, as well as Ray workers on Inf2.48xlarge instances, autoscaled by Karpenter.  Let's take a closer look at the key files used in this deployment and understand their functionalities before proceeding with the deployment:  ray_serve_Llama-2.py:This script uses FastAPI, Ray Serve, and PyTorch-based Hugging Face Transformers to create an efficient API for text generation using the NousResearch/Llama-2-13b-chat-hf language model. Alternatively, users have the flexibility to switch to the meta-llama/Llama-2-13b-chat-hf model. The script establishes an endpoint that accepts input sentences and efficiently generates text outputs, benefiting from Neuron acceleration for enhanced performance. With its high configurability, users can fine-tune model parameters to suit a wide range of natural language processing applications, including chatbots and text generation tasks. ray-service-Llama-2.yaml:This Ray Serve YAML file serves as a Kubernetes configuration for deploying the Ray Serve service, facilitating efficient text generation using the Llama-2-13b-chat model. It defines a Kubernetes namespace named Llama-2 to isolate resources. Within the configuration, the RayService specification, named Llama-2-service, is created and hosted within the Llama-2 namespace. The RayService specification leverages the Python script ray_serve_Llama-2.py (copied into the Dockerfile located within the same folder) to create the Ray Serve service. The Docker image used in this example is publicly available on Amazon Elastic Container Registry (ECR) for ease of deployment. Users can also modify the Dockerfile to suit their specific requirements and push it to their own ECR repository, referencing it in the YAML file.  ","version":"Next","tagName":"h2"},{"title":"Deploy the Llama-2-Chat Model‚Äã","type":1,"pageTitle":"Deploying Llama-2-13b Chat Model with Inferentia, Ray Serve and Gradio","url":"/data-on-eks/docs/gen-ai/inference/Llama2#deploy-the-llama-2-chat-model","content":" Ensure the cluster is configured locally  aws eks --region us-west-2 update-kubeconfig --name trainium-inferentia   Deploy RayServe Cluster  cd ai-ml/trainium-inferentia/examples/ray-serve/llama2-inf2 kubectl apply -f ray-service-llama2.yaml   Verify the deployment by running the following commands  info The deployment process may take up to 10 minutes. The Head Pod is expected to be ready within 2 to 3 minutes, while the Ray Serve worker pod may take up to 10 minutes for image retrieval and Model deployment from Huggingface.  $ kubectl get all -n llama2 NAME READY STATUS RESTARTS AGE pod/llama2-service-raycluster-smqrl-head-4wlbb 0/1 ContainerCreating 0 77s pod/service-raycluster-smqrl-worker-inf2-worker-group-wjxqq 0/1 Init:0/1 0 77s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/llama2-service NodePort 172.20.246.48 &lt;none&gt; 8000:32138/TCP,52365:32653/TCP,8080:32604/TCP,6379:32739/TCP,8265:32288/TCP,10001:32419/TCP 78s $ kubectl get ingress -n llama2 NAME CLASS HOSTS ADDRESS PORTS AGE llama2-ingress nginx * k8s-ingressn-ingressn-randomid-randomid.elb.us-west-2.amazonaws.com 80 2m4s   Now, you can access the Ray Dashboard from the Load balancer URL below.  http://&lt;NLB_DNS_NAME&gt;/dashboard/#/serve  If you don't have access to a public Load Balancer, you can use port-forwarding and browse the Ray Dashboard using localhost with the following command:  kubectl port-forward svc/llama2-service 8265:8265 -n llama2 # Open the link in the browser http://localhost:8265/   From this webpage, you will be able to monitor the progress of Model deployment, as shown in the image below:    ","version":"Next","tagName":"h3"},{"title":"To Test the Llama-2-Chat Model‚Äã","type":1,"pageTitle":"Deploying Llama-2-13b Chat Model with Inferentia, Ray Serve and Gradio","url":"/data-on-eks/docs/gen-ai/inference/Llama2#to-test-the-llama-2-chat-model","content":" Once you see the status of the model deployment is in running state then you can start using Llama-2-chat.  You can use the following URL with a query added at the end of the URL.  http://&lt;NLB_DNS_NAME&gt;/serve/infer?sentence=what is data parallelism and tensor parallelisma and the differences  You will see an output like this in your browser:    ","version":"Next","tagName":"h3"},{"title":"Deploying the Gradio WebUI App‚Äã","type":1,"pageTitle":"Deploying Llama-2-13b Chat Model with Inferentia, Ray Serve and Gradio","url":"/data-on-eks/docs/gen-ai/inference/Llama2#deploying-the-gradio-webui-app","content":" Discover how to create a user-friendly chat interface using Gradio that integrates seamlessly with deployed models.  Let's deploy Gradio app locally on your machine to interact with the LLama-2-Chat model deployed using RayServe.  info The Gradio app interacts with the locally exposed service created solely for the demonstration. Alternatively, you can deploy the Gradio app on EKS as a Pod with Ingress and Load Balancer for wider accessibility.  ","version":"Next","tagName":"h2"},{"title":"Execute Port Forward to the llama2 Ray Service‚Äã","type":1,"pageTitle":"Deploying Llama-2-13b Chat Model with Inferentia, Ray Serve and Gradio","url":"/data-on-eks/docs/gen-ai/inference/Llama2#execute-port-forward-to-the-llama2-ray-service","content":" First, execute a port forward to the Llama-2 Ray Service using kubectl:  kubectl port-forward svc/llama2-service 8000:8000 -n llama2   ","version":"Next","tagName":"h3"},{"title":"Deploy Gradio WebUI Locally‚Äã","type":1,"pageTitle":"Deploying Llama-2-13b Chat Model with Inferentia, Ray Serve and Gradio","url":"/data-on-eks/docs/gen-ai/inference/Llama2#deploy-gradio-webui-locally","content":" Create a Virtual Environment‚Äã  Create a Python virtual environment in your machine for the Gradio application:  cd ai-ml/trainium-inferentia/examples/gradio-ui python3 -m venv .venv source .venv/bin/activate   Install Gradio ChatBot app‚Äã  Install all the Gradio WebUI app dependencies with pip  pip install gradio requests   Invoke the WebUI‚Äã  Run the Gradio WebUI using the following command:  NOTE: gradio-app.py refers to the port forward url. e.g., service_name = &quot;http://localhost:8000&quot;   python gradio-app.py   You should see output similar to the following:  Using cache from ~/data-on-eks/ai-ml/trainium-inferentia/examples/gradio-ui/gradio_cached_examples/16' directory. If method or examples have changed since last caching, delete this folder to clear cache. Running on local URL: http://127.0.0.1:7860 To create a public link, set `share=True` in `launch()`.   2.4. Access the WebUI from Your Browser‚Äã  Open your web browser and access the Gradio WebUI by navigating to the following URL:  http://127.0.0.1:7860  You should now be able to interact with the Gradio application from your local machine.    ","version":"Next","tagName":"h3"},{"title":"Conclusion‚Äã","type":1,"pageTitle":"Deploying Llama-2-13b Chat Model with Inferentia, Ray Serve and Gradio","url":"/data-on-eks/docs/gen-ai/inference/Llama2#conclusion","content":" In conclusion, you will have successfully deployed the Llama-2-13b chat model on EKS with Ray Serve and created a chatGPT-style chat web UI using Gradio. This opens up exciting possibilities for natural language processing and chatbot development.  In summary, when it comes to deploying and scaling Llama-2, AWS Trn1/Inf2 instances offer a compelling advantage. They provide the scalability, cost optimization, and performance boost needed to make running large language models efficient and accessible, all while overcoming the challenges associated with the scarcity of GPUs. Whether you're building chatbots, natural language processing applications, or any other LLM-driven solution, Trn1/Inf2 instances empower you to harness the full potential of Llama-2 on the AWS cloud.  ","version":"Next","tagName":"h2"},{"title":"Cleanup‚Äã","type":1,"pageTitle":"Deploying Llama-2-13b Chat Model with Inferentia, Ray Serve and Gradio","url":"/data-on-eks/docs/gen-ai/inference/Llama2#cleanup","content":" Finally, we'll provide instructions for cleaning up and deprovisioning the resources when they are no longer needed.  Step1: Cancel the execution of the python gradio-app.py  Step2: Delete Ray Cluster  cd ai-ml/trainium-inferentia/examples/ray-serve/llama2-inf2 kubectl delete -f ray-service-llama2.yaml   Step3: Cleanup the EKS Cluster This script will cleanup the environment using -target option to ensure all the resources are deleted in correct order.  export AWS_DEAFULT_REGION=&quot;DEPLOYED_EKS_CLUSTER_REGION&gt;&quot; cd data-on-eks/ai-ml/trainium-inferentia/ &amp;&amp; chmod +x cleanup.sh ./cleanup.sh  ","version":"Next","tagName":"h2"}],"options":{"id":"default"}}