apiVersion: v1
kind: Pod
metadata:
  name: ny-taxi-driver
  namespace: emr-data-team-a
  labels:
    applicationId: ny-taxi-yunikorn
    queue: root.test
  annotations:
    yunikorn.apache.org/schedulingPolicyParameters: "placeholderTimeoutSeconds=30 gangSchedulingStyle=Hard"
    yunikorn.apache.org/task-group-name: "spark-driver"
    # YuniKorn Gang Scheduling Configuration
    # minMember should match with driver and executor instances
    # minResource cpu and memory should match with driver and executor cpu and memory. This includes sidecar container resources.
    # Resource below should never be less than the actual resources defined for Driver and Executor with sidecar containers
    yunikorn.apache.org/task-groups: |-
      [{
          "name": "spark-driver",
          "minMember": 1,
          "minResource": {
            "cpu": "1200m",
            "memory": "15Gi"
          },
          "nodeSelector": {
            "NodeGroupType": "SparkMemoryOptimized"
          },
          "tolerations": [{"key" : "spark-memory-optimized", "operator": "Exists", "effect": "NoSchedule"}]
        },
        {
          "name": "spark-executor",
          "minMember": 20,
          "minResource": {
            "cpu": "1200m",
            "memory": "15Gi"
          },
          "nodeSelector": {
            "NodeGroupType": "SparkMemoryOptimized"
          },
          "tolerations": [{"key" : "spark-memory-optimized", "operator": "Exists", "effect": "NoSchedule"}]
      }]
spec:
  volumes:
    # This is using the temp storage on the node.
    # if you are using NVMe SSD then karpenter will configure the RAID0 under /mnt/k8s-disks/0 and copies the shuffle data to this location
    - name: spark-local-dir-1
      hostPath:
        path: /mnt/k8s-disks/0
        type: Directory

  nodeSelector:
    NodeGroupType: "SparkMemoryOptimized"
    karpenter.sh/capacity-type: "on-demand"
    topology.kubernetes.io/zone: "us-west-2b"

  # Don't use "/mnt" path as mountPath with EMR pod Templates as its reserved. You will get the following error.
  # Exception in thread "main" java.lang.IllegalArgumentException: Defined volume mount path on main container must not overlap with reserved mount paths: [/mnt]
  # at org.apache.spark.deploy.k8s.features.EmrInternalPodTemplateFeatureStep$AddVolumeMountsToMainContainerApplier.validate(EmrInternalPodTemplateFeatureStep.scala:447)
  initContainers:
    - name: volume-permission
      image: public.ecr.aws/docker/library/busybox
      # grant volume access to hadoop user
      command: ['sh', '-c', 'mkdir /data1; chown -R 999:1000 /data1']
      volumeMounts:
        - name: spark-local-dir-1
          mountPath: /data1
  containers:
    - name: spark-kubernetes-driver # Don't change this name. EMR on EKS looking for this name
      volumeMounts:
        - name: spark-local-dir-1
          mountPath: /data1
          readOnly: false

  tolerations:
    - key: "spark-memory-optimized"
      operator: "Exists"
      effect: "NoSchedule"
